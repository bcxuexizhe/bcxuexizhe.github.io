<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>hadoop的基础操作——Hadoop中创建、修改、查看、删除文件夹及文件 - 编程学习者</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcxuexizhe.github.io/posts/79955088da34333920b30f888bf1f217/">
  <meta property="og:site_name" content="编程学习者">
  <meta property="og:title" content="hadoop的基础操作——Hadoop中创建、修改、查看、删除文件夹及文件">
  <meta property="og:description" content="一、实验目的
熟练掌握常用的hadoop shell命令
二、实验内容 1.学习在开启、关闭Hadoop
2.学习在Hadoop中创建、修改、查看、删除文件夹及文件
3.学习改变文件的权限及文件的拥有者
4.学习使用shell命令提交job任务
5.Hadoop安全模式的进入与退出
三、实验原理或流程
调用文件系统(FS)Shell命令应使用 hadoop fs &lt;args&gt;的形式。 所有的的FS shell命令使用URI路径作为参数。URI格式是scheme://authority/path。对HDFS文件系统，scheme是hdfs，对本地文件系统，scheme是file。其中scheme和authority参数都是可选的，如果未加指定，就会使用配置中指定的默认scheme。一个HDFS文件或目录比如/parent/child可以表示成hdfs://namenode:namenodeport/parent/child，或者更简单的/parent/child（假设你配置文件中的默认值是namenode:namenodeport）。大多数FS Shell命令的行为和对应的Unix Shell命令类似，出错信息会输出到stderr，其他信息输出到stdout。
四、实验过程及源代码
1.打开终端模拟器，切换到/apps/hadoop/sbin目录下，启动Hadoop
​
​2.执行jps，检查一下Hadoop相关进程是否启动
3.在/目录下创建一个test1文件夹
hadoop fs -mkdir /test1 在Hadoop中的test1文件夹中创建一个file.txt文件 hadoop fs -touchz /test1/file.txt 查看根目录下所有文件 hadoop fs -ls / 还可以使用ls -R的方式递归查看根下所有文件 hadoop fs -ls -R / 将Hadoop根下test1目录中的file.txt文件，移动到根下并重命名为file2.txt hadoop fs -mv /test1/file.txt /file2.txt Hadoop中的mv用法同Linux中的一样，都可以起到移动文件和重命名的作用。
将Hadoop根下的file2.txt文件复制到test1目录下 hadoop fs -cp /file2.txt /test1 在Linux本地/data目录下，创建一个data.txt文件，并向其中写入hello hadoop cd /data touch data.txt echo hello hadoop! &gt;&gt; data.txt 将Linux本地/data目录下的data.txt文件，上传到HDFS中的/test1目录下hadoop fs -put /data/data.">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2023-12-19T17:18:50+08:00">
    <meta property="article:modified_time" content="2023-12-19T17:18:50+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程学习者" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程学习者</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">hadoop的基础操作——Hadoop中创建、修改、查看、删除文件夹及文件</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p style="margin-left:0;text-align:left;"><strong><span style="color:#000000;">一、实验目的</span></strong></p> 
<p style="margin-left:0;text-align:left;"><span style="color:#333333;">熟练掌握常用的hadoop shell命令</span></p> 
<p style="margin-left:0;text-align:left;"></p> 
<p style="margin-left:0;text-align:left;"><strong><span style="color:#000000;">二、实验内容 </span></strong></p> 
<p style="margin-left:0;text-align:left;"><span style="color:#333333;"> </span></p> 
<p style="margin-left:0;text-align:left;"><span style="color:#333333;">1.学习在开启、关闭Hadoop</span></p> 
<p style="margin-left:0;text-align:left;"><span style="color:#333333;">2.学习在Hadoop中创建、修改、查看、删除文件夹及文件</span></p> 
<p style="margin-left:0;text-align:left;"><span style="color:#333333;">3.学习改变文件的权限及文件的拥有者</span></p> 
<p style="margin-left:0;text-align:left;"><span style="color:#333333;">4.学习使用shell命令提交job任务</span></p> 
<p style="margin-left:0;text-align:left;"><span style="color:#333333;">5.Hadoop安全模式的进入与退出</span></p> 
<p style="margin-left:0;text-align:left;"></p> 
<p style="margin-left:0;text-align:left;"><strong><span style="color:#000000;">三、实验原理或流程</span></strong></p> 
<p style="margin-left:0;text-align:left;"><span style="color:#333333;">调用文件系统(FS)Shell命令应使用 hadoop fs &lt;args&gt;的形式。 所有的的FS shell命令使用URI路径作为参数。URI格式是scheme://authority/path。对HDFS文件系统，scheme是hdfs，对本地文件系统，scheme是file。其中scheme和authority参数都是可选的，如果未加指定，就会使用配置中指定的默认scheme。一个HDFS文件或目录比如/parent/child可以表示成hdfs://namenode:namenodeport/parent/child，或者更简单的/parent/child（假设你配置文件中的默认值是namenode:namenodeport）。大多数FS Shell命令的行为和对应的Unix Shell命令类似，出错信息会输出到stderr，其他信息输出到stdout。</span></p> 
<p style="margin-left:0;text-align:left;"></p> 
<p style="margin-left:0;text-align:left;"><strong><span style="color:#000000;">四、实验过程及源代码</span></strong></p> 
<p style="margin-left:0;text-align:left;"><span style="color:#333333;">1.打开终端模拟器，切换到/apps/hadoop/sbin目录下，启动Hadoop</span></p> 
<p style="margin-left:0;text-align:left;"><img alt="" height="428" src="https://images2.imgbox.com/5d/3b/J18xJXAa_o.png" width="570"><span style="color:#000000;">​</span></p> 
<p style="margin-left:0;text-align:left;"><span style="color:#000000;">​</span><span style="color:#333333;">2.执行jps，检查一下Hadoop相关进程是否启动</span></p> 
<p style="margin-left:0;text-align:left;"><img alt="" height="190" src="https://images2.imgbox.com/bc/1c/yQqCS8MN_o.png" width="1023"></p> 
<p style="margin-left:0;text-align:left;"><span style="background-color:#ffffff;"><span style="color:#333333;">3.在/目录下创建一个test1文件夹</span></span></p> 
<p style="margin-left:0;text-align:left;"><span style="background-color:#ffffff;"><span style="color:#000000;">hadoop fs -mkdir /test1  </span></span></p> 
<ol><li style="text-align:left;"><span style="background-color:#ffffff;"><span style="background-color:#ffffff;"><span style="color:#333333;">在Hadoop中的test1文件夹中创建一个file.txt文件</span></span></span></li></ol> 
<p style="margin-left:0;text-align:left;"><span style="background-color:#ffffff;"><span style="background-color:#ffffff;"><span style="color:#000000;">hadoop fs -touchz /test1/file.txt </span></span><span style="background-color:#ffffff;"><span style="color:#000000;"> </span></span></span></p> 
<ol><li style="text-align:left;"><span style="background-color:#ffffff;"><span style="background-color:#ffffff;"><span style="color:#333333;">查看根目录下所有文件</span></span></span></li></ol> 
<p style="margin-left:0;text-align:left;"><span style="background-color:#ffffff;"><span style="background-color:#ffffff;"><span style="color:#000000;">hadoop fs -ls /  </span></span></span></p> 
<p style="margin-left:0;text-align:left;"><img alt="" height="105" src="https://images2.imgbox.com/a3/17/kDfWVHJJ_o.png" width="692"></p> 
<ol><li style="text-align:left;"><span style="background-color:#ffffff;"><span style="background-color:#ffffff;"><span style="color:#333333;">还可以使用ls -R的方式递归查看根下所有文件</span></span></span></li></ol> 
<p style="margin-left:0;text-align:left;"><span style="background-color:#ffffff;"><span style="background-color:#ffffff;"><span style="color:#000000;">hadoop fs -ls -R /  </span></span></span></p> 
<p style="margin-left:0;text-align:left;"><img alt="" height="55" src="https://images2.imgbox.com/c6/05/q4NnBXZl_o.png" width="692"></p> 
<ol><li style="text-align:left;"><span style="background-color:#ffffff;"><span style="background-color:#ffffff;"><span style="color:#333333;">将Hadoop根下test1目录中的file.txt文件，移动到根下并重命名为file2.tx</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">t</span></span></span></li></ol> 
<p style="margin-left:0;text-align:left;"><span style="background-color:#ffffff;"><span style="background-color:#ffffff;"><span style="color:#000000;">hadoop fs -mv /test1/file.txt /file2.txt  </span></span></span></p> 
<p style="margin-left:0;text-align:left;"><img alt="" height="65" src="https://images2.imgbox.com/51/67/GLKv6HzJ_o.png" width="692"></p> 
<p style="margin-left:0;text-align:left;"><span style="background-color:#ffffff;"><span style="background-color:#ffffff;"><span style="color:#333333;">Hadoop中的mv用法同Linux中的一样，都可以起到移动文件和重命名的作用。</span></span></span></p> 
<ol><li style="text-align:left;"><span style="background-color:#ffffff;"><span style="background-color:#ffffff;"><span style="color:#333333;">将Hadoop根下的file2.txt文件复制到test1目录下</span></span></span></li></ol> 
<p style="margin-left:0;text-align:left;"><span style="background-color:#ffffff;"><span style="background-color:#ffffff;"><span style="color:#000000;">hadoop fs -cp /file2.txt /test1 </span></span></span></p> 
<p style="margin-left:0;text-align:left;"><img alt="" height="87" src="https://images2.imgbox.com/58/98/7QnDRWtN_o.png" width="692"></p> 
<ol><li style="text-align:left;"><span style="background-color:#ffffff;"><span style="background-color:#ffffff;"><span style="color:#333333;">在Linux本地/data目录下，创建一个data.txt文件，并向其中写入hello hadoop</span></span></span></li></ol> 
<p style="margin-left:0;text-align:left;"><span style="background-color:#ffffff;"><span style="background-color:#ffffff;"><span style="color:#000000;">cd /data  </span></span></span></p> 
<p style="margin-left:0;text-align:left;"><span style="background-color:#ffffff;"><span style="background-color:#f8f8f8;"><span style="color:#000000;">touch data.txt  </span></span></span></p> 
<p style="margin-left:0;text-align:left;"><span style="background-color:#ffffff;"><span style="background-color:#ffffff;"><span style="color:#000000;">echo hello hadoop! &gt;&gt; data.txt  </span></span></span></p> 
<p style="margin-left:0;text-align:left;"><img alt="" height="102" src="https://images2.imgbox.com/89/36/4QbsF1hZ_o.png" width="692"></p> 
<ol><li style="text-align:left;"><span style="background-color:#ffffff;"><span style="background-color:#ffffff;"><span style="color:#333333;">将Linux本地/data目录下的data.txt文件，上传到HDFS中的/test1目录下</span></span><span style="background-color:#ffffff;"><span style="color:#000000;">hadoop fs -put /data/data.txt /test1  </span></span></span></li><li style="text-align:left;"><span style="background-color:#ffffff;"><span style="background-color:#ffffff;"><span style="color:#333333;">查看Hadoop中/test1目录下的data.txt文件</span></span><span style="background-color:#ffffff;"><span style="color:#000000;"> </span></span></span></li></ol> 
<p style="margin-left:0;text-align:left;"><span style="background-color:#ffffff;"><span style="background-color:#ffffff;"><span style="color:#000000;">hadoop fs -cat /test1/data.txt  </span></span></span></p> 
<p style="margin-left:0;text-align:left;"><img alt="" height="60" src="https://images2.imgbox.com/7d/3a/CQypswxl_o.png" width="692"></p> 
<ol><li style="text-align:left;"><span style="background-color:#ffffff;"><span style="background-color:#ffffff;"><span style="color:#333333;">除此之外还可以使用tail方法</span></span></span></li></ol> 
<p style="margin-left:0;text-align:left;"><span style="background-color:#ffffff;"><span style="background-color:#ffffff;"><span style="color:#000000;">hadoop fs -tail /test1/data.txt  </span></span></span></p> 
<p style="margin-left:0;text-align:left;"><img alt="" height="45" src="https://images2.imgbox.com/96/be/eI152XuW_o.png" width="692"></p> 
<p style="margin-left:0;text-align:left;"><span style="background-color:#ffffff;"><span style="background-color:#ffffff;"><span style="color:#333333;">tail方法是将文件尾部1K字节的内容输出。支持-f选项，行为和Unix中一致。</span></span></span></p> 
<ol><li style="text-align:left;"><span style="background-color:#ffffff;"><span style="background-color:#ffffff;"><span style="color:#333333;">查看Hadoop中/test1目录下的data.txt文件大小</span></span></span></li></ol> 
<p style="margin-left:0;text-align:left;"><span style="background-color:#ffffff;"><span style="background-color:#ffffff;"><span style="color:#000000;">hadoop fs -du -s /test1/data.txt  </span></span></span></p> 
<p style="margin-left:0;text-align:left;"><img alt="" height="45" src="https://images2.imgbox.com/58/f1/WR8xoEGw_o.png" width="692"></p> 
<p style="margin-left:0;text-align:left;"><span style="background-color:#ffffff;"><span style="background-color:#ffffff;"><span style="color:#333333;">-du 后面可以不加-s，直接写目录表示查看该目录下所有文件大小</span></span></span></p> 
<ol><li style="text-align:left;"><span style="background-color:#ffffff;"><span style="background-color:#ffffff;"><span style="color:#333333;">text方法可以将源文件输出为文本格式。允许的格式是zip和TextRecordInputStream。</span></span></span></li></ol> 
<p style="margin-left:0;text-align:left;"><span style="background-color:#ffffff;"><span style="background-color:#ffffff;"><span style="color:#000000;"> </span></span><span style="background-color:#ffffff;"><span style="color:#000000;">hadoop fs -text /test1/data.txt</span></span></span></p> 
<p style="margin-left:0;text-align:left;"><img alt="" height="43" src="https://images2.imgbox.com/0c/70/eQU5pSwp_o.png" width="692"></p> 
<ol><li style="text-align:left;"><span style="background-color:#ffffff;"><span style="background-color:#ffffff;"><span style="color:#333333;">stat方法可以返回指定路径的统计信息，有多个参数可选，当使用-stat选项但不指定format时候，只打印文件创建日期，相当于%y</span></span></span></li></ol> 
<p style="margin-left:0;text-align:left;"><span style="background-color:#ffffff;"><span style="background-color:#ffffff;"><span style="color:#000000;">hadoop fs -stat /test1/data.txt</span></span></span></p> 
<p style="margin-left:0;text-align:left;"><img alt="" height="40" src="https://images2.imgbox.com/d0/83/smPTa44p_o.png" width="692"></p> 
<p style="margin-left:0;text-align:left;"><span style="background-color:#ffffff;"><span style="background-color:#ffffff;"><span style="color:#333333;">下面列出了format的形式：</span></span></span></p> 
<p style="margin-left:0;text-align:left;"><span style="background-color:#ffffff;"><span style="background-color:#ffffff;"><span style="color:#333333;">%b：打印文件大小（目录为0）</span></span></span></p> 
<p style="margin-left:0;text-align:left;"><span style="background-color:#ffffff;"><span style="background-color:#ffffff;"><span style="color:#333333;">%n：打印文件名</span></span></span></p> 
<p style="margin-left:0;text-align:left;"><span style="background-color:#ffffff;"><span style="background-color:#ffffff;"><span style="color:#333333;">%o：打印block size （我们要的值）</span></span></span></p> 
<p style="margin-left:0;text-align:left;"><span style="background-color:#ffffff;"><span style="background-color:#ffffff;"><span style="color:#333333;">%r：打印备份数</span></span></span></p> 
<p style="margin-left:0;text-align:left;"><span style="background-color:#ffffff;"><span style="background-color:#ffffff;"><span style="color:#333333;">%y：打印UTC日期 yyyy-MM-dd HH:mm:ss</span></span></span></p> 
<p style="margin-left:0;text-align:left;"><span style="background-color:#ffffff;"><span style="background-color:#ffffff;"><span style="color:#333333;">%Y：打印自1970年1月1日以来的UTC微秒数</span></span></span></p> 
<p style="margin-left:0;text-align:left;"><span style="background-color:#ffffff;"><span style="background-color:#ffffff;"><span style="color:#333333;">%F：目录打印directory, 文件打印regular file</span></span></span></p> 
<ol><li style="text-align:left;"><span style="background-color:#ffffff;"><span style="background-color:#ffffff;"><span style="color:#333333;">将Hadoop中/test1目录下的data.txt文件，下载到Linux本地/apps目录中</span></span><span style="background-color:#ffffff;"><span style="color:#000000;">hadoop fs -get /test1/data.txt /apps  </span></span></span></li><li style="text-align:left;"><span style="background-color:#ffffff;"><span style="background-color:#ffffff;"><span style="color:#333333;">查看一下/apps目录下是否存在data.txt文件</span></span></span></li></ol> 
<p style="margin-left:0;text-align:left;"><span style="background-color:#ffffff;"><span style="background-color:#ffffff;"><span style="color:#000000;">ls /apps  </span></span></span></p> 
<p style="margin-left:0;text-align:left;"><img alt="" height="101" src="https://images2.imgbox.com/b1/3d/Leq2Erto_o.png" width="693"></p> 
<p style="margin-left:0;text-align:left;"><span style="background-color:#ffffff;"><span style="background-color:#ffffff;"><span style="color:#333333;">18.</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">使用chown方法，改变Hadoop中/test1目录中的data.txt文件拥有者为root，使用-R将使改变在目录结构下递归进行。  </span></span></span></p> 
<p style="margin-left:0;text-align:left;"><span style="background-color:#ffffff;"><span style="background-color:#ffffff;"><span style="color:#000000;">hadoop fs -chown root /test1/data.txt </span></span></span></p> 
<p style="margin-left:0;text-align:left;"><img alt="" height="132" src="https://images2.imgbox.com/46/1c/TqyFJP2Y_o.png" width="692"></p> 
<p style="margin-left:0;text-align:left;"><span style="background-color:#ffffff;"><span style="background-color:#ffffff;"><span style="color:#333333;">19.</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">使用chmod方法，赋予Hadoop中/test1目录中的data.txt文件777权限</span></span></span></p> 
<p style="margin-left:0;text-align:left;"><span style="background-color:#ffffff;"><span style="background-color:#ffffff;"><span style="color:#000000;">hadoop fs -chmod 777 /test1/data.txt</span></span></span></p> 
<p style="margin-left:0;text-align:left;"><img alt="" height="142" src="https://images2.imgbox.com/00/8e/IJBOSLWq_o.png" width="692"></p> 
<ol><li style="text-align:left;"><span style="background-color:#ffffff;"><span style="background-color:#ffffff;"><span style="color:#333333;">删除Hadoop根下的file2.txt文件</span></span></span></li></ol> 
<p style="margin-left:0;text-align:left;"><span style="background-color:#ffffff;"><span style="background-color:#ffffff;"><span style="color:#000000;">hadoop fs -rm /file2.txt </span></span></span></p> 
<p style="margin-left:0;text-align:left;"><img alt="" height="63" src="https://images2.imgbox.com/85/47/tG45CcHC_o.png" width="692"></p> 
<ol><li style="text-align:left;"><span style="background-color:#ffffff;"><span style="background-color:#ffffff;"><span style="color:#333333;">删除Hadoop根下的test1目录</span></span></span></li></ol> 
<p style="margin-left:0;text-align:left;"><span style="background-color:#ffffff;"><span style="background-color:#ffffff;"><span style="color:#000000;">hadoop fs -rm -r /test1</span></span></span></p> 
<p style="margin-left:0;text-align:left;"><img alt="" height="66" src="https://images2.imgbox.com/e7/19/galmNhTA_o.png" width="692"></p> 
<ol><li style="text-align:left;"><span style="background-color:#ffffff;"><span style="background-color:#ffffff;"><span style="color:#333333;">当在Hadoop中设置了回收站功能时，删除的文件会保留在回收站中，可以使用expunge方法清空回收站。</span></span></span></li></ol> 
<p style="margin-left:0;text-align:left;"><span style="background-color:#ffffff;"><span style="background-color:#ffffff;"><span style="color:#000000;">hadoop fs -expunge  </span></span></span></p> 
<p style="margin-left:0;text-align:left;"><img alt="" height="53" src="https://images2.imgbox.com/fc/ac/CWkrwfPg_o.png" width="692"></p> 
<p style="margin-left:0;text-align:left;"><span style="background-color:#ffffff;"><span style="background-color:#ffffff;"><span style="color:#333333;">在分布式文件系统启动的时候，开始的时候会有安全模式，当分布式文件系统处于安全模式的情况下，文件系统中的内容不允许修改也不允许删除，直到安全模式结束。安全模式主要是为了系统启动的时候检查各个DataNode上数据块的有效性，同时根据策略必要的复制或者删除部分数据块。运行期通过命令也可以进入安全模式。在实践过程中，系统启动的时候去修改和删除文件也会有安全模式不允许修改的出错提示，只需要等待一会儿即可。</span></span></span></p> 
<ol><li style="text-align:left;"><span style="background-color:#ffffff;"><span style="background-color:#ffffff;"><span style="color:#333333;">使用Shell命令执行Hadoop自带的WordCount</span></span></span></li></ol> 
<p style="margin-left:0;text-align:left;"><span style="background-color:#ffffff;"><span style="background-color:#ffffff;"><span style="color:#333333;">首先切换到/data目录下，使用vim编辑一个data.txt文件，内容为:hello world hello hadoop hello ipieuvre</span></span></span></p> 
<p style="margin-left:0;text-align:left;"><span style="background-color:#ffffff;"><span style="background-color:#ffffff;"><span style="color:#000000;">cd /data  </span></span></span></p> 
<p style="margin-left:0;text-align:left;"><span style="background-color:#ffffff;"><span style="background-color:#f8f8f8;"><span style="color:#000000;">vim data.txt  </span></span></span></p> 
<p style="margin-left:0;text-align:left;"><span style="background-color:#ffffff;"><span style="background-color:#ffffff;"><span style="color:#333333;">在HDFS的根下创建in目录，并将/data下的data.txt文件上传到HDFS中的in目录</span></span></span></p> 
<p style="margin-left:0;text-align:left;"><span style="background-color:#ffffff;"><span style="background-color:#ffffff;"><span style="color:#000000;">hadoop fs -put /data/data.txt /</span></span><strong><span style="background-color:#ffffff;"><span style="color:#006699;"><strong>in</strong></span></span></strong></span></p> 
<p style="margin-left:0;text-align:left;"><span style="background-color:#ffffff;"><span style="background-color:#ffffff;"><span style="color:#333333;">执行hadoop jar命令，在hadoop的/apps/hadoop/share/hadoop/mapreduce路径下存在hadoop-mapreduce-examples-2.6.0-cdh5.4.5.jar包，我们执行其中的worldcount类，数据来源为HDFS的/in目录，数据输出到HDFS的/out目录</span></span><span style="background-color:#ffffff;"><span style="color:#000000;">hadoop jar /apps/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.0-cdh5.4.5.jar wordcount /</span></span><strong><span style="background-color:#ffffff;"><span style="color:#006699;"><strong>in</strong></span></span></strong><span style="background-color:#ffffff;"><span style="color:#000000;"> /out  </span></span></span></p> 
<p style="margin-left:0;text-align:left;"></p> 
<p style="margin-left:0;text-align:left;"><span style="background-color:#ffffff;"><span style="background-color:#ffffff;"><span style="color:#333333;">查看HDFS中的/out目录</span></span></span></p> 
<p style="margin-left:0;text-align:left;"><span style="background-color:#ffffff;"><span style="background-color:#ffffff;"><span style="color:#000000;">hadoop fs -ls /out </span></span></span></p> 
<p style="margin-left:0;text-align:left;"><span style="background-color:#ffffff;"><span style="background-color:#ffffff;"><span style="color:#000000;"> </span></span><span style="background-color:#f8f8f8;"><span style="color:#000000;">hadoop fs -cat /out/* </span></span></span></p> 
<ol><li style="text-align:left;"><span style="background-color:#ffffff;"><span style="background-color:#ffffff;"><span style="color:#333333;">进入Hadoop安全模式</span></span></span></li></ol> 
<p style="margin-left:0;text-align:left;"><span style="background-color:#ffffff;"><span style="background-color:#ffffff;"><span style="color:#000000;">hdfs dfsadmin -safemode enter  </span></span></span></p> 
<p style="margin-left:0;text-align:left;"><img alt="" height="47" src="https://images2.imgbox.com/d5/2b/3hftDDSe_o.png" width="692"></p> 
<ol><li style="text-align:left;"><span style="background-color:#ffffff;"><span style="background-color:#ffffff;"><span style="color:#333333;">退出Hadoop安全模式</span></span></span></li></ol> 
<p style="margin-left:0;text-align:left;"><span style="background-color:#ffffff;"><span style="background-color:#ffffff;"><span style="color:#000000;">hdfs dfsadmin -safemode leave  </span></span></span></p> 
<p style="margin-left:0;text-align:left;"><img alt="" height="41" src="https://images2.imgbox.com/a3/1f/wm7rnsRx_o.png" width="693"></p> 
<ol><li style="text-align:left;"><span style="background-color:#ffffff;"><span style="background-color:#ffffff;"><span style="color:#333333;">切换到/apps/hadoop/sbin目录下，关闭Hadoop</span></span></span></li></ol> 
<p style="margin-left:0;text-align:left;"><span style="background-color:#ffffff;"><span style="background-color:#ffffff;"><span style="color:#000000;">cd /apps/hadoop/sbin  </span></span><span style="background-color:#f8f8f8;"><span style="color:#000000;">./stop-all.sh</span></span></span></p> 
<p style="margin-left:0;text-align:left;"><img alt="" height="212" src="https://images2.imgbox.com/de/39/q0s65KHB_o.png" width="692"></p> 
<p style="margin-left:0;text-align:left;"><strong><span style="color:#000000;">五、实验结论及心得</span></strong></p> 
<p style="margin-left:.0001pt;text-align:justify;">通过完成本次实验，我熟练掌握了常用的Hadoop Shell命令，并对Hadoop的基本操作有了更深入的了解。</p> 
<p style="margin-left:.0001pt;text-align:justify;">在本次实验中，我学习了如何开启和关闭Hadoop集群。通过使用适当的命令，我能够启动和停止Hadoop服务，确保集群正常运行。</p> 
<p style="margin-left:.0001pt;text-align:justify;">我还学习了如何在Hadoop中创建、修改、查看和删除文件夹及文件。使用命令行界面，我可以轻松地创建新的文件夹和文件，并对它们进行必要的修改和删除操作。</p> 
<p style="margin-left:.0001pt;text-align:justify;">另外，我了解了如何改变文件的权限和文件的拥有者。通过使用适当的命令，我可以为文件设置不同的权限，以控制对文件的访问级别。我还学会了如何更改文件的所有者，以确保适当的文件管理和访问控制。</p> 
<p style="margin-left:.0001pt;text-align:justify;">在本次实验的过程中，我还学习了如何使用Shell命令提交Hadoop作业任务。这使我能够将作业提交到Hadoop集群，并跟踪作业的执行情况。通过这种方式，我可以有效地管理和监控我的作业。</p> 
<p style="margin-left:.0001pt;text-align:justify;"></p> 
<p style="margin-left:.0001pt;text-align:justify;">最后，我了解了Hadoop的安全模式，并学会了如何进入和退出安全模式。这对于确保集群的安全性和稳定性非常重要，因为安全模式可以防止对文件系统的意外修改。</p> 
<p style="margin-left:.0001pt;text-align:justify;">总的来说，通过本次实验，我不仅熟悉了常用的Hadoop Shell命令，还获得了对Hadoop集群管理的实际经验。这将对我的日后工作和学习中的大数据处理任务非常有帮助。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/0e8cb32fe4a59c5bf35d6259ebb9864e/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">大数据Hadoop之——部署hadoop&#43;hive&#43;Mysql环境（window11）</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/74f90241ef48ee6ef54e73b49b983601/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Postgresql中PL/pgSQL代码块的语法与使用-声明与赋值、IF语句、CASE语句、循环语句</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程学习者.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>