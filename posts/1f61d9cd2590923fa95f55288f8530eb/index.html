<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Stable Diffusion AI绘画：从提示词到模型出图的全景指南 - 编程学习者</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcxuexizhe.github.io/posts/1f61d9cd2590923fa95f55288f8530eb/">
  <meta property="og:site_name" content="编程学习者">
  <meta property="og:title" content="Stable Diffusion AI绘画：从提示词到模型出图的全景指南">
  <meta property="og:description" content="💂 个人网站:【 摸鱼游戏】【神级代码资源网站】【工具大全】🤟 一站式轻松构建小程序、Web网站、移动应用：👉注册地址🤟 基于Web端打造的：👉轻量化工具创作平台💅 想寻找共同学习交流，摸鱼划水的小伙伴，请点击【全栈技术交流群】 Stable Diffusion 是近年来备受关注的一种AI绘画技术，它能够根据文本提示生成高质量的图像。本文将详细介绍Stable Diffusion 的工作原理、技术架构以及如何使用该技术从提示词生成图像，并附上示例代码，帮助你更好地理解和应用这项技术。
什么是 Stable Diffusion？ Stable Diffusion 是一种基于扩散模型（Diffusion Models）的图像生成技术。扩散模型通过逐步添加和去除噪声来训练神经网络，从而生成高质量的图像。这种方法在图像生成任务中表现出色，能够根据输入的文本提示生成符合描述的图像。
Stable Diffusion 的工作原理 Stable Diffusion 的核心原理是扩散过程，它包括两个主要阶段：
正向扩散过程：将训练数据中的图像逐步添加噪声，直到图像变成纯噪声。这一过程帮助模型学习如何在不同的噪声水平下还原图像。
逆向扩散过程：训练好的模型根据输入的噪声图像逐步去除噪声，最终生成高质量的图像。在生成过程中，模型会结合输入的文本提示，生成与提示相符的图像。
Stable Diffusion 的技术架构 Stable Diffusion 的技术架构主要由以下几个部分组成：
编码器（Encoder）：将输入的文本提示编码成向量表示，作为生成图像的条件输入。
噪声预测网络（Noise Prediction Network）：基于U-Net架构，预测并去除图像中的噪声。
调度器（Scheduler）：控制扩散过程中的噪声添加和去除步骤，确保生成过程的稳定性和效果。
从提示词到模型出图的流程 以下是使用 Stable Diffusion 从提示词生成图像的完整流程：
1. 安装必要的依赖 首先，需要安装必要的Python库和 Stable Diffusion 模型的依赖项。可以使用以下命令：
pip install torch torchvision transformers diffusers 2. 加载模型和其他组件 接下来，加载预训练的 Stable Diffusion 模型和相关组件。以下是示例代码：
import torch from transformers import CLIPTextModel, CLIPTokenizer from diffusers import StableDiffusionPipeline # 加载CLIP文本编码器和分词器 tokenizer = CLIPTokenizer.">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-05-28T09:28:16+08:00">
    <meta property="article:modified_time" content="2024-05-28T09:28:16+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程学习者" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程学习者</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Stable Diffusion AI绘画：从提示词到模型出图的全景指南</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-tomorrow-night-eighties">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <blockquote> 
 <ul><li><strong>💂 个人网站:【 <a href="https://haiyong.site/moyu" rel="nofollow">摸鱼游戏</a>】【<a href="https://code.haiyong.site" rel="nofollow">神级代码资源网站</a>】【<a href="https://tools.haiyong.site/" rel="nofollow">工具大全</a>】</strong></li><li><strong>🤟 一站式轻松构建小程序、Web网站、移动应用：👉<a href="https://cloud.memfiredb.com/auth/login?from=5VkUHt" rel="nofollow">注册地址</a></strong></li><li><strong>🤟 基于Web端打造的：👉<a href="https://sso.mapmost.com/#/login?source_inviter=ryIXGCHG" rel="nofollow">轻量化工具创作平台</a></strong></li><li><strong>💅 想寻找共同学习交流，摸鱼划水的小伙伴，请点击【<a href="https://haiyong.site/chat/" rel="nofollow">全栈技术交流群</a>】</strong></li></ul> 
</blockquote> 
<p>Stable Diffusion 是近年来备受关注的一种AI绘画技术，它能够根据文本提示生成高质量的图像。本文将详细介绍Stable Diffusion 的工作原理、技术架构以及如何使用该技术从提示词生成图像，并附上示例代码，帮助你更好地理解和应用这项技术。</p> 
<h3><a id="_Stable_Diffusion_8"></a>什么是 Stable Diffusion？</h3> 
<p>Stable Diffusion 是一种基于扩散模型（Diffusion Models）的图像生成技术。扩散模型通过逐步添加和去除噪声来训练神经网络，从而生成高质量的图像。这种方法在图像生成任务中表现出色，能够根据输入的文本提示生成符合描述的图像。</p> 
<h3><a id="Stable_Diffusion__12"></a>Stable Diffusion 的工作原理</h3> 
<p>Stable Diffusion 的核心原理是扩散过程，它包括两个主要阶段：</p> 
<ol><li> <p><strong>正向扩散过程</strong>：将训练数据中的图像逐步添加噪声，直到图像变成纯噪声。这一过程帮助模型学习如何在不同的噪声水平下还原图像。</p> </li><li> <p><strong>逆向扩散过程</strong>：训练好的模型根据输入的噪声图像逐步去除噪声，最终生成高质量的图像。在生成过程中，模型会结合输入的文本提示，生成与提示相符的图像。</p> </li></ol> 
<h3><a id="Stable_Diffusion__20"></a>Stable Diffusion 的技术架构</h3> 
<p>Stable Diffusion 的技术架构主要由以下几个部分组成：</p> 
<ol><li> <p><strong>编码器（Encoder）</strong>：将输入的文本提示编码成向量表示，作为生成图像的条件输入。</p> </li><li> <p><strong>噪声预测网络（Noise Prediction Network）</strong>：基于U-Net架构，预测并去除图像中的噪声。</p> </li><li> <p><strong>调度器（Scheduler）</strong>：控制扩散过程中的噪声添加和去除步骤，确保生成过程的稳定性和效果。</p> </li></ol> 
<h3><a id="_30"></a>从提示词到模型出图的流程</h3> 
<p>以下是使用 Stable Diffusion 从提示词生成图像的完整流程：</p> 
<h4><a id="1__34"></a>1. 安装必要的依赖</h4> 
<p>首先，需要安装必要的Python库和 Stable Diffusion 模型的依赖项。可以使用以下命令：</p> 
<pre><code class="prism language-bash">pip <span class="token function">install</span> torch torchvision transformers diffusers
</code></pre> 
<h4><a id="2__42"></a>2. 加载模型和其他组件</h4> 
<p>接下来，加载预训练的 Stable Diffusion 模型和相关组件。以下是示例代码：</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> torch
<span class="token keyword">from</span> transformers <span class="token keyword">import</span> CLIPTextModel<span class="token punctuation">,</span> CLIPTokenizer
<span class="token keyword">from</span> diffusers <span class="token keyword">import</span> StableDiffusionPipeline

<span class="token comment"># 加载CLIP文本编码器和分词器</span>
tokenizer <span class="token operator">=</span> CLIPTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"openai/clip-vit-base-patch32"</span><span class="token punctuation">)</span>
text_encoder <span class="token operator">=</span> CLIPTextModel<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"openai/clip-vit-base-patch32"</span><span class="token punctuation">)</span>

<span class="token comment"># 加载Stable Diffusion模型</span>
model_id <span class="token operator">=</span> <span class="token string">"CompVis/stable-diffusion-v1-4"</span>
pipeline <span class="token operator">=</span> StableDiffusionPipeline<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>model_id<span class="token punctuation">,</span> torch_dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float16<span class="token punctuation">)</span>
pipeline <span class="token operator">=</span> pipeline<span class="token punctuation">.</span>to<span class="token punctuation">(</span><span class="token string">"cuda"</span><span class="token punctuation">)</span>
</code></pre> 
<h4><a id="3__61"></a>3. 编码文本提示</h4> 
<p>使用CLIP文本编码器将输入的文本提示编码成向量表示：</p> 
<pre><code class="prism language-python">prompt <span class="token operator">=</span> <span class="token string">"A futuristic cityscape at sunset"</span>
inputs <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>prompt<span class="token punctuation">,</span> return_tensors<span class="token operator">=</span><span class="token string">"pt"</span><span class="token punctuation">)</span>
text_embeddings <span class="token operator">=</span> text_encoder<span class="token punctuation">(</span><span class="token operator">**</span>inputs<span class="token punctuation">)</span><span class="token punctuation">.</span>last_hidden_state
</code></pre> 
<h4><a id="4__71"></a>4. 生成图像</h4> 
<p>使用 Stable Diffusion 模型生成图像：</p> 
<pre><code class="prism language-python"><span class="token comment"># 生成图像</span>
num_images_to_generate <span class="token operator">=</span> <span class="token number">1</span>
generated_images <span class="token operator">=</span> pipeline<span class="token punctuation">(</span>prompt<span class="token punctuation">,</span> num_images_to_generate<span class="token operator">=</span>num_images_to_generate<span class="token punctuation">,</span> guidance_scale<span class="token operator">=</span><span class="token number">7.5</span><span class="token punctuation">)</span><span class="token punctuation">.</span>images

<span class="token comment"># 保存或显示生成的图像</span>
generated_images<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>save<span class="token punctuation">(</span><span class="token string">"generated_image.png"</span><span class="token punctuation">)</span>
</code></pre> 
<h4><a id="5__84"></a>5. 完整示例代码</h4> 
<p>以下是完整的示例代码，展示了如何使用 Stable Diffusion 从提示词生成图像：</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> torch
<span class="token keyword">from</span> transformers <span class="token keyword">import</span> CLIPTextModel<span class="token punctuation">,</span> CLIPTokenizer
<span class="token keyword">from</span> diffusers <span class="token keyword">import</span> StableDiffusionPipeline
<span class="token keyword">from</span> PIL <span class="token keyword">import</span> Image

<span class="token comment"># 加载CLIP文本编码器和分词器</span>
tokenizer <span class="token operator">=</span> CLIPTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"openai/clip-vit-base-patch32"</span><span class="token punctuation">)</span>
text_encoder <span class="token operator">=</span> CLIPTextModel<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"openai/clip-vit-base-patch32"</span><span class="token punctuation">)</span>

<span class="token comment"># 加载Stable Diffusion模型</span>
model_id <span class="token operator">=</span> <span class="token string">"CompVis/stable-diffusion-v1-4"</span>
pipeline <span class="token operator">=</span> StableDiffusionPipeline<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>model_id<span class="token punctuation">,</span> torch_dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float16<span class="token punctuation">)</span>
pipeline <span class="token operator">=</span> pipeline<span class="token punctuation">.</span>to<span class="token punctuation">(</span><span class="token string">"cuda"</span><span class="token punctuation">)</span>

<span class="token comment"># 编码文本提示</span>
prompt <span class="token operator">=</span> <span class="token string">"A futuristic cityscape at sunset"</span>
inputs <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>prompt<span class="token punctuation">,</span> return_tensors<span class="token operator">=</span><span class="token string">"pt"</span><span class="token punctuation">)</span>
text_embeddings <span class="token operator">=</span> text_encoder<span class="token punctuation">(</span><span class="token operator">**</span>inputs<span class="token punctuation">)</span><span class="token punctuation">.</span>last_hidden_state

<span class="token comment"># 生成图像</span>
num_images_to_generate <span class="token operator">=</span> <span class="token number">1</span>
generated_images <span class="token operator">=</span> pipeline<span class="token punctuation">(</span>prompt<span class="token punctuation">,</span> num_images_to_generate<span class="token operator">=</span>num_images_to_generate<span class="token punctuation">,</span> guidance_scale<span class="token operator">=</span><span class="token number">7.5</span><span class="token punctuation">)</span><span class="token punctuation">.</span>images

<span class="token comment"># 保存或显示生成的图像</span>
generated_images<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>save<span class="token punctuation">(</span><span class="token string">"generated_image.png"</span><span class="token punctuation">)</span>

<span class="token comment"># 显示生成的图像</span>
Image<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">"generated_image.png"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<h3><a id="_119"></a>未来展望</h3> 
<p>Stable Diffusion 作为一种先进的AI绘画技术，展现了巨大的潜力和广泛的应用前景。随着模型的不断优化和扩展，未来将能够生成更高质量、更符合用户需求的图像。无论是艺术创作、广告设计，还是游戏开发，Stable Diffusion 都将成为重要的技术工具。</p> 
<p>通过本文的介绍，相信你已经对 Stable Diffusion 的工作原理和实际应用有了全面的了解。希望这些示例代码能够帮助你在实际项目中更好地应用这项技术，创造出更多精彩的图像作品。</p> 
<h3><a id="__125"></a>⭐️ 好书推荐</h3> 
<p><b>《Stable Diffusion AI绘画从提示词到模型出图》</b></p> 
<p><img src="https://images2.imgbox.com/cb/bf/GLlTN4xN_o.png" alt="在这里插入图片描述" width="300"></p> 
<p>【内容简介】</p> 
<p>本书从ChatGPT的基础知识讲起，针对运营工作中的各种痛点，结合实战案例，如文案写作、图片制作、社交媒体运营、爆款视频文案、私域推广、广告策划、电商平台高效运营等，手把手教你使用ChatGPT进行智能化工作。此外，还介绍了通过ChatGPT配合Midjourney、D-ID等AI软件的使用，进一步帮助提高运营工作的效率。</p> 
<p><img src="https://images2.imgbox.com/2c/bc/xLQnvy34_o.png" alt="在这里插入图片描述" width="500"><img src="https://images2.imgbox.com/a9/2a/xde9nLQ0_o.png" alt="在这里插入图片描述" width="500"></p> 
<p>📚 京东购买链接：<a href="https://item.jd.com/14121179.html" rel="nofollow">《Stable Diffusion AI绘画从提示词到模型出图》</a></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/3023d84cce761d4900ad36b078447a52/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Linux完整版命令大全（十三）</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/0248f98b853769c053e286da587556ea/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Android 性能为王时代SparseArray和HashMap一争高下</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程学习者.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>