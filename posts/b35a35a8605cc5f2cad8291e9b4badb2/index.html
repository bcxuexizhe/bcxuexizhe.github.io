<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>手把手教你如何用python进行数据分析！（附四个案例） - 编程学习者</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcxuexizhe.github.io/posts/b35a35a8605cc5f2cad8291e9b4badb2/">
  <meta property="og:site_name" content="编程学习者">
  <meta property="og:title" content="手把手教你如何用python进行数据分析！（附四个案例）">
  <meta property="og:description" content="一、前期准备 三个包：Numpy、Pandas和matplotlib；工具：jupyter notebook。首先确保导入这两个包
#导入Numpy包 import numpy as np #导入Pandas包 import pandas as pd 二、基础知识 Pandas有三种数据结构：Series、DataFrame和Panel。Series类似于一维数组；DataFrame是类似表格的二维数组；Panel可以视为Excel的多表单Sheet。
1.read_table
read_table(filepath_or_buffer, sep=False, delimiter=None, header=’infer’, names=None, index_col=None, usecols=None, squeeze=False, prefix=None, mangle_dupe_cols=True, dtype=None, engine=None, converters=None, true_values=None, false_values=None, skipinitialspace=False, skiprows=None, skipfooter=0, nrows=None, na_values=None, keep_default_na=True, na_filter=True, verbose=False, skip_blank_lines=True, parse_dates=False, infer_datetime_format=False, keep_date_col=False, date_parser=None, dayfirst=False, iterator=False, chunksize=None, compression=’infer’, thousands=None, decimal=b’.’, lineterminator=None, quotechar=&#39;”‘, quoting=0, doublequote=True, escapechar=None, comment=None, encoding=None, dialect=None, tupleize_cols=None, error_bad_lines=True, warn_bad_lines=True, delim_whitespace=False, low_memory=True, memory_map=False, float_precision=None) 可以用于读取csv、excel、dat文件。
2.merge
merge(left, right, how=‘inner’, on=None, left_on=None, right_on=None, left_index=False, right_index=False, sort=False, suffixes=(’_x’, ‘_y’), copy=True, indicator=False, validate=None) 连接两个DataFrame并返回连接之后的DataFrame。">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2023-07-14T09:41:19+08:00">
    <meta property="article:modified_time" content="2023-07-14T09:41:19+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程学习者" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程学习者</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">手把手教你如何用python进行数据分析！（附四个案例）</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h2>一、前期准备</h2> 
<p>三个包：Numpy、Pandas和matplotlib；工具：jupyter notebook。首先确保导入这两个包</p> 
<pre><code class="language-python">#导入Numpy包
import numpy as np
#导入Pandas包
import pandas as pd</code></pre> 
<h2>二、基础知识</h2> 
<p>Pandas有三种数据结构：Series、DataFrame和Panel。Series类似于一维数组；DataFrame是类似表格的二维数组；Panel可以视为Excel的多表单Sheet。</p> 
<p>1.read_table</p> 
<pre><code class="language-python">read_table(filepath_or_buffer, sep=False, delimiter=None, header=’infer’, names=None, index_col=None, usecols=None, squeeze=False, prefix=None, mangle_dupe_cols=True, dtype=None, engine=None, converters=None, true_values=None, false_values=None, skipinitialspace=False, skiprows=None, skipfooter=0, nrows=None, na_values=None, keep_default_na=True, na_filter=True, verbose=False, skip_blank_lines=True, parse_dates=False, infer_datetime_format=False, keep_date_col=False, date_parser=None, dayfirst=False, iterator=False, chunksize=None, compression=’infer’, thousands=None, decimal=b’.’, lineterminator=None, quotechar='”‘, quoting=0, doublequote=True, escapechar=None, comment=None, encoding=None, dialect=None, tupleize_cols=None, error_bad_lines=True, warn_bad_lines=True, delim_whitespace=False, low_memory=True, memory_map=False, float_precision=None)</code></pre> 
<p>可以用于读取csv、excel、dat文件。</p> 
<p>2.merge</p> 
<pre><code class="language-python">merge(left, right, how=‘inner’, on=None, left_on=None, right_on=None, left_index=False, right_index=False, sort=False, suffixes=(’_x’, ‘_y’), copy=True, indicator=False, validate=None)</code></pre> 
<p>连接两个DataFrame并返回连接之后的DataFrame。</p> 
<p>3.iloc</p> 
<p><strong>iloc函数</strong>：通过行号来取行数据（<strong>如取第二行的数据</strong>）</p> 
<p>4.pivot_table</p> 
<p>通过使用pandas.pivot_table（）函数，可以实现与电子表格软件（例如Excel）的数据透视表功能相同的处理</p> 
<p>5.groupby</p> 
<p>和sql中的分组类似，pandas中的groupby函数也是先将df按照某个字段进行拆分，将相同属性分为一组；然后对拆分后的各组执行相应的转换操作；最后输出汇总转换后的各组结果。</p> 
<h2>三、具体案例</h2> 
<p>数据分析步骤：1.提出问题 2.理解数据 3.数据清洗 4.构建模型 5.数据可视化</p> 
<h3>3.1 MoviesLens 1M数据集</h3> 
<p>GroupLens实验室提供了一些从MoviesLens用户那里收集的20世纪90年代末到21世纪初的电影评分数据的集合。浙西额数据提供了电影的评分、流派、年份和观众数据（年龄、邮编、性别、职业）。 MovisLens1M数据集包含6000个用户对4000部电影的100万个评分。数据分布在三个表格之中：分别包含评分、用户信息和电影信息。 </p> 
<p>下载地址为：<a href="https://links.jianshu.com/go?to=http%3A%2F%2Ffiles.grouplens.org%2Fdatasets%2Fmovielens%2F" rel="nofollow" title="http://files.grouplens.org/datasets/movielens/">http://files.grouplens.org/datasets/movielens/</a>，有好几种版本，对应不同数据量。</p> 
<pre><code class="language-python">#读取users.dat文件
unames = ["user_id", "gender", "age", "occupation", "zip"]
users = pd.read_table("datasets/movielens/users.dat", sep="::",
                      header=None, names=unames, engine="python")
#读取ratings.dat文件
rnames = ["user_id", "movie_id", "rating", "timestamp"]
ratings = pd.read_table("datasets/movielens/ratings.dat", sep="::",
                        header=None, names=rnames, engine="python")
#读取movies.dat文件
mnames = ["movie_id", "title", "genres"]
movies = pd.read_table("datasets/movielens/movies.dat", sep="::",
                       header=None, names=mnames, engine="python")</code></pre> 
<p> 首先读取users.dat、rating.dat、movies.dat三个文件，并将他们存储在不同的DataFrame中，分别命名为users、ratings、movies。</p> 
<pre><code class="language-python">users.head(5)
ratings.head(5)
movies.head(5)
ratings</code></pre> 
<p>分别输出三个DataFrame的前五行，并输出ratings的全部数据。</p> 
<p><img alt="" height="453" src="https://images2.imgbox.com/b5/8e/zjywQEIj_o.png" width="798"></p> 
<pre><code class="language-python">data = pd.merge(pd.merge(ratings, users), movies)
data
data.iloc[0]</code></pre> 
<p>使用merge函数将ratings，users和movies进行合并，保留了三个DataFrame中所有的数据，并将他们之间重复的数据和行进行合并。合并生成名为data的新DataFrame，并输出整个数据以及读取第一行数据。</p> 
<p><img alt="" height="252" src="https://images2.imgbox.com/bc/00/Ux2xKlEa_o.png" width="766"></p> 
<pre><code class="language-python">mean_ratings = data.pivot_table("rating", index="title",
                                columns="gender", aggfunc="mean")
mean_ratings.head(5)</code></pre> 
<p> 使用pivot_table函数实现数据透视表功能，对rating中title列求均值，columns参数就是用来显示字符型数据的，显示性别数据。求均值生成名为mean_ratings的新DataFrame，并读取输出前五行数据。</p> 
<p><img alt="" height="248" src="https://images2.imgbox.com/ed/1f/XagMcTZD_o.png" width="600"></p> 
<pre><code class="language-python">ratings_by_title = data.groupby("title").size()
ratings_by_title.head()
active_titles = ratings_by_title.index[ratings_by_title &gt;= 250]
active_titles</code></pre> 
<p>使用groupby函数对data这一DataFrame按照电影名称title分组，并计算每个电影标题对应的评分数量。第二行代码显示每个电影标题对应的评分数量。第三四行代码统计对应评分数量大于250的电影标题将其定义为active_titles并输出。</p> 
<p><img alt="" height="277" src="https://images2.imgbox.com/d0/77/jpYeql8h_o.png" width="880"></p> 
<p></p> 
<pre><code class="language-python">mean_ratings = mean_ratings.loc[active_titles]
mean_ratings</code></pre> 
<p>读取mean_ratings中评分数量大于250的电影标题对应的数据并输出。</p> 
<p><img alt="" height="478" src="https://images2.imgbox.com/85/6a/wVuToewi_o.png" width="432"></p> 
<pre><code class="language-python">mean_ratings = mean_ratings.rename(index={"Seven Samurai (The Magnificent Seven) (Shichinin no samurai) (1954)":
                           "Seven Samurai (Shichinin no samurai) (1954)"})</code></pre> 
<p>使用rename函数将mean_ratings中Seven Samurai (The Magnificent Seven) (Shichinin no samurai) (1954)重新更改为Seven Samurai (Shichinin no samurai) (1954)。</p> 
<pre><code class="language-python">top_female_ratings = mean_ratings.sort_values("F", ascending=False)
top_female_ratings.head()</code></pre> 
<p>根据女性的评分使用排序函数对mean_ratings进行降序排序并输出。</p> 
<p><img alt="" height="248" src="https://images2.imgbox.com/dc/82/acuS3Sex_o.png" width="737"></p> 
<pre><code class="language-python">mean_ratings["diff"] = mean_ratings["M"] - mean_ratings["F"]</code></pre> 
<p> 用mean_ratings中男性评分减去女性评分计算出男女评分差异diff。</p> 
<pre><code class="language-python">sorted_by_diff = mean_ratings.sort_values("diff")
sorted_by_diff.head()</code></pre> 
<p>根据diff列的值使用排序函数对mean_ratings进行升序排序并输出。</p> 
<p><img alt="" height="245" src="https://images2.imgbox.com/60/09/65VHycYf_o.png" width="487"></p> 
<pre><code class="language-python">sorted_by_diff[::-1].head()</code></pre> 
<p>使用切片操作对diff进行逆序排序，并输出。</p> 
<pre><code class="language-python">rating_std_by_title = data.groupby("title")["rating"].std()
rating_std_by_title = rating_std_by_title.loc[active_titles]
rating_std_by_title.head()</code></pre> 
<p>std函数用于表示标准差。对电影标题title根据评分标准差分组。并读取活跃标题（评分数量大于250的电影标题）的标准差输出。</p> 
<p><img alt="" height="173" src="https://images2.imgbox.com/80/51/lcqPhF1j_o.png" width="476"></p> 
<pre><code class="language-python">rating_std_by_title.sort_values(ascending=False)[:10]</code></pre> 
<p> 根据评分标准差进行降序排序并读取前十行，也即输出评分标准差最大的十个电影标题。</p> 
<p><img alt="" height="269" src="https://images2.imgbox.com/7c/0a/KKmtLTOA_o.png" width="538"></p> 
<pre><code class="language-python">movies["genres"].head()
movies["genres"].head().str.split("|")
movies["genre"] = movies.pop("genres").str.split("|")
movies.head()</code></pre> 
<p>读取电影中genres列数据，并通过|分隔开。将分割后的数据命名为genre列，原数据列genres删除。</p> 
<p><img alt="" height="212" src="https://images2.imgbox.com/20/37/0hpAa3Wt_o.png" width="635"></p> 
<pre><code class="language-python">movies_exploded = movies.explode("genre")
movies_exploded[:10]</code></pre> 
<p> 使用explode函数将genre列中分割的数据展开成单独的几列数据并记为movies_exploded这个新DataFrame，输出前十行数据。</p> 
<p><img alt="" height="375" src="https://images2.imgbox.com/21/c1/tde6owp2_o.png" width="402"></p> 
<pre><code class="language-python">ratings_with_genre = pd.merge(pd.merge(movies_exploded, ratings), users)
ratings_with_genre.iloc[0]
genre_ratings = (ratings_with_genre.groupby(["genre", "age"])
                 ["rating"].mean()
                 .unstack("age"))
genre_ratings[:10]</code></pre> 
<p>将movies_exploded，ratings，users这三个合并起来生成一个新DataFrame，并读取第一行数据。按照genre和age进行分组，并计算每个组评分的平均值，使用unstack函数将结果重塑为以age为列索引的形式。</p> 
<p><img alt="" height="402" src="https://images2.imgbox.com/0b/9a/ycAuHKEQ_o.png" width="712"></p> 
<h3> 3.2 美国1880-2010年的婴儿名字</h3> 
<p>美国社会保障局（SSA）提供了从1880年至现在的婴儿姓名频率的数据。可以使用这些数据做很多事情：根据给定的名字对婴儿名字随时间的比例进行可视化，确定一个名字的相对排位，确定每年最受欢迎的名字，或者流行程度最高或最低的名字</p> 
<p>数据集下载地址：<a href="http://github.com/wesm/pydata-book" title="http://github.com/wesm/pydata-book">http://github.com/wesm/pydata-book</a></p> 
<pre><code class="language-python">names1880 = pd.read_csv("datasets/babynames/yob1880.txt",
                        names=["name", "sex", "births"])
names1880</code></pre> 
<p>读取名为“yob1880.txt”文件，并将其列名设为name，sex，births。</p> 
<p><img alt="" height="444" src="https://images2.imgbox.com/46/15/rPbW99Bk_o.png" width="269"></p> 
<pre><code class="language-python">names1880.groupby("sex")["births"].sum()</code></pre> 
<p>按照性别分组，并计算每组生日的总和。</p> 
<p><img alt="" height="103" src="https://images2.imgbox.com/c2/40/Q7U4l300_o.png" width="340"></p> 
<pre><code class="language-python">pieces = []
for year in range(1880, 2011):
    path = f"datasets/babynames/yob{year}.txt"
    frame = pd.read_csv(path, names=["name", "sex", "births"])

    # Add a column for the year
    frame["year"] = year
    pieces.append(frame)

# Concatenate everything into a single DataFrame
names = pd.concat(pieces, ignore_index=True)
names</code></pre> 
<p>提取从数据集中读取1880-2011年间的数据并生成names这个DataFrame。</p> 
<p><img alt="" height="439" src="https://images2.imgbox.com/66/72/H7KodWwu_o.png" width="418"></p> 
<pre><code class="language-python">total_births = names.pivot_table("births", index="year",
                                 columns="sex", aggfunc=sum)
total_births.tail()
total_births.plot(title="Total births by sex and year")</code></pre> 
<p> 使用pivot_table函数以births和sex分组的出生数总和，并显示最后几行。</p> 
<p>绘制一个标题为Total births by sex and year的折线图。</p> 
<p><img alt="" height="731" src="https://images2.imgbox.com/9e/e2/0cyfqBJQ_o.png" width="1143"></p> 
<pre><code class="language-python">def add_prop(group):
    group["prop"] = group["births"] / group["births"].sum()
    return group
names = names.groupby(["year", "sex"], group_keys=False).apply(add_prop)
names</code></pre> 
<p>定义一个增加组的函数add_prop，表示每个名字在出生年份和性别组中的比例，每个名字的出生率。</p> 
<p>对names按照年份和性别分组，并对每组应用add_prop函数。</p> 
<p><img alt="" height="434" src="https://images2.imgbox.com/d8/b7/HR0G3mxl_o.png" width="425"></p> 
<pre><code class="language-python">names.groupby(["year", "sex"])["prop"].sum()</code></pre> 
<p> 通过年份和性别分组，并计算对每组中的每个名字比例的总和。</p> 
<p><img alt="" height="300" src="https://images2.imgbox.com/13/a4/89had1br_o.png" width="411"></p> 
<pre><code class="language-python">def get_top1000(group):
    return group.sort_values("births", ascending=False)[:1000]
grouped = names.groupby(["year", "sex"])
top1000 = grouped.apply(get_top1000)
top1000.head()</code></pre> 
<p> 定义一个get_top1000的函数，该函数根据births进行降序排序，并取前1000行，也即births值最大的前1000。根据年份和性别分组，并对每个分组应用get_top1000函数。</p> 
<p><img alt="" height="241" src="https://images2.imgbox.com/32/3c/X9cvD9ML_o.png" width="463"></p> 
<pre><code class="language-python">top1000 = top1000.reset_index(drop=True)
top1000.head()</code></pre> 
<p>使用reset_index()函数对top1000 DataFrame 进行重置索引，并丢弃原始索引。设置drop=True可以移除原始索引列，以便在重置索引后不保留它。</p> 
<p><img alt="" height="213" src="https://images2.imgbox.com/cf/17/NbY0sTIh_o.png" width="373"></p> 
<pre><code class="language-python">boys = top1000[top1000["sex"] == "M"]
girls = top1000[top1000["sex"] == "F"]
total_births = top1000.pivot_table("births", index="year",
                                   columns="name",
                                   aggfunc=sum)
total_births.info()
subset = total_births[["John", "Harry", "Mary", "Marilyn"]]
subset.plot(subplots=True, figsize=(12, 10),
            title="Number of births per year")</code></pre> 
<p> 根据性别将top1000的值分为boys和girls两个数据集。并对births进行数据透视。</p> 
<p>使用info()方法打印出total_births的全部数据，并选择John、Harry、Mary、Marilyn四个名字绘制标题为Number of births per year的折线图。</p> 
<p><img alt="" height="751" src="https://images2.imgbox.com/cc/a5/QIeSA9EM_o.png" width="806"></p> 
<pre><code class="language-python">plt.figure()
table = top1000.pivot_table("prop", index="year",
                            columns="sex", aggfunc=sum)
table.plot(title="Sum of table1000.prop by year and sex",
           yticks=np.linspace(0, 1.2, 13))</code></pre> 
<p>对prop进行数据透视图，绘制标题为Sum of table1000.prop by year and sex的折线图。</p> 
<p><img alt="" height="699" src="https://images2.imgbox.com/ff/a5/gtc3Mr27_o.png" width="1148"></p> 
<pre><code class="language-python">df = boys[boys["year"] == 2010]
df</code></pre> 
<p>得到2010年男孩出生人数表</p> 
<p><img alt="" height="444" src="https://images2.imgbox.com/ea/e7/dSYsZYpU_o.png" width="437"></p> 
<pre><code class="language-python">prop_cumsum = df["prop"].sort_values(ascending=False).cumsum()
prop_cumsum[:10]
prop_cumsum.searchsorted(0.5)</code></pre> 
<p> 对2010年男孩出生人数表中prop值进行降序排序并计算累计和，并提取前10行，使用 searchsorted() 方法找到累计和达到 0.5 时的索引位置。<br><img alt="" height="41" src="https://images2.imgbox.com/50/ba/XHz8P6ek_o.png" width="318"></p> 
<pre><code class="language-python">df = boys[boys.year == 1900]
in1900 = df.sort_values("prop", ascending=False).prop.cumsum()
in1900.searchsorted(0.5) + 1</code></pre> 
<p> 得到1900年男孩出生人数表， 对表中prop值进行降序排序并计算累计和， searchsorted() 方法找到累计和达到 0.5 时的后一个索引位置。</p> 
<p><img alt="" height="43" src="https://images2.imgbox.com/f4/f7/HJHgZtV6_o.png" width="245"></p> 
<pre><code class="language-python">def get_quantile_count(group, q=0.5):
    group = group.sort_values("prop", ascending=False)
    return group.prop.cumsum().searchsorted(q) + 1

diversity = top1000.groupby(["year", "sex"]).apply(get_quantile_count)
diversity = diversity.unstack()
fig = plt.figure()
diversity.head()
diversity.plot(title="Number of popular names in top 50%")</code></pre> 
<p> 定义一个get_quantile_count函数，对prop值进行降序排序并计算累计和， searchsorted() 方法找到累计和达到 0.5 时的后一个索引位置。</p> 
<p>根据年份和性别分组，并对每组应用get_quantile_count函数，得到diversity这个新DataFrame，并绘制标题为Number of popular names in top 50%的折线图。</p> 
<p><img alt="" height="713" src="https://images2.imgbox.com/40/1f/wwML5adc_o.png" width="1126"></p> 
<pre><code class="language-python">def get_last_letter(x):
    return x[-1]

last_letters = names["name"].map(get_last_letter)
last_letters.name = "last_letter"

table = names.pivot_table("births", index=last_letters,
                          columns=["sex", "year"], aggfunc=sum)
subtable = table.reindex(columns=[1910, 1960, 2010], level="year")
subtable.head()</code></pre> 
<p> 定义一个返回字符串最后一个字母的函数。</p> 
<p>使用map函数对names中每一个名字提取最后一个字母。进行数据透视。</p> 
<p>展示1910，1960，2010年的数据。</p> 
<p><img alt="" height="273" src="https://images2.imgbox.com/e7/e3/3JEI2kcv_o.png" width="603"></p> 
<pre><code class="language-python">subtable.sum()
letter_prop = subtable / subtable.sum()
letter_prop</code></pre> 
<p> 展示每个年份和性别组合中每个名字的总和，以及占比</p> 
<p><img alt="" height="506" src="https://images2.imgbox.com/13/d0/qwO4GoFT_o.png" width="570"></p> 
<pre><code class="language-python">import matplotlib.pyplot as plt

fig, axes = plt.subplots(2, 1, figsize=(10, 8))
letter_prop["M"].plot(kind="bar", rot=0, ax=axes[0], title="Male")
letter_prop["F"].plot(kind="bar", rot=0, ax=axes[1], title="Female",
                      legend=False)</code></pre> 
<p> 导入matplotlib包分别以男生和女生绘制两幅柱状图。</p> 
<p><img alt="" height="720" src="https://images2.imgbox.com/a6/4f/mPv7CtJa_o.png" width="908"></p> 
<pre><code class="language-python">letter_prop = table / table.sum()

dny_ts = letter_prop.loc[["d", "n", "y"], "M"].T
dny_ts.head()</code></pre> 
<p> 统计最后男生中名字最后一个字母为d、n、y的比例。</p> 
<p><img alt="" height="236" src="https://images2.imgbox.com/7e/bb/sC9lz2Hw_o.png" width="394"></p> 
<p> 并绘制折线图。</p> 
<p><img alt="" height="678" src="https://images2.imgbox.com/4f/7a/B3AL0ivB_o.png" width="1101"></p> 
<pre><code class="language-python">all_names = pd.Series(top1000["name"].unique())
lesley_like = all_names[all_names.str.contains("Lesl")]
lesley_like</code></pre> 
<p>从top1000 DataFrame的"name"列获取唯一的姓名，并将结果存储在all_names变量中。选择all_names中包含"Lesl"的姓名，并将结果赋值给lesley_like变量。显示lesley_like Series，即包含以"Lesl"开头的姓名。</p> 
<p><img alt="" height="148" src="https://images2.imgbox.com/b7/71/svv6eKrr_o.png" width="212"></p> 
<pre><code class="language-python">filtered = top1000[top1000["name"].isin(lesley_like)]
filtered.groupby("name")["births"].sum()</code></pre> 
<p>根据top1000 DataFrame中的"name"列与lesley_like中的姓名进行匹配，筛选出匹配的行数据，并将结果赋值给filtered变量。 对filtered DataFrame按姓名进行分组，计算每个姓名的出生人数总和，并显示结果。</p> 
<p><img alt="" height="173" src="https://images2.imgbox.com/bc/fc/zxooduSp_o.png" width="340"></p> 
<pre><code class="language-python">table = filtered.pivot_table("births", index="year",
                             columns="sex", aggfunc="sum")
table = table.div(table.sum(axis="columns"), axis="index")
table.tail()</code></pre> 
<p>根据年份和性别对filtered进行透视，计算每个年份和性别的出生人数总和，并将结果存储在table变量中。对table进行归一化，即每行的总和作为除数，计算每个年份和性别的归一化比例。table归一化后最后几行的结果。</p> 
<p><img alt="" height="244" src="https://images2.imgbox.com/2c/dc/PqWxGbz4_o.png" width="181"></p> 
<pre><code class="language-python">fig = plt.figure()
table.plot(style={"M": "k-", "F": "k--"})</code></pre> 
<p> 绘制折线图，其中男生用实线，女生用虚线。</p> 
<p><img alt="" height="675" src="https://images2.imgbox.com/98/c3/4v8esQiJ_o.png" width="1074"></p> 
<h3>3.3 美国农业部食品数据库</h3> 
<p>美国农业部提供了食物营养信息数据库。每种事务都有一些识别属性以及两份营养元素和营养比例的列表。这种形式的数据不适合分析，所以需要做一些工作将数据转换成更好的形式。</p> 
<p>下载地址：<a href="http://www.nal.usda.gov/fnic/foodcomp/search/" rel="nofollow" title="http://www.nal.usda.gov/fnic/foodcomp/search/">http://www.nal.usda.gov/fnic/foodcomp/search/</a></p> 
<pre><code class="language-python">import json
db = json.load(open("datasets/usda_food/database.json"))
len(db)</code></pre> 
<p>计算列表中元素的个数</p> 
<pre><code class="language-python">db[0].keys()
db[0]["nutrients"][0]
nutrients = pd.DataFrame(db[0]["nutrients"])
nutrients.head(7)</code></pre> 
<p>获得db列表中索引为0的所有关键值。 从db列表中索引为0的元素中获取键为"nutrients"的值的列表，并返回列表中的第一个元素。将db列表中索引为0的元素中的"nutrients"值转换为Pandas DataFrame对象。 显示nutrients DataFrame的前7行数据。</p> 
<p><img alt="" height="275" src="https://images2.imgbox.com/30/8e/tWuGbjdv_o.png" width="508"></p> 
<pre><code class="language-python">info_keys = ["description", "group", "id", "manufacturer"]
info = pd.DataFrame(db, columns=info_keys)
info.head()
info.info()</code></pre> 
<p>包含要从数据库中提取的信息的键的列表。使用info_keys作为列名，创建包含db数据的Pandas DataFrame对象，并将其存储在info变量中。 显示info DataFrame的前几行数据。显示info DataFrame的基本信息。</p> 
<p><img alt="" height="250" src="https://images2.imgbox.com/26/b3/2AsCpK3K_o.png" width="405"></p> 
<pre><code class="language-python">pd.value_counts(info["group"])[:10]</code></pre> 
<p>从DataFrame info 中选择了名为 "group" 的列，该列包含了食物的分组信息。对选定列中的每个唯一值进行计数，并返回计数结果。取计数结果中的前 10 个值，即返回出现次数最多的前 10 个分组。</p> 
<p><img alt="" height="260" src="https://images2.imgbox.com/e1/23/9ueCGyhb_o.png" width="429"></p> 
<pre><code class="language-python">nutrients = []

for rec in db:
    fnuts = pd.DataFrame(rec["nutrients"])
    fnuts["id"] = rec["id"]
    nutrients.append(fnuts)

nutrients = pd.concat(nutrients, ignore_index=True)
nutrients</code></pre> 
<p> 创建一个空列表。定义一个函数为每个记录创建一个包含营养信息的DataFrame对象，添加一个名为"id"的列，将记录的id值赋给该列的每个元素，并将每个记录的营养信息DataFrame添加到nutrients列表中， 将nutrients列表中的DataFrame对象合并为一个大的DataFrame，并重新索引行号。</p> 
<p><img alt="" height="449" src="https://images2.imgbox.com/d1/27/H44pcHNW_o.png" width="677"></p> 
<pre><code>nutrients.duplicated().sum()  # number of duplicates
nutrients = nutrients.drop_duplicates()</code></pre> 
<p>计算duplicates的总值，并将其赋值给nutrients。</p> 
<pre><code>col_mapping = {"description" : "food",
               "group"       : "fgroup"}
info = info.rename(columns=col_mapping, copy=False)
info.info()
col_mapping = {"description" : "nutrient",
               "group" : "nutgroup"}
nutrients = nutrients.rename(columns=col_mapping, copy=False)
nutrients</code></pre> 
<p>定义一个字典，里面有两个键值对。将其重命名为info，并输出。定义另一个字典，将其重命名为nutrients并输出。</p> 
<p><img alt="" height="682" src="https://images2.imgbox.com/5c/bc/Y7ViKXZR_o.png" width="696"></p> 
<pre><code>ndata = pd.merge(nutrients, info, on="id")
ndata.info()
ndata.iloc[30000]</code></pre> 
<p> 合并nutrients和info，并读取第30000行数据</p> 
<p><img alt="" height="553" src="https://images2.imgbox.com/ad/d1/xPNYC218_o.png" width="609"></p> 
<pre><code>fig = plt.figure()
result = ndata.groupby(["nutrient", "fgroup"])["value"].quantile(0.5)
result["Zinc, Zn"].sort_values().plot(kind="barh")</code></pre> 
<p>以nutrient和fgroup分组，并排序绘制柱状图。</p> 
<p><img alt="" height="633" src="https://images2.imgbox.com/24/55/UKCGNWf3_o.png" width="1200"></p> 
<pre><code>by_nutrient = ndata.groupby(["nutgroup", "nutrient"])

def get_maximum(x):
    return x.loc[x.value.idxmax()]

max_foods = by_nutrient.apply(get_maximum)[["value", "food"]]

# make the food a little smaller
max_foods["food"] = max_foods["food"].str[:50]
max_foods.loc["Amino Acids"]["food"]</code></pre> 
<p> 根据nutgroup和nutrient分组，并定义一个求最大值得函数，对value和food求最大值，对最大food读取前50行，读取Amino Acids行数据。</p> 
<p><img alt="" height="468" src="https://images2.imgbox.com/5d/69/9o4zNuBZ_o.png" width="739"></p> 
<p></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/939dfd0c99c85a4143f33840213c1704/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">超详细MySQL下载及安装、基本使用</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/589e03bf9c102407ab6cb7858db79e75/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Redis—分布式系统</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程学习者.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>