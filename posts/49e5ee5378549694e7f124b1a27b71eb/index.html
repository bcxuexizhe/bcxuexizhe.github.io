<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>【Python】科研代码学习：十四 wandb (可视化AI工具) - 编程学习者</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcxuexizhe.github.io/posts/49e5ee5378549694e7f124b1a27b71eb/">
  <meta property="og:site_name" content="编程学习者">
  <meta property="og:title" content="【Python】科研代码学习：十四 wandb (可视化AI工具)">
  <meta property="og:description" content="【Python】科研代码学习：十四 wandb[可视化AI工具] wandb 介绍注册账号使用 `HF Trainer` &#43; `wandb` 训练低级 API wandb 介绍 【wandb官网】
wandb 是 Weights &amp; Biases 的缩写（w and b）核心作用： 可视化重要参数云端存储提供各种工具可以和其他工具配合使用，比如下面的 pytorch, HF transformers, tensorflow, keras 等等
可以在里面使用 matplotlib貌似是 tensorboard 的上位替代 注册账号 首先我们需要去官网注册账号，貌似不能使用vpn
注册号后，按照教程创建一个团队，然后来到这个界面
可以按照这个 Quickstart 的样例走一下。选择 Track Runs，接下来可以选择使用哪个工具训练的模型
然后需要 pip install wandb 导包，以及 wandb login 登录
使用 HF Trainer &#43; wandb 训练 我们调用官方给的样例
我们发现其实新添了这几个内容：
WANDB_PROJECT 环境变量：项目名
WANDB_LOG_MODEL 环境变量：是否保存中继到wandb
WANDB_WATCH环境变量在 TrainingArguments 中，设置了 report_to=&#34;wandb&#34;
最后调用 wandb.finish() ，整体变化不大 # This script needs these libraries to be installed: # numpy, transformers, datasets import wandb import os import numpy as np from datasets import load_dataset from transformers import TrainingArguments, Trainer from transformers import AutoTokenizer, AutoModelForSequenceClassification # 设置GPU编号 os.">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-03-15T18:09:59+08:00">
    <meta property="article:modified_time" content="2024-03-15T18:09:59+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程学习者" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程学习者</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">【Python】科研代码学习：十四 wandb (可视化AI工具)</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-tomorrow-night">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>【Python】科研代码学习：十四 wandb[可视化AI工具]</h4> 
 <ul><li><a href="#wandb__1" rel="nofollow">wandb 介绍</a></li><li><a href="#_12" rel="nofollow">注册账号</a></li><li><a href="#_HF_Trainer__wandb__18" rel="nofollow">使用 `HF Trainer` + `wandb` 训练</a></li><li><a href="#_API_118" rel="nofollow">低级 API</a></li></ul> 
</div> 
<p></p> 
<h2><a id="wandb__1"></a>wandb 介绍</h2> 
<ul><li><a href="https://wandb.ai/site" rel="nofollow">【wandb官网】</a><br> <code>wandb</code> 是 <code>Weights &amp; Biases</code> 的缩写（w and b）</li><li>核心作用： 
  <ul><li>可视化重要参数</li><li>云端存储</li><li>提供各种工具</li><li>可以和其他工具配合使用，比如下面的 <code>pytorch, HF transformers, tensorflow, keras</code> 等等<br> <img src="https://images2.imgbox.com/61/d6/CiYKbL4Y_o.png" alt="在这里插入图片描述"></li></ul> </li><li>可以在里面使用 <code>matplotlib</code></li><li>貌似是 <code>tensorboard</code> 的上位替代</li></ul> 
<h2><a id="_12"></a>注册账号</h2> 
<ul><li>首先我们需要去官网注册账号，貌似不能使用vpn<br> 注册号后，按照教程创建一个团队，然后来到这个界面<br> 可以按照这个 <code>Quickstart</code> 的样例走一下。选择 <code>Track Runs</code>，接下来可以选择使用哪个工具训练的模型<br> 然后需要 <code>pip install wandb</code> 导包，以及 <code>wandb login</code> 登录<br> <img src="https://images2.imgbox.com/ab/2f/eiOnnfcp_o.png" alt="在这里插入图片描述"></li></ul> 
<h2><a id="_HF_Trainer__wandb__18"></a>使用 <code>HF Trainer</code> + <code>wandb</code> 训练</h2> 
<ul><li>我们调用官方给的样例<br> 我们发现其实新添了这几个内容：<br> <code>WANDB_PROJECT</code> 环境变量：项目名<br> <code>WANDB_LOG_MODEL</code> 环境变量：是否保存中继到wandb<br> <code>WANDB_WATCH</code>环境变量</li><li>在 <code>TrainingArguments</code> 中，设置了 <code>report_to="wandb"</code><br> 最后调用 <code>wandb.finish()</code> ，整体变化不大</li></ul> 
<pre><code class="prism language-py"><span class="token comment"># This script needs these libraries to be installed: </span>
<span class="token comment">#   numpy, transformers, datasets</span>

<span class="token keyword">import</span> wandb 

<span class="token keyword">import</span> os
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">from</span> datasets <span class="token keyword">import</span> load_dataset
<span class="token keyword">from</span> transformers <span class="token keyword">import</span> TrainingArguments<span class="token punctuation">,</span> Trainer
<span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoTokenizer<span class="token punctuation">,</span> AutoModelForSequenceClassification

<span class="token comment"># 设置GPU编号</span>
os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">"CUDA_DEVICE_ORDER"</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">"PCI_BUS_ID"</span>
os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">"CUDA_VISIBLE_DEVICES"</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">"1,2"</span>

<span class="token keyword">def</span> <span class="token function">tokenize_function</span><span class="token punctuation">(</span>examples<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> tokenizer<span class="token punctuation">(</span>examples<span class="token punctuation">[</span><span class="token string">"text"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">"max_length"</span><span class="token punctuation">,</span> truncation<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">compute_metrics</span><span class="token punctuation">(</span>eval_pred<span class="token punctuation">)</span><span class="token punctuation">:</span>
    logits<span class="token punctuation">,</span> labels <span class="token operator">=</span> eval_pred
    predictions <span class="token operator">=</span> np<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>logits<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> <span class="token punctuation">{<!-- --></span><span class="token string">"accuracy"</span><span class="token punctuation">:</span> np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>predictions <span class="token operator">==</span> labels<span class="token punctuation">)</span><span class="token punctuation">}</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Loading Dataset"</span><span class="token punctuation">)</span>
<span class="token comment"># download prepare the data</span>
dataset <span class="token operator">=</span> load_dataset<span class="token punctuation">(</span><span class="token string">"yelp_review_full"</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Loading Tokenizer"</span><span class="token punctuation">)</span>

tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"distilbert-base-uncased"</span><span class="token punctuation">)</span>

small_train_dataset <span class="token operator">=</span> dataset<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shuffle<span class="token punctuation">(</span>seed<span class="token operator">=</span><span class="token number">42</span><span class="token punctuation">)</span><span class="token punctuation">.</span>select<span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
small_eval_dataset <span class="token operator">=</span> dataset<span class="token punctuation">[</span><span class="token string">"test"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shuffle<span class="token punctuation">(</span>seed<span class="token operator">=</span><span class="token number">42</span><span class="token punctuation">)</span><span class="token punctuation">.</span>select<span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">300</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

small_train_dataset <span class="token operator">=</span> small_train_dataset<span class="token punctuation">.</span><span class="token builtin">map</span><span class="token punctuation">(</span>tokenize_function<span class="token punctuation">,</span> batched<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
small_eval_dataset <span class="token operator">=</span> small_train_dataset<span class="token punctuation">.</span><span class="token builtin">map</span><span class="token punctuation">(</span>tokenize_function<span class="token punctuation">,</span> batched<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Loading Model"</span><span class="token punctuation">)</span>

<span class="token comment"># download the model</span>
model <span class="token operator">=</span> AutoModelForSequenceClassification<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"distilbert-base-uncased"</span><span class="token punctuation">,</span> num_labels<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span>

<span class="token comment"># set the wandb project where this run will be logged</span>
os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">"WANDB_PROJECT"</span><span class="token punctuation">]</span><span class="token operator">=</span><span class="token string">"my-awesome-project"</span>

<span class="token comment"># save your trained model checkpoint to wandb</span>
os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">"WANDB_LOG_MODEL"</span><span class="token punctuation">]</span><span class="token operator">=</span><span class="token string">"true"</span>

<span class="token comment"># turn off watch to log faster</span>
os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">"WANDB_WATCH"</span><span class="token punctuation">]</span><span class="token operator">=</span><span class="token string">"false"</span>

<span class="token comment"># pass "wandb" to the 'report_to' parameter to turn on wandb logging</span>
training_args <span class="token operator">=</span> TrainingArguments<span class="token punctuation">(</span>
    output_dir<span class="token operator">=</span><span class="token string">'models'</span><span class="token punctuation">,</span>
    report_to<span class="token operator">=</span><span class="token string">"wandb"</span><span class="token punctuation">,</span>
    logging_steps<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> 
    per_device_train_batch_size<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>
    per_device_eval_batch_size<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>
    evaluation_strategy<span class="token operator">=</span><span class="token string">"steps"</span><span class="token punctuation">,</span>
    eval_steps<span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">,</span>
    max_steps <span class="token operator">=</span> <span class="token number">100</span><span class="token punctuation">,</span>
    save_steps <span class="token operator">=</span> <span class="token number">100</span>
<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Loading Trainer"</span><span class="token punctuation">)</span>

<span class="token comment"># define the trainer and start training</span>
trainer <span class="token operator">=</span> Trainer<span class="token punctuation">(</span>
    model<span class="token operator">=</span>model<span class="token punctuation">,</span>
    args<span class="token operator">=</span>training_args<span class="token punctuation">,</span>
    train_dataset<span class="token operator">=</span>small_train_dataset<span class="token punctuation">,</span>
    eval_dataset<span class="token operator">=</span>small_eval_dataset<span class="token punctuation">,</span>
    compute_metrics<span class="token operator">=</span>compute_metrics<span class="token punctuation">,</span>
<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Training"</span><span class="token punctuation">)</span>

trainer<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># [optional] finish the wandb run, necessary in notebooks</span>
wandb<span class="token punctuation">.</span>finish<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<ul><li>在 wandb 网站中<br> 我们可以打开该 project。每一次运行相当于一次 <code>run</code>，我这里跑了三次所以就有三条线。<br> 这里主要是看 <code>eval</code> 验证集和 <code>train</code> 训练集的一些参数。<br> <img src="https://images2.imgbox.com/0d/bf/Q5nQHajk_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/4b/c0/t5rRzj6w_o.png" alt="在这里插入图片描述"></li><li>我们可以删掉不关心的面板，或者增添一个想看的面板<br> 但如果两个参数的值域变化比较大的话，在一个图里面比较难看清，所以比较相关的参数才建议放在一个图里。<br> <img src="https://images2.imgbox.com/9f/c9/ZWhCTzTS_o.png" alt="在这里插入图片描述"></li></ul> 
<h2><a id="_API_118"></a>低级 API</h2> 
<ul><li>这上面是封装比较高级的 API，一般我们也都配合 <code>transformers</code> 库去用<br> 如果想用比较原生的 API，一般用法如下：<br> 首先调用 <code>wandb.init()</code> 方法<br> 然后使用 <code>wandb.log(dict)</code> 输出你要可视化的参数即可。</li></ul> 
<pre><code class="prism language-py"><span class="token comment"># train.py</span>
<span class="token keyword">import</span> wandb
<span class="token keyword">import</span> random  <span class="token comment"># for demo script</span>

wandb<span class="token punctuation">.</span>login<span class="token punctuation">(</span><span class="token punctuation">)</span>

epochs <span class="token operator">=</span> <span class="token number">10</span>
lr <span class="token operator">=</span> <span class="token number">0.01</span>

run <span class="token operator">=</span> wandb<span class="token punctuation">.</span>init<span class="token punctuation">(</span>
    <span class="token comment"># Set the project where this run will be logged</span>
    project<span class="token operator">=</span><span class="token string">"my-awesome-project"</span><span class="token punctuation">,</span>
    <span class="token comment"># Track hyperparameters and run metadata</span>
    config<span class="token operator">=</span><span class="token punctuation">{<!-- --></span>
        <span class="token string">"learning_rate"</span><span class="token punctuation">:</span> lr<span class="token punctuation">,</span>
        <span class="token string">"epochs"</span><span class="token punctuation">:</span> epochs<span class="token punctuation">,</span>
    <span class="token punctuation">}</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>

offset <span class="token operator">=</span> random<span class="token punctuation">.</span>random<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">5</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"lr: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>lr<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>

<span class="token comment"># simulating a training run</span>
<span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
    acc <span class="token operator">=</span> <span class="token number">1</span> <span class="token operator">-</span> <span class="token number">2</span><span class="token operator">**</span><span class="token operator">-</span>epoch <span class="token operator">-</span> random<span class="token punctuation">.</span>random<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">/</span> epoch <span class="token operator">-</span> offset
    loss <span class="token operator">=</span> <span class="token number">2</span><span class="token operator">**</span><span class="token operator">-</span>epoch <span class="token operator">+</span> random<span class="token punctuation">.</span>random<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">/</span> epoch <span class="token operator">+</span> offset
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"epoch=</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>epoch<span class="token punctuation">}</span></span><span class="token string">, accuracy=</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>acc<span class="token punctuation">}</span></span><span class="token string">, loss=</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>loss<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
    wandb<span class="token punctuation">.</span>log<span class="token punctuation">(</span><span class="token punctuation">{<!-- --></span><span class="token string">"accuracy"</span><span class="token punctuation">:</span> acc<span class="token punctuation">,</span> <span class="token string">"loss"</span><span class="token punctuation">:</span> loss<span class="token punctuation">}</span><span class="token punctuation">)</span>

<span class="token comment"># run.log_code()</span>
</code></pre>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/9d5fe8b502ecbfd4d248ee3c7231894a/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">python：消息推送 - 飞书机器人推送 - 富文本格式</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/12c8827e2e9281c5e1748351c5b3c291/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">2024年前端前景怎么样？零基础学前端还来的及吗？</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程学习者.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>