<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>StableDiffusion XL 1.0 SDXL 使用方法(填坑) - 编程学习者</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcxuexizhe.github.io/posts/efda3ef8945f06c6c16defc5114cfe64/">
  <meta property="og:site_name" content="编程学习者">
  <meta property="og:title" content="StableDiffusion XL 1.0 SDXL 使用方法(填坑)">
  <meta property="og:description" content="SDXL的安装方法，可以参考我的另一篇文章 “矿卡40HX上跑stable Diffusion XL 1.0模型的方法” 目前已实现在8G VRAM的情况下，使用超过1024x1024的画面生成。
1. 下载
StableDiffusion XL的二个模型，分别是base与refiner, 很多介绍中对二个模型的用法没解释清楚，其实这二个模型，都可以单独生成图片，Base更注重模型的内容生成，refiner更注重细节的补充。所以官方建议是先跑base再跑refiner.
你可以从huggingface上下载官方（stabilityai) 提供的模型。
sd_xl_base_1.0_0.9vae.safetensors &lt;------这是1.0base的vae修正版, 放入models目录下的Stable-diffusion目录中。
sd_xl_refiner_1.0_0.9vae.safetensors &lt;-----这是1.0refiner的vae修正版， 放入models目录下的Stable-diffusion目录中。
sdxl_vae.safetensors &lt;---这个是专用的vae， 放入models目录下的vae目录中。
2. 分辨率选择
SDXL模型是用1024x1024的样本进行训练的，所以最好从1024x1024起步生成。也有其它几种分辨率可以选择：
21:9 – 1536 x 64016:9 – 1344 x 7683:2 – 1216 x 8325:4 – 1152 x 8961:1 – 1024 x 1024 官方说法是除了这几种分辨率外，其它的分辨率会增加破图的可能性（事实上1024x1024破图的概率也比较大）
3. 取样器选择
取样器默认用Euler a就可以了，uniPC是绝对不行的，现在取样器实在太多选择了，个别不能用，个别破图，我也没一个个试过，自行测试吧。
4. 采样迭代步数
Euler a采样器的情况下，base用10步，refiner用20步，基本够用了
5. 图片生成过程
a, 文生图状态下，直接用base模型生成图片
b, 可以加vae生成图片, 如果到这步觉得满意了，后面可以忽略。
c, 文生图完成后（可以不加vae, 个人觉得意义不大），直接转到图生图
d, 改图生图的模型为refiner模型(这步是关键)
e, 加上vae, 然后生成图片。">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2023-08-08T18:17:31+08:00">
    <meta property="article:modified_time" content="2023-08-08T18:17:31+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程学习者" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程学习者</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">StableDiffusion XL 1.0 SDXL 使用方法(填坑)</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p>SDXL的安装方法，可以参考我的另一篇文章 “矿卡40HX上跑stable Diffusion XL 1.0模型的方法” 目前已实现在8G VRAM的情况下，使用超过1024x1024的画面生成。</p> 
<p>1. 下载</p> 
<p>    StableDiffusion XL的二个模型，分别是base与refiner, 很多介绍中对二个模型的用法没解释清楚，其实这二个模型，都可以单独生成图片，Base更注重模型的内容生成，refiner更注重细节的补充。所以官方建议是先跑base再跑refiner.</p> 
<p>     你可以从huggingface上下载官方（stabilityai) 提供的模型。</p> 
<p>        sd_xl_base_1.0_0.9vae.safetensors  &lt;------这是1.0base的vae修正版,  放入models目录下的Stable-diffusion目录中。</p> 
<p>        sd_xl_refiner_1.0_0.9vae.safetensors &lt;-----这是1.0refiner的vae修正版， 放入models目录下的Stable-diffusion目录中。</p> 
<p>        sdxl_vae.safetensors &lt;---这个是专用的vae，  放入models目录下的vae目录中。</p> 
<p>2. 分辨率选择</p> 
<p>    SDXL模型是用1024x1024的样本进行训练的，所以最好从1024x1024起步生成。也有其它几种分辨率可以选择：</p> 
<ul><li>21:9 – 1536 x 640</li><li>16:9 – 1344 x 768</li><li>3:2 – 1216 x 832</li><li>5:4 – 1152 x 896</li><li>1:1 – 1024 x 1024</li></ul> 
<p>    官方说法是除了这几种分辨率外，其它的分辨率会增加破图的可能性（事实上1024x1024破图的概率也比较大）</p> 
<p>3. 取样器选择</p> 
<p>    取样器默认用Euler a就可以了，uniPC是绝对不行的，现在取样器实在太多选择了，个别不能用，个别破图，我也没一个个试过，自行测试吧。</p> 
<p>4. 采样迭代步数</p> 
<p>    Euler a采样器的情况下，base用10步，refiner用20步，基本够用了</p> 
<p>5. 图片生成过程</p> 
<p>    a, 文生图状态下，直接用base模型生成图片</p> 
<p>    b, 可以加vae生成图片, 如果到这步觉得满意了，后面可以忽略。</p> 
<p>    c, 文生图完成后（可以不加vae, 个人觉得意义不大），直接转到图生图</p> 
<p>    d, 改图生图的模型为refiner模型(这步是关键)</p> 
<p>    e, 加上vae, 然后生成图片。</p> 
<p></p> 
<p></p> 
<p></p> 
<p></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/fcc2417623f46ca45fb5ce6bc0987bf2/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">【git】Git 回退到指定版本：</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/f21eb8cc231c7778c5c01c0618a8f4aa/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Kafka——管理Kafka(命令行工具)详解</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程学习者.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>