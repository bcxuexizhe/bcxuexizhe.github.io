<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>实战whisper语音识别第一天，部署服务器，可远程访问，实时语音转文字（全部代码和详细部署步骤） - 编程学习者</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcxuexizhe.github.io/posts/c5a4940c8f3d6284e458c55ca7aafb99/">
  <meta property="og:site_name" content="编程学习者">
  <meta property="og:title" content="实战whisper语音识别第一天，部署服务器，可远程访问，实时语音转文字（全部代码和详细部署步骤）">
  <meta property="og:description" content="Whisper是OpenAI于2022年发布的一个开源深度学习模型，专门用于语音识别任务。它能够将音频转换成文字，支持多种语言的识别，包括但不限于英语、中文、西班牙语等。Whisper模型的特点是它在多种不同的音频条件下（如不同的背景噪声水平、说话者的口音、语速等）都能实现高准确率的语音识别，这得益于它在训练过程中使用的大量多样化的音频数据。
Whisper模型使用了一系列先进的深度学习技术和架构，主要包括：
自注意力机制（Self-Attention）：Whisper模型中使用了自注意力机制，特别是变种形式的Transformer架构，这在处理序列数据（如音频）中尤其有效。端到端学习：Whisper采用端到端的训练方式，直接从原始音频数据学习到文本输出，无需人工提取特征。大规模数据集训练：它是在广泛的数据集上进行训练的，包括各种语言、口音和音频质量，这有助于提高模型的泛化能力和鲁棒性。 Whisper的开发和发布对于语音识别和人工智能领域有着重要的意义：
提高语音识别的准确率：Whisper在多种测试集上显示出优越的性能，尤其是在噪声环境下和非英语语言的识别上。多语言支持：Whisper的多语言识别能力对于打破语言障碍、促进全球信息的交流和共享具有重要作用。开源共享：作为一个开源项目，Whisper为研究人员和开发者提供了一个强大的工具，可以在此基础上进一步开发定制化的语音识别应用，促进了技术的创新和应用的多样化。推动人工智能技术的发展：通过对Whisper模型的研究和应用，可以进一步推动相关领域，如自然语言处理、机器学习等领域的技术进步。 pip install -U openai-whisper pip install git&#43;https://github.com/openai/whisper.git # on Ubuntu or Debian sudo apt update &amp;&amp; sudo apt install ffmpeg # on Arch Linux sudo pacman -S ffmpeg # on MacOS using Homebrew (https://brew.sh/) brew install ffmpeg # on Windows using Chocolatey (https://chocolatey.org/) choco install ffmpeg # on Windows using Scoop (https://scoop.sh/) scoop install ffmpeg pip install setuptools-rust 运行：
whisper 5.wav --language Chinese python代码： import whisper model = whisper.">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-03-21T17:25:53+08:00">
    <meta property="article:modified_time" content="2024-03-21T17:25:53+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程学习者" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程学习者</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">实战whisper语音识别第一天，部署服务器，可远程访问，实时语音转文字（全部代码和详细部署步骤）</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p>Whisper是OpenAI于2022年发布的一个开源深度学习模型，专门用于语音识别任务。它能够将音频转换成文字，支持多种语言的识别，包括但不限于英语、中文、西班牙语等。Whisper模型的特点是它在多种不同的音频条件下（如不同的背景噪声水平、说话者的口音、语速等）都能实现高准确率的语音识别，这得益于它在训练过程中使用的大量多样化的音频数据。</p> 
<p>Whisper模型使用了一系列先进的深度学习技术和架构，主要包括：</p> 
<ul><li><strong>自注意力机制（Self-Attention）</strong>：Whisper模型中使用了自注意力机制，特别是变种形式的Transformer架构，这在处理序列数据（如音频）中尤其有效。</li><li><strong>端到端学习</strong>：Whisper采用端到端的训练方式，直接从原始音频数据学习到文本输出，无需人工提取特征。</li><li><strong>大规模数据集训练</strong>：它是在广泛的数据集上进行训练的，包括各种语言、口音和音频质量，这有助于提高模型的泛化能力和鲁棒性。</li></ul> 
<p>Whisper的开发和发布对于语音识别和人工智能领域有着重要的意义：</p> 
<ul><li><strong>提高语音识别的准确率</strong>：Whisper在多种测试集上显示出优越的性能，尤其是在噪声环境下和非英语语言的识别上。</li><li><strong>多语言支持</strong>：Whisper的多语言识别能力对于打破语言障碍、促进全球信息的交流和共享具有重要作用。</li><li><strong>开源共享</strong>：作为一个开源项目，Whisper为研究人员和开发者提供了一个强大的工具，可以在此基础上进一步开发定制化的语音识别应用，促进了技术的创新和应用的多样化。</li><li><strong>推动人工智能技术的发展</strong>：通过对Whisper模型的研究和应用，可以进一步推动相关领域，如自然语言处理、机器学习等领域的技术进步。</li></ul> 
<p></p> 
<pre><code>pip install -U openai-whisper

pip install git+https://github.com/openai/whisper.git 

# on Ubuntu or Debian
sudo apt update &amp;&amp; sudo apt install ffmpeg

# on Arch Linux
sudo pacman -S ffmpeg

# on MacOS using Homebrew (https://brew.sh/)
brew install ffmpeg

# on Windows using Chocolatey (https://chocolatey.org/)
choco install ffmpeg

# on Windows using Scoop (https://scoop.sh/)
scoop install ffmpeg

pip install setuptools-rust</code></pre> 
<p>运行：</p> 
<pre><code>whisper 5.wav --language Chinese</code></pre> 
<p>python代码： </p> 
<pre><code>import whisper

model = whisper.load_model("base")
result = model.transcribe("audio.mp3")
print(result["text"])</code></pre> 
<p>部署api服务：</p> 
<p>繁体变简体：</p> 
<pre><code>pip install opencc-python-reimplemented
</code></pre> 
<pre><code>from fastapi import FastAPI, File, UploadFile
from whisper import load_model
import asyncio
import uvicorn
from opencc import OpenCC

app = FastAPI()
model = load_model("small")  # 加载模型

@app.post("/transcribe/")
async def transcribe_audio(file: UploadFile = File(...)):
    contents = await file.read()
    with open("temp_audio.mp3", "wb") as f:  # 临时保存上传的音频文件
        f.write(contents)

    # 调用Whisper模型进行语音识别
    result = model.transcribe("temp_audio.mp3")
    text = result["text"]

    # 将繁体字转换为简体字
    cc = OpenCC('t2s')  # 繁体转简体
    simplified_text = cc.convert(text)

    return {"text": simplified_text}

if __name__ == "__main__":
    uvicorn.run("whisper_api:app", host="0.0.0.0", port=8000, reload=True)
</code></pre> 
<p style="text-align:center;"></p> 
<p><img alt="" height="512" src="https://images2.imgbox.com/d0/8c/Y0bJMDND_o.png" width="847"></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/929249167de18fab10ed2d7b79120de3/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">人工智能在心理健康评估和干预中的应用</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/c9ecbcc99866c0ef127d6a3061a52541/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Hive自定义GenericUDF函数</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程学习者.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>