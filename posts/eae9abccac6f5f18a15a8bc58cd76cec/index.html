<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>【LLama】Llama3 的本地部署与lora微调(基于xturn) - 编程学习者</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcxuexizhe.github.io/posts/eae9abccac6f5f18a15a8bc58cd76cec/">
  <meta property="og:site_name" content="编程学习者">
  <meta property="og:title" content="【LLama】Llama3 的本地部署与lora微调(基于xturn)">
  <meta property="og:description" content="系列课程代码&#43;文档（前2节课可跳过）：https://github.com/SmartFlowAI/Llama3-Tutorial
课程视频：https://space.bilibili.com/3546636263360696/channel/series
XTuner ：https://github.com/InternLM/xtuner/blob/main/README_zh-CN.md
一、Llama 3 本地部署（Nidia3090显卡） 教程所提供的在线显卡只有8G, 微调和推理时一般是16-20G，所以本地部署。
下载llama3模型 # 如果下面命令报错则使用 apt install git git-lfs -y conda install git-lfs git-lfs install git clone https://code.openxlab.org.cn/MrCat/Llama-3-8B-Instruct.git Meta-Llama-3-8B-Instruct 下载在本地后的内容
本地环境 conda create -n llama3-xtuner python=3.10 -y conda activate llama3-xtuner conda install pytorch==2.1.2 torchvision==0.16.2 torchaudio==2.1.2 pytorch-cuda=12.1 -c pytorch -c nvidia 其他依赖 git clone https://github.com/InternLM/xtuner.git cd xtuner conda activate llama3-xtuner pip install -e . 运行llama3-instruct Llama3-Tutorial-main
streamlit run ~/code/Llama3-Tutorial-main/tools/internstudio_web_demo.py \ ~/code/Meta-Llama-3-8B-Instruct 二、 使用Xturn微调llama3 （1条数据） 主要参考：https://github.">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-05-06T18:20:52+08:00">
    <meta property="article:modified_time" content="2024-05-06T18:20:52+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程学习者" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程学习者</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">【LLama】Llama3 的本地部署与lora微调(基于xturn)</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p>系列课程<strong>代码+文档（前2节课可跳过）</strong>：<a href="https://github.com/SmartFlowAI/Llama3-Tutorial">https://github.com/SmartFlowAI/Llama3-Tutorial</a><br> 课程<strong>视频</strong>：<a href="https://space.bilibili.com/3546636263360696/channel/series" rel="nofollow">https://space.bilibili.com/3546636263360696/channel/series</a><br> <strong>XTuner</strong> ：<a href="https://github.com/InternLM/xtuner/blob/main/README_zh-CN.md">https://github.com/InternLM/xtuner/blob/main/README_zh-CN.md</a></p> 
<h2><a id="Llama_3__Nidia3090_4"></a>一、Llama 3 本地部署（Nidia3090显卡）</h2> 
<p>教程所提供的在线显卡只有8G, 微调和推理时一般是16-20G，所以本地部署。</p> 
<h3><a id="llama3_7"></a>下载llama3模型</h3> 
<pre><code class="prism language-bash"><span class="token comment"># 如果下面命令报错则使用 apt install git git-lfs -y</span>
conda <span class="token function">install</span> git-lfs
git-lfs <span class="token function">install</span>
<span class="token function">git</span> clone https://code.openxlab.org.cn/MrCat/Llama-3-8B-Instruct.git Meta-Llama-3-8B-Instruct
</code></pre> 
<p>下载在本地后的内容<br> <img src="https://images2.imgbox.com/8b/da/N3lzDfGL_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="_20"></a>本地环境</h3> 
<pre><code class="prism language-bash">conda create <span class="token parameter variable">-n</span> llama3-xtuner <span class="token assign-left variable">python</span><span class="token operator">=</span><span class="token number">3.10</span> <span class="token parameter variable">-y</span>
conda activate llama3-xtuner
conda <span class="token function">install</span> <span class="token assign-left variable">pytorch</span><span class="token operator">==</span><span class="token number">2.1</span>.2 <span class="token assign-left variable">torchvision</span><span class="token operator">==</span><span class="token number">0.16</span>.2 <span class="token assign-left variable">torchaudio</span><span class="token operator">==</span><span class="token number">2.1</span>.2 pytorch-cuda<span class="token operator">=</span><span class="token number">12.1</span> <span class="token parameter variable">-c</span> pytorch <span class="token parameter variable">-c</span> nvidia

</code></pre> 
<h4><a id="_27"></a>其他依赖</h4> 
<pre><code class="prism language-bash"><span class="token function">git</span> clone https://github.com/InternLM/xtuner.git
<span class="token builtin class-name">cd</span> xtuner
conda activate llama3-xtuner
pip <span class="token function">install</span> <span class="token parameter variable">-e</span> <span class="token builtin class-name">.</span>
</code></pre> 
<h3><a id="llama3instruct_38"></a>运行llama3-instruct</h3> 
<p>Llama3-Tutorial-main</p> 
<pre><code class="prism language-bash">streamlit run ~/code/Llama3-Tutorial-main/tools/internstudio_web_demo.py <span class="token punctuation">\</span>
  ~/code/Meta-Llama-3-8B-Instruct
</code></pre> 
<p><img src="https://images2.imgbox.com/75/a1/PsNNFtes_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="_Xturnllama3_1_47"></a>二、 使用Xturn微调llama3 （1条数据）</h2> 
<p>主要参考：<a href="https://github.com/SmartFlowAI/Llama3-Tutorial/blob/main/docs/assistant.md">https://github.com/SmartFlowAI/Llama3-Tutorial/blob/main/docs/assistant.md</a></p> 
<h3><a id="21__49"></a>2.1 生成训练数据</h3> 
<p>重复次数 n = 2按需要修改，跑流程时可以很小，原始设置是2000<br> 改为自己的名字：<br> name = ‘曾小蛙’<br> author=“星艺AI”</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> json

<span class="token comment"># 输入你的名字</span>
name <span class="token operator">=</span> <span class="token string">'曾小蛙'</span>
author<span class="token operator">=</span><span class="token string">"星艺AI"</span>
<span class="token comment"># 重复次数</span>
n <span class="token operator">=</span> <span class="token number">2</span>

data <span class="token operator">=</span> <span class="token punctuation">[</span>
    <span class="token punctuation">{<!-- --></span>
        <span class="token string">"conversation"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span>
            <span class="token punctuation">{<!-- --></span>
                <span class="token string">"system"</span><span class="token punctuation">:</span><span class="token string">"你是一个懂中文的小助手"</span><span class="token punctuation">,</span>
                <span class="token string">"input"</span><span class="token punctuation">:</span> <span class="token string">"你是（请用中文回答）"</span><span class="token punctuation">,</span>
                <span class="token string">"output"</span><span class="token punctuation">:</span> <span class="token string">"您好，我是{}，一个由 {} 打造的人工智能助手，请问有什么可以帮助您的吗？"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>name<span class="token punctuation">,</span> author<span class="token punctuation">)</span>

               
            <span class="token punctuation">}</span>
        <span class="token punctuation">]</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">]</span>

<span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>n<span class="token punctuation">)</span><span class="token punctuation">:</span>
    data<span class="token punctuation">.</span>append<span class="token punctuation">(</span>data<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">'data/personal_assistant.json'</span><span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
    json<span class="token punctuation">.</span>dump<span class="token punctuation">(</span>data<span class="token punctuation">,</span> f<span class="token punctuation">,</span> ensure_ascii<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> indent<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">)</span>

</code></pre> 
<h4><a id="json_84"></a>生成的训练用的json</h4> 
<p><img src="https://images2.imgbox.com/53/cf/SPeJZnxb_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="22__87"></a>2.2 修改训练脚本</h3> 
<p>Llama3-Tutorial/configs/assistant/llama3_8b_instruct_qlora_assistant.py</p> 
<p><img src="https://images2.imgbox.com/aa/29/lPRlMXNh_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="23__95"></a>2.3 开始训练</h3> 
<pre><code class="prism language-bash">xtuner train configs/assistant/llama3_8b_instruct_qlora_assistant.py
</code></pre> 
<p>保存的结果<br> <img src="https://images2.imgbox.com/89/f4/8Kr1jqwp_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="24_Adapter_PTH__HF__103"></a>2.4 Adapter PTH 转 HF 格式</h3> 
<pre><code class="prism language-bash">xtuner convert pth_to_hf ~/code/Llama3-Tutorial-main/work_dirs/llama3_8b_instruct_qlora_assistant/llama3_8b_instruct_qlora_assistant.py <span class="token punctuation">\</span>
  ~/code/Llama3-Tutorial-main/work_dirs/llama3_8b_instruct_qlora_assistant/iter_20.pth <span class="token punctuation">\</span>
  ~/code/Llama3-Tutorial-main/work_dirs/llama3_hf_adapter
</code></pre> 
<p><img src="https://images2.imgbox.com/82/65/0QHU9Icr_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="25_lorallama3_113"></a>2.5 合并lora到llama3中</h3> 
<p>记得将模型换为自己的路径·<br> 本文使用相对路径，llama3的模型与教程代码在</p> 
<pre><code class="prism language-bash"><span class="token builtin class-name">export</span> <span class="token assign-left variable">MKL_SERVICE_FORCE_INTEL</span><span class="token operator">=</span><span class="token number">1</span>
xtuner convert merge ./Meta-Llama-3-8B-Instruct <span class="token punctuation">\</span>
  ./Llama3-Tutorial-main/work_dirs/llama3_hf_adapter<span class="token punctuation">\</span>
  ./Llama3-Tutorial-main/work_dirs/llama3_hf_merged
</code></pre> 
<p><img src="https://images2.imgbox.com/36/05/YeYbdJ1j_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="26____123"></a>2.6 推理微调后的模型 （过拟合，还需要重新调参数）</h3> 
<p>Llama3-Tutorial-main是手动下载的</p> 
<pre><code class="prism language-bash">streamlit run ./Llama3-Tutorial-main/tools/internstudio_web_demo.py <span class="token punctuation">\</span>
  ./Llama3-Tutorial-main/work_dirs//llama3_hf_merged
</code></pre> 
<p><img src="https://images2.imgbox.com/db/f4/6sZCjAhf_o.png" alt="在这里插入图片描述"></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/5294cd99c6df32e380f6baecdc9d2827/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">2024年前端最全vue项目首页优化问题（前后端都要优化），web前端开发面试技巧</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/367fbfe437b454add8cb4d018e009d95/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Spring IoC&amp;DI（1）—入门</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程学习者.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>