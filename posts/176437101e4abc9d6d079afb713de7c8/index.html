<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>使用LM Studio与Anything LLM基于Llama-3高效构建本地知识库系统 - 编程学习者</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcxuexizhe.github.io/posts/176437101e4abc9d6d079afb713de7c8/">
  <meta property="og:site_name" content="编程学习者">
  <meta property="og:title" content="使用LM Studio与Anything LLM基于Llama-3高效构建本地知识库系统">
  <meta property="og:description" content="本文详细介绍了如何使用LM Studio和Anything LLM工具来构建和部署本地知识库。文中首先解释了安装和配置大模型的步骤，随后展示了如何将模型部署为后台服务，并通过API进行调用。此外，文章还涉及了如何使用这些工具快速构建知识库应用，包括知识库的配置和问答系统的设置。整个过程强调了无需深厚编程知识即可实现快速部署和使用，适合业务专家和产品设计人员使用。
业务背景 最近一直在寻找一套最佳的基于大模型的知识库系统解决方案，需要具有如下能力：
能够快速将大型模型进行本地化的部署使用。
结合大语言模型，能有一套良好的知识库系统，方便使用。
针对业务专家和产品设计人员，即使不懂代码，也能快速构建产品原型，了解基于大型模型知识体系的构建过程，并能选型大语言模型。
针对算法人员，“套壳”大模型或微调大模型，可通过一款工具完成本地化的快速部署和分发，而不需要自己单独写一个服务。
针对开发人员，可将算法开发好的模型快速构建成后台服务，且为OpenAI标准的服务API，能让开发团队快速进行大型模型的接入测试和验证。
针对测试人员，可以在构建的大型模型和知识库问答应用中进行快速测试，并跟踪各个环节的结果，如embedding的召回结果是否覆盖所有知识点，可通过接口调用日志进行快速查看。
针对甲方的企业要快速验证知识库项目的可行性，可以使用这两个工具搭建本地的测试环境。这样可以对一些关键技术进行全流程化的跟踪调试，待验证没有问题再进行立项或系统的集成。
最终选择了LM studio &#43; Anything LLM搭建本地知识库。
LM Studio安装部署及使用 安装 LM Studio是一款桌面软件，安装后，经过简单的配置即可使用。登录https://lmstudio.ai/ 即可看到如下界面，按自己的操作系统进行下载即可。
​
安装完成之后，登录系统的主界面如下图所，可以看到其默认界面如下：
​
安装完成！！！
下载和管理大模型 在LMs studio的首页即提供了大模型列表及搜索能力，可以从hugging Face上获取支持的大模型列表，并可以通过搜索获取关注的大模型。如下图搜索最近也比较火的Mistral：
​
点击“download”可以将想要的大模型下载到本地磁盘中。
​
查看下载进度条
​
2. 点击My models图标，即可查看本地下载的大模型列表，在这里我本身下载了4个大模型（LLama-3、LLama-3 chinese、gemma，刚刚下载的mistral）、一个embedding Model（据说是一个比较好的embedding算法），还有一个是自己通过LLama-3套壳的本地模型：
​
AI chat 下载了模型之后，就来验证一下这个模型能否正常使用，进入AI chat界面：
​
是选择模型，选择我们刚下载的mistral，左侧可以显示该模型在执行时的内存及cpu占用情况。
是针对该模型的聊天历史
是针对该模型进行对话时的参数配置，这里我们默认即可
是聊天的主交互界面。
以下是Mistral模型回答的结果，问题都理解出错了：
​
换成最近超火的LLama 3:8b之后结果还是不错的：
​
​
将大模型部署为后台服务 点击“local server“，进入服务配置界面：
​
选择做为后台服务的大语言模型，在这里选择llama3
embedding算法，这里选择了一个社区比较推荐的nomic-ai-nomic embed text算法
配置做为后台服务的端口，并启动server
针对python在不同的场景下的示例代码
服务器的logs界面，每一次api的调用日志在这里都可以看得到，方便进行问题排查，还有就是embedding算法返回结果是否召回的验证非常有帮助，方便算法和测试人员进行模型测试和调优使用。
用Anything LLM快速构建知识库应用 Anything LLM有两个版本，一是桌面安装版本，另一是通过Docker进行部署的版本。我选择安装桌面版，有兴趣的同学可以研究一下Docker版本，它增加了用户权限管理功能，并可以进行企业级应用部署。它是开源的，可以在真正的生产环境中使用Anything LLM作为知识库的后台系统，并开放API供前端业务系统集成。">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-04-27T16:27:36+08:00">
    <meta property="article:modified_time" content="2024-04-27T16:27:36+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程学习者" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程学习者</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">使用LM Studio与Anything LLM基于Llama-3高效构建本地知识库系统</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p>本文详细介绍了如何使用LM Studio和Anything LLM工具来构建和部署本地知识库。文中首先解释了安装和配置大模型的步骤，随后展示了如何将模型部署为后台服务，并通过API进行调用。此外，文章还涉及了如何使用这些工具快速构建知识库应用，包括知识库的配置和问答系统的设置。整个过程强调了无需深厚编程知识即可实现快速部署和使用，适合业务专家和产品设计人员使用。</p> 
<h2><strong>业务背景</strong></h2> 
<p>最近一直在寻找一套最佳的基于大模型的知识库系统解决方案，需要具有如下能力：</p> 
<ol><li> <p>能够快速将大型模型进行本地化的部署使用。</p> </li><li> <p>结合大语言模型，能有一套良好的知识库系统，方便使用。</p> </li><li> <p>针对业务专家和产品设计人员，即使不懂代码，也能快速构建产品原型，了解基于大型模型知识体系的构建过程，并能选型大语言模型。</p> </li><li> <p>针对算法人员，“套壳”大模型或微调大模型，可通过一款工具完成本地化的快速部署和分发，而不需要自己单独写一个服务。</p> </li><li> <p>针对开发人员，可将算法开发好的模型快速构建成后台服务，且为OpenAI标准的服务API，能让开发团队快速进行大型模型的接入测试和验证。</p> </li><li> <p>针对测试人员，可以在构建的大型模型和知识库问答应用中进行快速测试，并跟踪各个环节的结果，如embedding的召回结果是否覆盖所有知识点，可通过接口调用日志进行快速查看。</p> </li><li> <p>针对甲方的企业要快速验证知识库项目的可行性，可以使用这两个工具搭建本地的测试环境。这样可以对一些关键技术进行全流程化的跟踪调试，待验证没有问题再进行立项或系统的集成。</p> </li></ol> 
<p>最终选择了LM studio + Anything LLM搭建本地知识库。</p> 
<h2><strong>LM Studio安装部署及使用</strong></h2> 
<h3><strong>安装</strong></h3> 
<p>LM Studio是一款桌面软件，安装后，经过简单的配置即可使用。登录https://lmstudio.ai/ 即可看到如下界面，按自己的操作系统进行下载即可。</p> 
<p></p> 
<div> 
 <p class="img-center"><img alt="图片" height="447" src="https://images2.imgbox.com/c4/73/RsPqN2po_o.png" width="1080"><span title="点击并拖拽以改变尺寸">​</span></p> 
</div> 
<p>安装完成之后，登录系统的主界面如下图所，可以看到其默认界面如下：</p> 
<p></p> 
<div> 
 <p class="img-center"><img alt="图片" height="801" src="https://images2.imgbox.com/52/70/1qAdtBmV_o.png" width="1080"><span title="点击并拖拽以改变尺寸">​</span></p> 
</div> 
<p></p> 
<p>安装完成！！！</p> 
<h3><strong>下载和管理大模型</strong></h3> 
<p>在LMs studio的首页即提供了大模型列表及搜索能力，可以从hugging Face上获取支持的大模型列表，并可以通过搜索获取关注的大模型。如下图搜索最近也比较火的Mistral：</p> 
<p></p> 
<div> 
 <p class="img-center"><img alt="图片" height="738" src="https://images2.imgbox.com/0c/31/GLcS0aU3_o.png" width="1080"><span title="点击并拖拽以改变尺寸">​</span></p> 
</div> 
<ol><li> <p>点击“download”可以将想要的大模型下载到本地磁盘中。</p> </li></ol> 
<p></p> 
<div> 
 <p class="img-center"><img alt="图片" height="715" src="https://images2.imgbox.com/6a/d1/03tOh3Fy_o.png" width="1080"><span title="点击并拖拽以改变尺寸">​</span></p> 
</div> 
<p>查看下载进度条</p> 
<p></p> 
<div> 
 <p class="img-center"><img alt="图片" height="262" src="https://images2.imgbox.com/cc/d6/JU84Xufe_o.png" width="1080"><span title="点击并拖拽以改变尺寸">​</span></p> 
</div> 
<p>2. 点击My models图标，即可查看本地下载的大模型列表，在这里我本身下载了4个大模型（LLama-3、LLama-3 chinese、gemma，刚刚下载的mistral）、一个embedding Model（据说是一个比较好的embedding算法），还有一个是自己通过LLama-3套壳的本地模型：</p> 
<p></p> 
<div> 
 <p class="img-center"><img alt="图片" height="439" src="https://images2.imgbox.com/e7/14/OrCwg8M3_o.png" width="1080"><span title="点击并拖拽以改变尺寸">​</span></p> 
</div> 
<h3><strong>AI chat</strong></h3> 
<p>下载了模型之后，就来验证一下这个模型能否正常使用，进入AI chat界面：</p> 
<p></p> 
<div> 
 <p class="img-center"><img alt="图片" height="729" src="https://images2.imgbox.com/9f/06/G7iZ6kfV_o.png" width="1080"><span title="点击并拖拽以改变尺寸">​</span></p> 
</div> 
<ol><li> <p>是选择模型，选择我们刚下载的mistral，左侧可以显示该模型在执行时的内存及cpu占用情况。</p> </li><li> <p>是针对该模型的聊天历史</p> </li><li> <p>是针对该模型进行对话时的参数配置，这里我们默认即可</p> </li><li> <p>是聊天的主交互界面。</p> </li></ol> 
<p>以下是Mistral模型回答的结果，问题都理解出错了：</p> 
<p></p> 
<div> 
 <p class="img-center"><img alt="图片" height="760" src="https://images2.imgbox.com/4c/82/uPOjASvi_o.png" width="1080"><span title="点击并拖拽以改变尺寸">​</span></p> 
</div> 
<p>换成最近超火的LLama 3:8b之后结果还是不错的：</p> 
<p></p> 
<div> 
 <p class="img-center"><img alt="图片" height="709" src="https://images2.imgbox.com/d3/17/eHdXmo1y_o.png" width="1080"><span title="点击并拖拽以改变尺寸">​</span></p> 
</div> 
<p></p> 
<div> 
 <p class="img-center"><img alt="图片" height="969" src="https://images2.imgbox.com/cd/aa/ckGx2dHo_o.png" width="1080"><span title="点击并拖拽以改变尺寸">​</span></p> 
</div> 
<h3><strong>将大模型部署为后台服务</strong></h3> 
<p>点击“local server“，进入服务配置界面：</p> 
<p></p> 
<div> 
 <p class="img-center"><img alt="图片" height="741" src="https://images2.imgbox.com/76/0a/DydDFisr_o.png" width="1080"><span title="点击并拖拽以改变尺寸">​</span></p> 
</div> 
<ol><li> <p>选择做为后台服务的大语言模型，在这里选择llama3</p> </li><li> <p>embedding算法，这里选择了一个社区比较推荐的nomic-ai-nomic embed text算法</p> </li><li> <p>配置做为后台服务的端口，并启动server</p> </li><li> <p>针对python在不同的场景下的示例代码</p> </li><li> <p>服务器的logs界面，每一次api的调用日志在这里都可以看得到，方便进行问题排查，还有就是embedding算法返回结果是否召回的验证非常有帮助，方便算法和测试人员进行模型测试和调优使用。</p> </li></ol> 
<h2><strong>用Anything LLM快速构建知识库应用</strong></h2> 
<p>Anything LLM有两个版本，一是桌面安装版本，另一是通过Docker进行部署的版本。我选择安装桌面版，有兴趣的同学可以研究一下Docker版本，它增加了用户权限管理功能，并可以进行企业级应用部署。它是开源的，可以在真正的生产环境中使用Anything LLM作为知识库的后台系统，并开放API供前端业务系统集成。</p> 
<h3><strong>安装</strong></h3> 
<p>登录网站https://useanything.com/download 并选择适用自己的版本：</p> 
<p></p> 
<div> 
 <p class="img-center"><img alt="图片" height="687" src="https://images2.imgbox.com/44/ae/CxiVmtKy_o.png" width="1080"><span title="点击并拖拽以改变尺寸">​</span></p> 
</div> 
<p>下载到本地后直接像普通软件一样安装即可，由于本地已经完成了安装，在此就不再进行安装了。</p> 
<p>安装完成之后，有三个比较重要的配置：</p> 
<ol><li> <p>配置大模型：</p> 
  <ol><li> <p>推荐使用LM Studio，因为他还是比较方便调试的。在这里输入LMStudio后台服务的URL,选择模型和token的大小</p> <img alt="图片" height="719" src="https://images2.imgbox.com/70/1b/lvvGjFFx_o.png" width="1080"><span title="点击并拖拽以改变尺寸">​</span>2. 另外，也可以选择openai或AnythingLLM，如果选择AnythingLLM，如下图所示，列表了其支持的大语言模型，选择了对应的模型点击“save changes“时，在后台会下载对应的大模型到本地。因此，AnythingLLM也可以自行体系独立运行。<img alt="图片" height="745" src="https://images2.imgbox.com/03/8a/TZVyYkwn_o.png" width="1080"><span title="点击并拖拽以改变尺寸">​</span></li></ol></li><li> <p>配置embedding模型（用于对语言档切分和向量数据库中知识内容的相似性判断并召回，该算法的好坏，直接影响大模型的推理结果），在这里也可以有多种选择，我选择使用LMStudio中的nomic-edmbed-text-v1.5，如下图所示：</p> <p></p> <p></p> 
  <div> 
   <p class="img-center"><img alt="图片" height="435" src="https://images2.imgbox.com/75/d9/5yVo22hK_o.png" width="1080"><span title="点击并拖拽以改变尺寸">​</span></p> 
  </div> </li><li> <p>向量数据库：在这里我选择了一个轻量级的LanceDB，如下图所示：</p> <p></p> 
  <div> 
   <p class="img-center"><img alt="图片" height="537" src="https://images2.imgbox.com/1d/42/ikHgmKkU_o.png" width="1080"><span title="点击并拖拽以改变尺寸">​</span></p> 
  </div> </li></ol> 
<h3></h3> 
<h3 style="background-color:transparent;"><strong>配置知识库</strong></h3> 
<p>返回主界面之后，默认如下图所示，没有任何应用：需要我们创建一个新的workspace。</p> 
<p></p> 
<div> 
 <p class="img-center"><img alt="图片" height="733" src="https://images2.imgbox.com/8b/35/Lnk5vi80_o.png" width="1080"><span title="点击并拖拽以改变尺寸">​</span></p> 
</div> 
<p>需要我们创建一个新的workspace，点击“new workspace”之后，创建一个新的worksapce：</p> 
<p></p> 
<div> 
 <p class="img-center"><img alt="图片" height="659" src="https://images2.imgbox.com/48/ba/aZJCdkZj_o.png" width="1080"><span title="点击并拖拽以改变尺寸">​</span></p> 
</div> 
<p>针对新创建的itops工作区，需要为其增加知识库的内容，我手动创建了一份markdown格式的应急预案文档，文包括大致内容如下：</p> 
<p></p> 
<div> 
 <p class="img-center"><img alt="图片" height="997" src="https://images2.imgbox.com/90/03/8gggI2gE_o.png" width="1080"><span title="点击并拖拽以改变尺寸">​</span></p> 
</div> 
<p>在AnythingLLM界面点击上传按钮，可以将本地的文件或来自某一个网站的站点内容进行抓取，并当成知识库的内容。</p> 
<p>点击上传本地的文件：</p> 
<p></p> 
<div> 
 <p class="img-center"><img alt="图片" height="595" src="https://images2.imgbox.com/7d/d6/LSS45u3U_o.png" width="1080"><span title="点击并拖拽以改变尺寸">​</span></p> 
</div> 
<p>上传后由于要对文件进行切分操作，在之前的配置中，我们配置了embedding算法使用的是LM Studio推荐的nomic-ai-nomic embed text算法，因此会直接调用LM Studio的后台服务对文档进行切分，如下图为后台日志：</p> 
<p></p> 
<div> 
 <p class="img-center"><img alt="图片" height="891" src="https://images2.imgbox.com/5e/c8/uqtFHXmt_o.png" width="1080"><span title="点击并拖拽以改变尺寸">​</span></p> 
</div> 
<p>至此知识库配置完成，下面将使用智能问答系统。</p> 
<h3><strong>知识问答</strong></h3> 
<p>现在我们来问“数据库异常锁表故障”，看下结果如何：</p> 
<ul><li> <p>首先，当我输入这个问题之后，第一件要做的事件就是调用LM Studio后台提供的API，这时会在Server Logs的控制台界面，看到调用过程，以及从知识库中召回的相关知识点：</p> <p></p> <p></p> <p></p> 
  <div> 
   <p class="img-center"><img alt="图片" height="405" src="https://images2.imgbox.com/83/3c/MFSjSWgW_o.png" width="1080"><span title="点击并拖拽以改变尺寸">​</span></p> 
  </div> </li><li> <p>当获取了这些召回的知识时，LM Studio的大语言模型（这里用的llama 3）就会执行推理的结果返回给Anything LLM，结果如下：</p> <p></p> <p></p> 
  <div> 
   <p class="img-center"><img alt="图片" height="470" src="https://images2.imgbox.com/04/c2/w9ONHQRi_o.png" width="1080"><span title="点击并拖拽以改变尺寸">​</span></p> 
  </div> <p>对比一下知识内容的原文，效果还是非常不错的，原文如下：</p> <p></p> <p></p> 
  <div> 
   <p class="img-center"><img alt="图片" height="528" src="https://images2.imgbox.com/6a/4b/2hnW7L2h_o.png" width="1080"><span title="点击并拖拽以改变尺寸">​</span></p> 
  </div> </li></ul> 
<p></p> 
<p></p> 
<p>至此，大型模型的知识库系统已经搭建完毕，并已完成从知识构建到知识问答结果展示的整个过程。</p> 
<p>下一步，我们将对问答的结果进行评估，并优化问答系统的结果，以使其在生产上得以应用。</p> 
<p>敬请期待！</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/7ea648647bcf98658f12bbf7cfa728f1/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">23种设计模式学习导航（Java完整版）</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/abacef97399d67a1ca1a0be2629342bb/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">spring boot3登录开发-微信小程序用户登录设计与实现</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程学习者.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>