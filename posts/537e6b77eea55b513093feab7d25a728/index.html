<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>OpenCV与AI深度学习 | 实战 | YOLOv8自定义数据集训练实现手势识别 (标注&#43;训练&#43;预测 保姆级教程) - 编程学习者</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcxuexizhe.github.io/posts/537e6b77eea55b513093feab7d25a728/">
  <meta property="og:site_name" content="编程学习者">
  <meta property="og:title" content="OpenCV与AI深度学习 | 实战 | YOLOv8自定义数据集训练实现手势识别 (标注&#43;训练&#43;预测 保姆级教程)">
  <meta property="og:description" content="本文来源公众号“OpenCV与AI深度学习”，仅用于学术分享，侵权删，干货满满。
原文链接：实战 | YOLOv8自定义数据集训练实现手势识别 (标注&#43;训练&#43;预测 保姆级教程)
0 导 读 本文将手把手教你用YoloV8训练自己的数据集并实现手势识别。
1 安装环境 【1】安装torch, torchvision对应版本，这里先下载好，直接安装
pip install torch-1.13.1&#43;cu116-cp38-cp38-win_amd64.whl pip install torchvision-0.14.1&#43;cu116-cp38-cp38-win_amd64.whl 安装好后可以查看是否安装成功，上面安装的gpu版本，查看指令与结果：
import torch print(torch.__version__) print(torch.cuda.is_available()) 【2】安装ultralytics
pip install ultralytics 【3】下载YoloV8预训练模型：GitHub - ultralytics/ultralytics: NEW - YOLOv8 🚀 in PyTorch &gt; ONNX &gt; OpenVINO &gt; CoreML &gt; TFLite
本文使用YOLOv8n，直接下载第一个即可
【4】运行demo测试安装是否成功：
from ultralytics import YOLO # Load a model model = YOLO(&#39;yolov8n.pt&#39;) # pretrained YOLOv8n model # Run batched inference on a list of images results = model([&#39;1.">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-04-02T17:54:55+08:00">
    <meta property="article:modified_time" content="2024-04-02T17:54:55+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程学习者" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程学习者</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">OpenCV与AI深度学习 | 实战 | YOLOv8自定义数据集训练实现手势识别 (标注&#43;训练&#43;预测 保姆级教程)</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p>本文来源公众号<strong>“OpenCV与AI深度学习”</strong>，仅用于学术分享，侵权删，干货满满。</p> 
<p>原文链接：<a href="https://mp.weixin.qq.com/s/0eArsPfpqftjyqdh1M9p9g" rel="nofollow" title="实战 | YOLOv8自定义数据集训练实现手势识别 (标注+训练+预测 保姆级教程)">实战 | YOLOv8自定义数据集训练实现手势识别 (标注+训练+预测 保姆级教程)</a></p> 
<h2>0 导  读</h2> 
<p>    本文将手把手教你用YoloV8训练自己的数据集并实现手势识别。</p> 
<h2 style="background-color:transparent;"><strong>1 安装环境</strong></h2> 
<p><img alt="" height="431" src="https://images2.imgbox.com/9a/96/5EU7qByf_o.png" width="1043"></p> 
<p><strong>【1】安装torch, torchvision对应版本，这里先下载好，直接安装</strong></p> 
<pre><code class="language-bash">pip install torch-1.13.1+cu116-cp38-cp38-win_amd64.whl
pip install torchvision-0.14.1+cu116-cp38-cp38-win_amd64.whl</code></pre> 
<p><img alt="" height="188" src="https://images2.imgbox.com/f9/ee/rIxCcKtM_o.png" width="1018"></p> 
<p>安装好后可以查看是否安装成功，上面安装的gpu版本，查看指令与结果：</p> 
<pre><code class="language-python">import torch
print(torch.__version__)
print(torch.cuda.is_available())</code></pre> 
<p><strong>【2】安装<strong>ultralytics</strong></strong></p> 
<pre><code class="language-bash">pip install ultralytics</code></pre> 
<p><strong>【3】下载YoloV8预训练模型：</strong><a href="https://github.com/ultralytics/ultralytics" title="GitHub - ultralytics/ultralytics: NEW - YOLOv8 🚀 in PyTorch &gt; ONNX &gt; OpenVINO &gt; CoreML &gt; TFLite">GitHub - ultralytics/ultralytics: NEW - YOLOv8 🚀 in PyTorch &gt; ONNX &gt; OpenVINO &gt; CoreML &gt; TFLite</a></p> 
<p><img alt="" height="489" src="https://images2.imgbox.com/97/31/sKHdduZJ_o.png" width="1033"></p> 
<p>本文使用YOLOv8n，直接下载第一个即可</p> 
<p><img alt="" height="60" src="https://images2.imgbox.com/e6/35/brQQj5nl_o.png" width="1030"></p> 
<p><strong><strong>【4】运行demo测试安装是否成功：</strong></strong></p> 
<pre><code class="language-python">from ultralytics import YOLO
# Load a model
model = YOLO('yolov8n.pt')  # pretrained YOLOv8n model

# Run batched inference on a list of images
results = model(['1.jpg', '2.jpg'])  # return a list of Results objects

# Process results list
for result in results:
    boxes = result.boxes  # Boxes object for bounding box outputs
    masks = result.masks  # Masks object for segmentation masks outputs
    keypoints = result.keypoints  # Keypoints object for pose outputs
    probs = result.probs  # Probs object for classification outputs
    result.show()  # display to screen
    result.save(filename='result.jpg')  # save to disk</code></pre> 
<p><img alt="" height="666" src="https://images2.imgbox.com/a3/fd/cHtbVbLG_o.png" width="953"></p> 
<p><img alt="" height="88" src="https://images2.imgbox.com/96/a5/l9T0hR1A_o.png" width="1041"></p> 
<h2>2 <strong>标注/制作数据集</strong></h2> 
<p><strong>【1】准备好待标注图片</strong></p> 
<p>    可以自己写一个从摄像头存图的脚本保存一下<strong>不同手势图</strong>到本地，这里提供一个供参考：</p> 
<pre><code class="language-python"># -*- coding: utf-8 -*-
import cv2

cap = cv2.VideoCapture(0)
flag = 0

if(cap.isOpened()): #视频打开成功
  flag = 1
else:
  flag = 0
  print('open cam failed!')

if(flag==1):
  while(True):
    cv2.namedWindow("frame")
    ret,frame = cap.read()#读取一帧
    if ret==False: #读取帧失败
      break
    cv2.imshow("frame", frame)
    if cv2.waitKey(50)&amp;0xFF ==27: #按下Esc键退出
      cv2.imwrite("1.jpg",frame)
      break

cap.release()
cv2.destroyAllWindows()</code></pre> 
<p>本文使用共3种手势<strong>1，2，5</strong>，三种手势各300张，大家可以根据实际情况增减样本数量。</p> 
<p><img alt="" height="548" src="https://images2.imgbox.com/64/e1/RBXmFMtU_o.png" width="992"></p> 
<p><strong>【2】标注样本</strong></p> 
<p>    标注工具使用labelimg即可，直接pip安装：</p> 
<pre><code>pip install labelimg -i https://pypi.tuna.tsinghua.edu.cn/simple</code></pre> 
<p><img alt="" height="534" src="https://images2.imgbox.com/03/05/fskYFGqJ_o.png" width="1042"></p> 
<p>安装完成后，命令行直接输入<span style="color:#fe2c24;">labelimg</span>，回车即可打开labelimg，数据集类型切换成YOLO，然后依次完成标注即可。</p> 
<p><img alt="" height="625" src="https://images2.imgbox.com/aa/5d/mNf5yPka_o.png" width="989"></p> 
<p><strong>【3】标注划分</strong></p> 
<p>    标注好之后，使用下面的脚本划分训练集、验证集，注意设置正确的图片和txt路径：</p> 
<pre><code class="language-python">
# -*- coding: utf-8 -*-

import os
import random
import shutil

# 设置文件路径和划分比例
root_path = "./voc_yolo/"
image_dir = "./JPEGImages/"
label_dir = "./Annotations/"
train_ratio = 0.7
val_ratio = 0.2
test_ratio = 0.1

# 创建训练集、验证集和测试集目录
os.makedirs("images/train", exist_ok=True)
os.makedirs("images/val", exist_ok=True)
os.makedirs("images/test", exist_ok=True)
os.makedirs("labels/train", exist_ok=True)
os.makedirs("labels/val", exist_ok=True)
os.makedirs("labels/test", exist_ok=True)

# 获取所有图像文件名
image_files = os.listdir(image_dir)
total_images = len(image_files)
random.shuffle(image_files)

# 计算划分数量
train_count = int(total_images * train_ratio)
val_count = int(total_images * val_ratio)
test_count = total_images - train_count - val_count

# 划分训练集
train_images = image_files[:train_count]
for image_file in train_images:
    label_file = image_file[:image_file.rfind(".")] + ".txt"
    shutil.copy(os.path.join(image_dir, image_file), "images/train/")
    shutil.copy(os.path.join(label_dir, label_file), "labels/train/")

# 划分验证集
val_images = image_files[train_count:train_count+val_count]
for image_file in val_images:
    label_file = image_file[:image_file.rfind(".")] + ".txt"
    shutil.copy(os.path.join(image_dir, image_file), "images/val/")
    shutil.copy(os.path.join(label_dir, label_file), "labels/val/")

# 划分测试集
test_images = image_files[train_count+val_count:]
for image_file in test_images:
    label_file = image_file[:image_file.rfind(".")] + ".txt"
    shutil.copy(os.path.join(image_dir, image_file), "images/test/")
    shutil.copy(os.path.join(label_dir, label_file), "labels/test/")

# 生成训练集图片路径txt文件
with open("train.txt", "w") as file:
    file.write("\n".join([root_path + "images/train/" + image_file for image_file in train_images]))

# 生成验证集图片路径txt文件
with open("val.txt", "w") as file:
    file.write("\n".join([root_path + "images/val/" + image_file for image_file in val_images]))

# 生成测试集图片路径txt文件
with open("test.txt", "w") as file:
    file.write("\n".join([root_path + "images/test/" + image_file for image_file in test_images]))

print("数据划分完成！")</code></pre> 
<p>接着会生成划分好的数据集如下：</p> 
<p class="img-center"><img alt="图片" height="260" src="https://images2.imgbox.com/ef/0c/XJcFvBTw_o.png" width="721"></p> 
<p>打开images文件夹：</p> 
<p class="img-center"><img alt="图片" height="283" src="https://images2.imgbox.com/f6/31/li7z0vNp_o.png" width="764"></p> 
<p>打开images下的train文件夹：</p> 
<p class="img-center"><img alt="图片" height="600" src="https://images2.imgbox.com/78/43/PnMMtmNl_o.png" width="964"></p> 
<p>打开labels下的train文件夹：</p> 
<p class="img-center"><img alt="图片" height="621" src="https://images2.imgbox.com/ef/ef/qTJBLMEB_o.png" width="916"></p> 
<h2>3 <strong>训练与预测</strong></h2> 
<p><strong>【1】开始训练</strong></p> 
<p>    训练脚本如下：</p> 
<pre><code class="language-python">from ultralytics import YOLO

# Load a model
model = YOLO('yolov8n.pt')  # load a pretrained model (recommended for training)

results = model.train(data='hand.yaml', epochs=30, imgsz=640, device=[0],
                      workers=0,lr0=0.001,batch=8,amp=False)</code></pre> 
<p>    <span style="color:#fe2c24;">hand.yaml</span>内容如下，注意修改自己的数据集路径即可：</p> 
<pre><code class="language-python"># Ultralytics YOLO 🚀, AGPL-3.0 license
# COCO8 dataset (first 8 images from COCO train2017) by Ultralytics
# Documentation: https://docs.ultralytics.com/datasets/detect/coco8/
# Example usage: yolo train data=coco8.yaml
# parent
# ├── ultralytics
# └── datasets
#     └── coco8  ← downloads here (1 MB)

# Train/val/test sets as 1) dir: path/to/imgs, 2) file: path/to/imgs.txt, or 3) list: [path/to/imgs1, path/to/imgs2, ..]
path: E:/Practice/DeepLearning/Yolo_Test/dataset/hand # dataset root dir
train: E:/Practice/DeepLearning/Yolo_Test/dataset/hand/images/train # train images (relative to 'path') 4 images
val: E:/Practice/DeepLearning/Yolo_Test/dataset/hand/images/val # val images (relative to 'path') 4 images
test: # test images (optional)

# Classes
names:
  0: hand-1
  1: hand-2
  2: hand-5


# Download script/URL (optional)
# download: https://ultralytics.com/assets/coco8.zip</code></pre> 
<p><img alt="" height="395" src="https://images2.imgbox.com/3a/ca/zQCUqodK_o.png" width="995"></p> 
<p>CPU训练将device=[0]改为device='cpu'即可</p> 
<p>训练完成后再runs/detect/train文件夹下生成如下内容：</p> 
<p><img alt="" height="926" src="https://images2.imgbox.com/7b/d5/Z87W4k2w_o.png" width="1200"></p> 
<p>    在weights文件夹下生成两个模型文件，直接使用best.pt即可。</p> 
<p><img alt="" height="334" src="https://images2.imgbox.com/89/24/nYLZbLeL_o.png" width="1051"></p> 
<p><strong>【2】预测推理</strong></p> 
<p>    预测脚本如下：</p> 
<pre><code class="language-python">from ultralytics import YOLO
# Load a model
model = YOLO('best.pt')  # pretrained YOLOv8n model

# Run batched inference on a list of images
results = model(['1 (1).jpg', '1 (2).jpg', '1 (3).jpg'])  # return a list of Results objects

# Process results list
for result in results:
    boxes = result.boxes  # Boxes object for bounding box outputs
    masks = result.masks  # Masks object for segmentation masks outputs
    keypoints = result.keypoints  # Keypoints object for pose outputs
    probs = result.probs  # Probs object for classification outputs
    result.show()  # display to screen
    result.save(filename='result.jpg')  # save to disk</code></pre> 
<p>    预测结果：</p> 
<p><img alt="" height="751" src="https://images2.imgbox.com/c5/a0/Ve6DThtd_o.png" width="993"></p> 
<p><img alt="" height="748" src="https://images2.imgbox.com/2c/a8/bPxw2jq9_o.png" width="990"></p> 
<p><img alt="" height="750" src="https://images2.imgbox.com/dc/76/8EyesIXx_o.png" width="993"></p> 
<p><strong><strong>—THE END—</strong></strong></p> 
<p>THE END!</p> 
<p>文章结束，感谢阅读。您的点赞，收藏，评论是我继续更新的动力。<strong>大家有推荐的公众号可以评论区留言，共同学习，一起进步。</strong></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/3c88f8554671a52934aceb2881bd1c3c/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">南京邮电大学数学实验MATLAB2023</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/4492afc67728daee796b4c9d8734e1ba/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">好书推荐 《AIGC重塑金融》</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程学习者.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>