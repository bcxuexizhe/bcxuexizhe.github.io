<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>OpenCVä¸AIæ·±åº¦å­¦ä¹  | å®æˆ˜ | YOLOv8è‡ªå®šä¹‰æ•°æ®é›†è®­ç»ƒå®ç°æ‰‹åŠ¿è¯†åˆ« (æ ‡æ³¨&#43;è®­ç»ƒ&#43;é¢„æµ‹ ä¿å§†çº§æ•™ç¨‹) - ç¼–ç¨‹å­¦ä¹ è€…</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcxuexizhe.github.io/posts/537e6b77eea55b513093feab7d25a728/">
  <meta property="og:site_name" content="ç¼–ç¨‹å­¦ä¹ è€…">
  <meta property="og:title" content="OpenCVä¸AIæ·±åº¦å­¦ä¹  | å®æˆ˜ | YOLOv8è‡ªå®šä¹‰æ•°æ®é›†è®­ç»ƒå®ç°æ‰‹åŠ¿è¯†åˆ« (æ ‡æ³¨&#43;è®­ç»ƒ&#43;é¢„æµ‹ ä¿å§†çº§æ•™ç¨‹)">
  <meta property="og:description" content="æœ¬æ–‡æ¥æºå…¬ä¼—å·â€œOpenCVä¸AIæ·±åº¦å­¦ä¹ â€ï¼Œä»…ç”¨äºå­¦æœ¯åˆ†äº«ï¼Œä¾µæƒåˆ ï¼Œå¹²è´§æ»¡æ»¡ã€‚
åŸæ–‡é“¾æ¥ï¼šå®æˆ˜ | YOLOv8è‡ªå®šä¹‰æ•°æ®é›†è®­ç»ƒå®ç°æ‰‹åŠ¿è¯†åˆ« (æ ‡æ³¨&#43;è®­ç»ƒ&#43;é¢„æµ‹ ä¿å§†çº§æ•™ç¨‹)
0 å¯¼Â è¯» æœ¬æ–‡å°†æ‰‹æŠŠæ‰‹æ•™ä½ ç”¨YoloV8è®­ç»ƒè‡ªå·±çš„æ•°æ®é›†å¹¶å®ç°æ‰‹åŠ¿è¯†åˆ«ã€‚
1 å®‰è£…ç¯å¢ƒ ã€1ã€‘å®‰è£…torch, torchvisionå¯¹åº”ç‰ˆæœ¬ï¼Œè¿™é‡Œå…ˆä¸‹è½½å¥½ï¼Œç›´æ¥å®‰è£…
pipÂ installÂ torch-1.13.1&#43;cu116-cp38-cp38-win_amd64.whl pip install torchvision-0.14.1&#43;cu116-cp38-cp38-win_amd64.whl å®‰è£…å¥½åå¯ä»¥æŸ¥çœ‹æ˜¯å¦å®‰è£…æˆåŠŸï¼Œä¸Šé¢å®‰è£…çš„gpuç‰ˆæœ¬ï¼ŒæŸ¥çœ‹æŒ‡ä»¤ä¸ç»“æœï¼š
importÂ torch print(torch.__version__) print(torch.cuda.is_available()) ã€2ã€‘å®‰è£…ultralytics
pip install ultralytics ã€3ã€‘ä¸‹è½½YoloV8é¢„è®­ç»ƒæ¨¡å‹ï¼šGitHub - ultralytics/ultralytics: NEW - YOLOv8 ğŸš€ in PyTorch &gt; ONNX &gt; OpenVINO &gt; CoreML &gt; TFLite
æœ¬æ–‡ä½¿ç”¨YOLOv8nï¼Œç›´æ¥ä¸‹è½½ç¬¬ä¸€ä¸ªå³å¯
ã€4ã€‘è¿è¡Œdemoæµ‹è¯•å®‰è£…æ˜¯å¦æˆåŠŸï¼š
from ultralytics import YOLO # Load a model model = YOLO(&#39;yolov8n.pt&#39;) # pretrained YOLOv8n model # Run batched inference on a list of images results = model([&#39;1.">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-04-02T17:54:55+08:00">
    <meta property="article:modified_time" content="2024-04-02T17:54:55+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="ç¼–ç¨‹å­¦ä¹ è€…" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">ç¼–ç¨‹å­¦ä¹ è€…</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">OpenCVä¸AIæ·±åº¦å­¦ä¹  | å®æˆ˜ | YOLOv8è‡ªå®šä¹‰æ•°æ®é›†è®­ç»ƒå®ç°æ‰‹åŠ¿è¯†åˆ« (æ ‡æ³¨&#43;è®­ç»ƒ&#43;é¢„æµ‹ ä¿å§†çº§æ•™ç¨‹)</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p>æœ¬æ–‡æ¥æºå…¬ä¼—å·<strong>â€œOpenCVä¸AIæ·±åº¦å­¦ä¹ â€</strong>ï¼Œä»…ç”¨äºå­¦æœ¯åˆ†äº«ï¼Œä¾µæƒåˆ ï¼Œå¹²è´§æ»¡æ»¡ã€‚</p> 
<p>åŸæ–‡é“¾æ¥ï¼š<a href="https://mp.weixin.qq.com/s/0eArsPfpqftjyqdh1M9p9g" rel="nofollow" title="å®æˆ˜ | YOLOv8è‡ªå®šä¹‰æ•°æ®é›†è®­ç»ƒå®ç°æ‰‹åŠ¿è¯†åˆ« (æ ‡æ³¨+è®­ç»ƒ+é¢„æµ‹ ä¿å§†çº§æ•™ç¨‹)">å®æˆ˜ | YOLOv8è‡ªå®šä¹‰æ•°æ®é›†è®­ç»ƒå®ç°æ‰‹åŠ¿è¯†åˆ« (æ ‡æ³¨+è®­ç»ƒ+é¢„æµ‹ ä¿å§†çº§æ•™ç¨‹)</a></p> 
<h2>0 å¯¼Â  è¯»</h2> 
<p>Â Â Â  æœ¬æ–‡å°†æ‰‹æŠŠæ‰‹æ•™ä½ ç”¨YoloV8è®­ç»ƒè‡ªå·±çš„æ•°æ®é›†å¹¶å®ç°æ‰‹åŠ¿è¯†åˆ«ã€‚</p> 
<h2 style="background-color:transparent;"><strong>1 å®‰è£…ç¯å¢ƒ</strong></h2> 
<p><img alt="" height="431" src="https://images2.imgbox.com/9a/96/5EU7qByf_o.png" width="1043"></p> 
<p><strong>ã€1ã€‘å®‰è£…torch, torchvisionå¯¹åº”ç‰ˆæœ¬ï¼Œè¿™é‡Œå…ˆä¸‹è½½å¥½ï¼Œç›´æ¥å®‰è£…</strong></p> 
<pre><code class="language-bash">pipÂ installÂ torch-1.13.1+cu116-cp38-cp38-win_amd64.whl
pip install torchvision-0.14.1+cu116-cp38-cp38-win_amd64.whl</code></pre> 
<p><img alt="" height="188" src="https://images2.imgbox.com/f9/ee/rIxCcKtM_o.png" width="1018"></p> 
<p>å®‰è£…å¥½åå¯ä»¥æŸ¥çœ‹æ˜¯å¦å®‰è£…æˆåŠŸï¼Œä¸Šé¢å®‰è£…çš„gpuç‰ˆæœ¬ï¼ŒæŸ¥çœ‹æŒ‡ä»¤ä¸ç»“æœï¼š</p> 
<pre><code class="language-python">importÂ torch
print(torch.__version__)
print(torch.cuda.is_available())</code></pre> 
<p><strong>ã€2ã€‘å®‰è£…<strong>ultralytics</strong></strong></p> 
<pre><code class="language-bash">pip install ultralytics</code></pre> 
<p><strong>ã€3ã€‘ä¸‹è½½YoloV8é¢„è®­ç»ƒæ¨¡å‹ï¼š</strong><a href="https://github.com/ultralytics/ultralytics" title="GitHub - ultralytics/ultralytics: NEW - YOLOv8 ğŸš€ in PyTorch &gt; ONNX &gt; OpenVINO &gt; CoreML &gt; TFLite">GitHub - ultralytics/ultralytics: NEW - YOLOv8 ğŸš€ in PyTorch &gt; ONNX &gt; OpenVINO &gt; CoreML &gt; TFLite</a></p> 
<p><img alt="" height="489" src="https://images2.imgbox.com/97/31/sKHdduZJ_o.png" width="1033"></p> 
<p>æœ¬æ–‡ä½¿ç”¨YOLOv8nï¼Œç›´æ¥ä¸‹è½½ç¬¬ä¸€ä¸ªå³å¯</p> 
<p><img alt="" height="60" src="https://images2.imgbox.com/e6/35/brQQj5nl_o.png" width="1030"></p> 
<p><strong><strong>ã€4ã€‘è¿è¡Œdemoæµ‹è¯•å®‰è£…æ˜¯å¦æˆåŠŸï¼š</strong></strong></p> 
<pre><code class="language-python">from ultralytics import YOLO
# Load a model
model = YOLO('yolov8n.pt')  # pretrained YOLOv8n model

# Run batched inference on a list of images
results = model(['1.jpg', '2.jpg'])  # return a list of Results objects

# Process results list
for result in results:
    boxes = result.boxes  # Boxes object for bounding box outputs
    masks = result.masks  # Masks object for segmentation masks outputs
    keypoints = result.keypoints  # Keypoints object for pose outputs
    probs = result.probs  # Probs object for classification outputs
    result.show()  # display to screen
    result.save(filename='result.jpg')  # save to disk</code></pre> 
<p><img alt="" height="666" src="https://images2.imgbox.com/a3/fd/cHtbVbLG_o.png" width="953"></p> 
<p><img alt="" height="88" src="https://images2.imgbox.com/96/a5/l9T0hR1A_o.png" width="1041"></p> 
<h2>2Â <strong>æ ‡æ³¨/åˆ¶ä½œæ•°æ®é›†</strong></h2> 
<p><strong>ã€1ã€‘å‡†å¤‡å¥½å¾…æ ‡æ³¨å›¾ç‰‡</strong></p> 
<p>Â  Â  å¯ä»¥è‡ªå·±å†™ä¸€ä¸ªä»æ‘„åƒå¤´å­˜å›¾çš„è„šæœ¬ä¿å­˜ä¸€ä¸‹<strong>ä¸åŒæ‰‹åŠ¿å›¾</strong>åˆ°æœ¬åœ°ï¼Œè¿™é‡Œæä¾›ä¸€ä¸ªä¾›å‚è€ƒï¼š</p> 
<pre><code class="language-python"># -*- coding: utf-8 -*-
import cv2

capÂ =Â cv2.VideoCapture(0)
flag = 0

if(cap.isOpened()): #è§†é¢‘æ‰“å¼€æˆåŠŸ
  flag = 1
else:
  flag = 0
  print('open cam failed!')

if(flag==1):
  while(True):
    cv2.namedWindow("frame")
    ret,frame = cap.read()#è¯»å–ä¸€å¸§
    if ret==False: #è¯»å–å¸§å¤±è´¥
      break
    cv2.imshow("frame", frame)
    if cv2.waitKey(50)&amp;0xFF ==27: #æŒ‰ä¸‹Escé”®é€€å‡º
      cv2.imwrite("1.jpg",frame)
      break

cap.release()
cv2.destroyAllWindows()</code></pre> 
<p>æœ¬æ–‡ä½¿ç”¨å…±3ç§æ‰‹åŠ¿<strong>1ï¼Œ2ï¼Œ5</strong>ï¼Œä¸‰ç§æ‰‹åŠ¿å„300å¼ ï¼Œå¤§å®¶å¯ä»¥æ ¹æ®å®é™…æƒ…å†µå¢å‡æ ·æœ¬æ•°é‡ã€‚</p> 
<p><img alt="" height="548" src="https://images2.imgbox.com/64/e1/RBXmFMtU_o.png" width="992"></p> 
<p><strong>ã€2ã€‘æ ‡æ³¨æ ·æœ¬</strong></p> 
<p>Â  Â  æ ‡æ³¨å·¥å…·ä½¿ç”¨labelimgå³å¯ï¼Œç›´æ¥pipå®‰è£…ï¼š</p> 
<pre><code>pip install labelimg -i https://pypi.tuna.tsinghua.edu.cn/simple</code></pre> 
<p><img alt="" height="534" src="https://images2.imgbox.com/03/05/fskYFGqJ_o.png" width="1042"></p> 
<p>å®‰è£…å®Œæˆåï¼Œå‘½ä»¤è¡Œç›´æ¥è¾“å…¥<span style="color:#fe2c24;">labelimg</span>ï¼Œå›è½¦å³å¯æ‰“å¼€labelimgï¼Œæ•°æ®é›†ç±»å‹åˆ‡æ¢æˆYOLOï¼Œç„¶åä¾æ¬¡å®Œæˆæ ‡æ³¨å³å¯ã€‚</p> 
<p><img alt="" height="625" src="https://images2.imgbox.com/aa/5d/mNf5yPka_o.png" width="989"></p> 
<p><strong>ã€3ã€‘æ ‡æ³¨åˆ’åˆ†</strong></p> 
<p>Â  Â  æ ‡æ³¨å¥½ä¹‹åï¼Œä½¿ç”¨ä¸‹é¢çš„è„šæœ¬åˆ’åˆ†è®­ç»ƒé›†ã€éªŒè¯é›†ï¼Œæ³¨æ„è®¾ç½®æ­£ç¡®çš„å›¾ç‰‡å’Œtxtè·¯å¾„ï¼š</p> 
<pre><code class="language-python">
# -*- coding: utf-8 -*-

import os
import random
import shutil

# è®¾ç½®æ–‡ä»¶è·¯å¾„å’Œåˆ’åˆ†æ¯”ä¾‹
root_path = "./voc_yolo/"
image_dir = "./JPEGImages/"
label_dir = "./Annotations/"
train_ratio = 0.7
val_ratio = 0.2
test_ratio = 0.1

# åˆ›å»ºè®­ç»ƒé›†ã€éªŒè¯é›†å’Œæµ‹è¯•é›†ç›®å½•
os.makedirs("images/train", exist_ok=True)
os.makedirs("images/val", exist_ok=True)
os.makedirs("images/test", exist_ok=True)
os.makedirs("labels/train", exist_ok=True)
os.makedirs("labels/val", exist_ok=True)
os.makedirs("labels/test", exist_ok=True)

# è·å–æ‰€æœ‰å›¾åƒæ–‡ä»¶å
image_files = os.listdir(image_dir)
total_images = len(image_files)
random.shuffle(image_files)

# è®¡ç®—åˆ’åˆ†æ•°é‡
train_count = int(total_images * train_ratio)
val_count = int(total_images * val_ratio)
test_count = total_images - train_count - val_count

# åˆ’åˆ†è®­ç»ƒé›†
train_images = image_files[:train_count]
for image_file in train_images:
    label_file = image_file[:image_file.rfind(".")] + ".txt"
    shutil.copy(os.path.join(image_dir, image_file), "images/train/")
    shutil.copy(os.path.join(label_dir, label_file), "labels/train/")

# åˆ’åˆ†éªŒè¯é›†
val_images = image_files[train_count:train_count+val_count]
for image_file in val_images:
    label_file = image_file[:image_file.rfind(".")] + ".txt"
    shutil.copy(os.path.join(image_dir, image_file), "images/val/")
    shutil.copy(os.path.join(label_dir, label_file), "labels/val/")

# åˆ’åˆ†æµ‹è¯•é›†
test_images = image_files[train_count+val_count:]
for image_file in test_images:
    label_file = image_file[:image_file.rfind(".")] + ".txt"
    shutil.copy(os.path.join(image_dir, image_file), "images/test/")
    shutil.copy(os.path.join(label_dir, label_file), "labels/test/")

# ç”Ÿæˆè®­ç»ƒé›†å›¾ç‰‡è·¯å¾„txtæ–‡ä»¶
with open("train.txt", "w") as file:
    file.write("\n".join([root_path + "images/train/" + image_file for image_file in train_images]))

# ç”ŸæˆéªŒè¯é›†å›¾ç‰‡è·¯å¾„txtæ–‡ä»¶
with open("val.txt", "w") as file:
    file.write("\n".join([root_path + "images/val/" + image_file for image_file in val_images]))

# ç”Ÿæˆæµ‹è¯•é›†å›¾ç‰‡è·¯å¾„txtæ–‡ä»¶
with open("test.txt", "w") as file:
    file.write("\n".join([root_path + "images/test/" + image_file for image_file in test_images]))

print("æ•°æ®åˆ’åˆ†å®Œæˆï¼")</code></pre> 
<p>æ¥ç€ä¼šç”Ÿæˆåˆ’åˆ†å¥½çš„æ•°æ®é›†å¦‚ä¸‹ï¼š</p> 
<p class="img-center"><img alt="å›¾ç‰‡" height="260" src="https://images2.imgbox.com/ef/0c/XJcFvBTw_o.png" width="721"></p> 
<p>æ‰“å¼€imagesæ–‡ä»¶å¤¹ï¼š</p> 
<p class="img-center"><img alt="å›¾ç‰‡" height="283" src="https://images2.imgbox.com/f6/31/li7z0vNp_o.png" width="764"></p> 
<p>æ‰“å¼€imagesä¸‹çš„trainæ–‡ä»¶å¤¹ï¼š</p> 
<p class="img-center"><img alt="å›¾ç‰‡" height="600" src="https://images2.imgbox.com/78/43/PnMMtmNl_o.png" width="964"></p> 
<p>æ‰“å¼€labelsä¸‹çš„trainæ–‡ä»¶å¤¹ï¼š</p> 
<p class="img-center"><img alt="å›¾ç‰‡" height="621" src="https://images2.imgbox.com/ef/ef/qTJBLMEB_o.png" width="916"></p> 
<h2>3Â <strong>è®­ç»ƒä¸é¢„æµ‹</strong></h2> 
<p><strong>ã€1ã€‘å¼€å§‹è®­ç»ƒ</strong></p> 
<p>Â  Â Â è®­ç»ƒè„šæœ¬å¦‚ä¸‹ï¼š</p> 
<pre><code class="language-python">from ultralytics import YOLO

# Load a model
model = YOLO('yolov8n.pt')  # load a pretrained model (recommended for training)

results = model.train(data='hand.yaml', epochs=30, imgsz=640, device=[0],
                      workers=0,lr0=0.001,batch=8,amp=False)</code></pre> 
<p>Â Â Â  <span style="color:#fe2c24;">hand.yaml</span>å†…å®¹å¦‚ä¸‹ï¼Œæ³¨æ„ä¿®æ”¹è‡ªå·±çš„æ•°æ®é›†è·¯å¾„å³å¯ï¼š</p> 
<pre><code class="language-python"># Ultralytics YOLO ğŸš€, AGPL-3.0 license
# COCO8 dataset (first 8 images from COCO train2017) by Ultralytics
# Documentation: https://docs.ultralytics.com/datasets/detect/coco8/
# Example usage: yolo train data=coco8.yaml
# parent
# â”œâ”€â”€ ultralytics
# â””â”€â”€ datasets
#     â””â”€â”€ coco8  â† downloads here (1 MB)

# Train/val/test sets as 1) dir: path/to/imgs, 2) file: path/to/imgs.txt, or 3) list: [path/to/imgs1, path/to/imgs2, ..]
path: E:/Practice/DeepLearning/Yolo_Test/dataset/hand # dataset root dir
train: E:/Practice/DeepLearning/Yolo_Test/dataset/hand/images/train # train images (relative to 'path') 4 images
val: E:/Practice/DeepLearning/Yolo_Test/dataset/hand/images/val # val images (relative to 'path') 4 images
test: # test images (optional)

# Classes
names:
  0: hand-1
  1: hand-2
  2: hand-5


# Download script/URL (optional)
# download: https://ultralytics.com/assets/coco8.zip</code></pre> 
<p><img alt="" height="395" src="https://images2.imgbox.com/3a/ca/zQCUqodK_o.png" width="995"></p> 
<p>CPUè®­ç»ƒå°†device=[0]æ”¹ä¸ºdevice='cpu'å³å¯</p> 
<p>è®­ç»ƒå®Œæˆåå†runs/detect/trainæ–‡ä»¶å¤¹ä¸‹ç”Ÿæˆå¦‚ä¸‹å†…å®¹ï¼š</p> 
<p><img alt="" height="926" src="https://images2.imgbox.com/7b/d5/Z87W4k2w_o.png" width="1200"></p> 
<p>Â Â Â Â åœ¨weightsæ–‡ä»¶å¤¹ä¸‹ç”Ÿæˆä¸¤ä¸ªæ¨¡å‹æ–‡ä»¶ï¼Œç›´æ¥ä½¿ç”¨best.ptå³å¯ã€‚</p> 
<p><img alt="" height="334" src="https://images2.imgbox.com/89/24/nYLZbLeL_o.png" width="1051"></p> 
<p><strong>ã€2ã€‘é¢„æµ‹æ¨ç†</strong></p> 
<p>Â  Â  é¢„æµ‹è„šæœ¬å¦‚ä¸‹ï¼š</p> 
<pre><code class="language-python">from ultralytics import YOLO
# Load a model
model = YOLO('best.pt')  # pretrained YOLOv8n model

# Run batched inference on a list of images
results = model(['1 (1).jpg', '1 (2).jpg', '1 (3).jpg'])  # return a list of Results objects

# Process results list
for result in results:
    boxes = result.boxes  # Boxes object for bounding box outputs
    masks = result.masks  # Masks object for segmentation masks outputs
    keypoints = result.keypoints  # Keypoints object for pose outputs
    probs = result.probs  # Probs object for classification outputs
    result.show()  # display to screen
    result.save(filename='result.jpg')  # save to disk</code></pre> 
<p>Â Â Â Â é¢„æµ‹ç»“æœï¼š</p> 
<p><img alt="" height="751" src="https://images2.imgbox.com/c5/a0/Ve6DThtd_o.png" width="993"></p> 
<p><img alt="" height="748" src="https://images2.imgbox.com/2c/a8/bPxw2jq9_o.png" width="990"></p> 
<p><img alt="" height="750" src="https://images2.imgbox.com/dc/76/8EyesIXx_o.png" width="993"></p> 
<p><strong><strong>â€”THE ENDâ€”</strong></strong></p> 
<p>THE END!</p> 
<p>æ–‡ç« ç»“æŸï¼Œæ„Ÿè°¢é˜…è¯»ã€‚æ‚¨çš„ç‚¹èµï¼Œæ”¶è—ï¼Œè¯„è®ºæ˜¯æˆ‘ç»§ç»­æ›´æ–°çš„åŠ¨åŠ›ã€‚<strong>å¤§å®¶æœ‰æ¨èçš„å…¬ä¼—å·å¯ä»¥è¯„è®ºåŒºç•™è¨€ï¼Œå…±åŒå­¦ä¹ ï¼Œä¸€èµ·è¿›æ­¥ã€‚</strong></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/3c88f8554671a52934aceb2881bd1c3c/" rel="prev">
			<span class="pager__subtitle">Â«&thinsp;Previous</span>
			<p class="pager__title">å—äº¬é‚®ç”µå¤§å­¦æ•°å­¦å®éªŒMATLAB2023</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/4492afc67728daee796b4c9d8734e1ba/" rel="next">
			<span class="pager__subtitle">Next&thinsp;Â»</span>
			<p class="pager__title">å¥½ä¹¦æ¨è ã€ŠAIGCé‡å¡‘é‡‘èã€‹</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 ç¼–ç¨‹å­¦ä¹ è€….
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>