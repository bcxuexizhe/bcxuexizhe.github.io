<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>spark和scala环境安装与部署（超详细版），我保证你敢看，你就学会了 - 编程学习者</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcxuexizhe.github.io/posts/6b0ca6b8ec427503b4a66fd81c839b8e/">
  <meta property="og:site_name" content="编程学习者">
  <meta property="og:title" content="spark和scala环境安装与部署（超详细版），我保证你敢看，你就学会了">
  <meta property="og:description" content="一.SPARK简介 Spark是一种基于内存的快速、通用、可扩展的大数据分析计算引擎。
是加州大学伯克利分校AMP实验室（Algorithms, Machines, and People Lab）开发的通用内存并行计算框架Spark得到了众多大数据公司的支持，这些公司包括Hortonworks、IBM、Intel、Cloudera、MapR、Pivotal、百度、阿里、腾讯、京东、携程、优酷土豆。当前百度的Spark已应用于大搜索、直达号、百度大数据等业务；阿里利用GraphX构建了大规模的图计算和图挖掘系统，实现了很多生产系统的推荐算法；腾讯Spark集群达到8000台的规模，是当前已知的世界上最大的Spark集群。
二.spark搭建准备 JDK1.8
Hadoop安装
版本：2.7.7
参考：https://blog.csdn.net/tangyi2008/article/details/121908766
虚拟机完全分布式加hive
三.scala与spark搭建与安装 1）scala下载安装 首先从Scala官网链接：The Scala Programming Language (scala-lang.org)下载scala安装包
all releases 是选择历史版本
在这里选择scala2.12.12版本
如果我们要给虚拟机安装就选择tgz后缀的安装包，如果要给windows安装就选择msi安装包的后缀
我们这边就演示虚拟机的所以我们下载Linux版本。
附上Linux版本的下载链接：https://downloads.lightbend.com/scala/2.12.12/scala-2.12.12.tgz
2）前往spark下载安装包 首先进入官网，官网链接：Apache Spark™ - Unified Engine for large-scale data analytics
下载spark安装包，然后进入download
可以在下载页面的下方进入它的release archives：https://archive.apache.org/dist/spark/ 选择想要的版本。
这里以3.1.1版本为例，我们下载的安装文件应该是形如：spark-3.1.1-bin-xxxxxx.tgz的文件，很多人很困惑如何选择这些版本。
之所以会有这么多版本的选择，是因为Spark需要一些Hadoop客户端的依赖包（需要访问HDFS和YARN）， 这些版本主要分为两类：
pre-packaged binary，将Hadoop客户端的依赖包编译到所下载的压缩包当中，比如spark-2.4.8-bin-hadoop2.6.tgz 和spark-2.4.8-bin-hadoop2.7.tgz ，
“Hadoop free” binary，需要自己通过配置 SPARK_DIST_CLASSPATH 变量，以便可以包含指定版本的Hadoop的相关jar包，比如：spark-3.1.1-bin-without-hadoop-scala-2.12.tgz、spark-2.4.8-bin-without-hadoop.tgz 。
我们这里选择“Hadoop free” binary形式的spark-3.1.1-bin-without-hadoop.tgz进行下载，直接使用浏览器下载过慢，可以使用迅雷加速下载，也可以去后面的网盘资源进行下载
3）上传安装包至虚拟机
我们如果是图形化界面可以进行直接拖拽，如果是mini版本的我们就需要xshell和xftp进行上传，我们这边是mini版本的我们就进行上传
我们用ifconfig命令查看我们主机的ip地址
打开xshell在文件新建中创建一个连接
然后在主机里输入我们刚刚查到的ip
之后我们点击用户身份验证在这里输入我们的用户名和密码即可连接
连接成功后我们选择xftp进行传输
把我们刚刚下载的安装包拖拽到虚拟机中，这里我推荐到opt目录里
3）进行scala的安装配置 解压安装包 tar -zxvf /opt/scala-2.">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-03-08T16:00:57+08:00">
    <meta property="article:modified_time" content="2024-03-08T16:00:57+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程学习者" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程学习者</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">spark和scala环境安装与部署（超详细版），我保证你敢看，你就学会了</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h2>一.SPARK简介</h2> 
<p>Spark是一种基于内存的快速、通用、可扩展的大数据分析计算引擎。</p> 
<p>是加州大学伯克利分校AMP实验室（Algorithms, Machines, and People Lab）开发的通用内存并行计算框架Spark得到了众多大数据公司的支持，这些公司包括Hortonworks、IBM、Intel、Cloudera、MapR、Pivotal、百度、阿里、腾讯、京东、携程、优酷土豆。当前百度的Spark已应用于大搜索、直达号、百度大数据等业务；阿里利用GraphX构建了大规模的图计算和图挖掘系统，实现了很多生产系统的推荐算法；腾讯Spark集群达到8000台的规模，是当前已知的世界上最大的Spark集群。</p> 
<h2>二.spark搭建准备</h2> 
<ul><li> <p>JDK1.8</p> </li><li> <p>Hadoop安装</p> <p>版本：2.7.7</p> <p>参考：https://blog.csdn.net/tangyi2008/article/details/121908766</p> </li><li> <p>虚拟机完全分布式加hive</p> </li></ul> 
<h2>三.scala与spark搭建与安装</h2> 
<h4>1）scala下载安装</h4> 
<p>首先从Scala官网链接：<a href="https://www.scala-lang.org/" rel="nofollow" title="The Scala Programming Language (scala-lang.org)">The Scala Programming Language (scala-lang.org)</a>下载scala安装包</p> 
<p>all releases 是选择历史版本</p> 
<p><img alt="" height="793" src="https://images2.imgbox.com/b7/3a/9OXPaWx4_o.png" width="1200"></p> 
<p>在这里选择scala2.12.12版本</p> 
<p><img alt="" height="218" src="https://images2.imgbox.com/f8/56/fAIsstxP_o.png" width="346"></p> 
<p>如果我们要给虚拟机安装就选择tgz后缀的安装包，如果要给windows安装就选择msi安装包的后缀</p> 
<p>我们这边就演示虚拟机的所以我们下载Linux版本。</p> 
<p>附上Linux版本的下载链接：<a href="https://downloads.lightbend.com/scala/2.12.12/scala-2.12.12.tgz" rel="nofollow" title="https://downloads.lightbend.com/scala/2.12.12/scala-2.12.12.tgz">https://downloads.lightbend.com/scala/2.12.12/scala-2.12.12.tgz</a></p> 
<p><img alt="" height="490" src="https://images2.imgbox.com/d6/00/02Gxteyv_o.png" width="1024"></p> 
<h4>2）前往spark下载安装包</h4> 
<p>首先进入官网，官网链接：<a href="https://spark.apache.org/" rel="nofollow" title="Apache Spark™ - Unified Engine for large-scale data analytics">Apache Spark™ - Unified Engine for large-scale data analytics</a></p> 
<p>下载spark安装包，然后进入download</p> 
<p><img alt="" height="425" src="https://images2.imgbox.com/ee/87/fMEAG1BG_o.png" width="1191"></p> 
<p>可以在下载页面的下方进入它的release archives：https://archive.apache.org/dist/spark/ 选择想要的版本。</p> 
<p><img alt="" height="166" src="https://images2.imgbox.com/32/f2/LlHsom1m_o.png" width="882"></p> 
<p>这里以3.1.1版本为例，我们下载的安装文件应该是形如：spark-3.1.1-bin-xxxxxx.tgz的文件，很多人很困惑如何选择这些版本。</p> 
<p><img alt="" height="732" src="https://images2.imgbox.com/9f/18/Dg4pERvg_o.png" width="354"></p> 
<p>之所以会有这么多版本的选择，是因为Spark需要一些Hadoop客户端的依赖包（需要访问HDFS和YARN）， 这些版本主要分为两类：</p> 
<p>pre-packaged binary，将Hadoop客户端的依赖包编译到所下载的压缩包当中，比如spark-2.4.8-bin-hadoop2.6.tgz 和spark-2.4.8-bin-hadoop2.7.tgz ，</p> 
<p>“Hadoop free” binary，需要自己通过配置 SPARK_DIST_CLASSPATH 变量，以便可以包含指定版本的Hadoop的相关jar包，比如：spark-3.1.1-bin-without-hadoop-scala-2.12.tgz、spark-2.4.8-bin-without-hadoop.tgz 。</p> 
<p>我们这里选择“Hadoop free” binary形式的spark-3.1.1-bin-without-hadoop.tgz进行下载，直接使用浏览器下载过慢，可以使用迅雷加速下载，也可以去后面的网盘资源进行下载</p> 
<p>3）上传安装包至虚拟机</p> 
<p>我们如果是图形化界面可以进行直接拖拽，如果是mini版本的我们就需要xshell和xftp进行上传，我们这边是mini版本的我们就进行上传</p> 
<p>我们用ifconfig命令查看我们主机的ip地址</p> 
<p><img alt="" height="183" src="https://images2.imgbox.com/5f/51/YxENfEJH_o.png" width="618"></p> 
<p>打开xshell在文件新建中创建一个连接</p> 
<p><img alt="" height="175" src="https://images2.imgbox.com/c3/1a/xSpecq6Z_o.png" width="243"></p> 
<p>然后在主机里输入我们刚刚查到的ip</p> 
<p><img alt="" height="286" src="https://images2.imgbox.com/23/59/50yPvZn3_o.png" width="390"></p> 
<p>之后我们点击用户身份验证在这里输入我们的用户名和密码即可连接</p> 
<p><img alt="" height="116" src="https://images2.imgbox.com/ea/4e/7aa4Uhh7_o.png" width="429"></p> 
<p>连接成功后我们选择xftp进行传输</p> 
<p><img alt="" height="85" src="https://images2.imgbox.com/cf/f1/aV1XipHb_o.png" width="643"></p> 
<p>把我们刚刚下载的安装包拖拽到虚拟机中，这里我推荐到opt目录里</p> 
<p><img alt="" height="799" src="https://images2.imgbox.com/bd/9c/o1t9awZC_o.png" width="1200"></p> 
<h4>3）进行scala的安装配置</h4> 
<h5>解压安装包   tar -zxvf /opt/scala-2.12.12.tgz -C /opt/</h5> 
<p><img alt="" height="133" src="https://images2.imgbox.com/2c/03/1d6X6zjC_o.png" width="639"></p> 
<p><img alt="" height="174" src="https://images2.imgbox.com/bd/16/PyCUC4Gm_o.png" width="795"></p> 
<h5>配置scala环境变量</h5> 
<p>vim /etc/profile</p> 
<p>#SCALA</p> 
<p><a name="adDz-1709650384406"></a>export SCALA_HOME=/opt/scala-2.12.12</p> 
<p><a name="2faB-1709650384408"></a>export PATH=$PATH:${SCALA_HOME}/bin </p> 
<p style="margin-left:.0001pt;text-align:justify;">图中SCALA_HOME是Scala的安装路径</p> 
<p style="margin-left:.0001pt;text-align:justify;"><img alt="" height="34" src="https://images2.imgbox.com/73/c6/x7e2fxdQ_o.png" width="534"></p> 
<p style="margin-left:.0001pt;text-align:justify;">然后source /etc/profile使环境变量生效，接着scala -version查看是否安装成功，出现画线版本号即为成功</p> 
<p style="margin-left:.0001pt;text-align:justify;"><img alt="" height="74" src="https://images2.imgbox.com/8f/51/qum3Dtko_o.png" width="714"></p> 
<h4 style="margin-left:.0001pt;text-align:justify;"><strong>4）进行spark安装配置</strong></h4> 
<h5 style="margin-left:.0001pt;text-align:justify;">解压安装spark安装包</h5> 
<p style="margin-left:.0001pt;text-align:justify;"><span style="background-color:#dbdbdb;">tar -zxvf / export/ software/ spark-3.1.1-bin-hadoop3.2.tgz </span></p> 
<p style="margin-left:.0001pt;text-align:justify;"><img alt="" height="129" src="https://images2.imgbox.com/06/bd/kV3AQm9s_o.png" width="591"></p> 
<h5 style="margin-left:.0001pt;text-align:justify;">spark-1.1-bin-hadoop3.2文件名字太长，改名字为spark方便后续操作</h5> 
<p>mv spark-1.1-bin-hadoop3.2 spark</p> 
<p style="margin-left:.0001pt;text-align:justify;"><img alt="" height="70" src="https://images2.imgbox.com/a4/e4/IupPThOH_o.png" width="491"></p> 
<h5>.配置环境变量  vim /etc/profile</h5> 
<p>#SPARK <br> export SPARK_HOME=/opt/spark<br> export PATH=$PATH:${SPARK_HOME}/bin<br> export PATH=$PATH:${SPARK_HOME}/sbin</p> 
<p>这里 SPARK_HOME是spark的安装路径</p> 
<p><img alt="" height="109" src="https://images2.imgbox.com/7f/e8/UuhE7ko8_o.png" width="328"></p> 
<p>.source /etc/profile使环境生效</p> 
<h5>修改配置文件  进入spark里的conf目录备份文件</h5> 
<p>cd /opt/spark/conf</p> 
<p>cp spark-env.sh.template spark-env.sh</p> 
<p><img alt="" height="32" src="https://images2.imgbox.com/8a/25/ZFU2TI0m_o.png" width="526"></p> 
<h5>修改配置文件             在spark下的conf目录打开env   vim spark-env.sh</h5> 
<p>export SCALA_HOME=/opt/scala-2.12.12</p> 
<p>export JAVA_HOME=/opt/module/java</p> 
<p>export SPARK_MASTER_IP=master</p> 
<p>export SPARK_WOKER_CORES=2</p> 
<p>export SPARK_WOKER_MEMORY=2g</p> 
<p>export HADOOP_CONF_DIR=/opt/hadoop/etc/hadoop</p> 
<p>#export SPARK_MASTER_WEBUI_PORT=8080</p> 
<p>#export SPARK_MASTER_PORT=7070</p> 
<p><img alt="" height="171" src="https://images2.imgbox.com/50/08/1MfubP71_o.png" width="587"></p> 
<h5 style="margin-left:.0001pt;text-align:justify;">修改从节点ip</h5> 
<p style="margin-left:.0001pt;text-align:justify;">   vi slaves 修改内容为slave1 slave2(我的子机分别为是slave1 slave2</p> 
<p style="margin-left:.0001pt;text-align:justify;"><img alt="" height="115" src="https://images2.imgbox.com/b2/fe/ed6OVrS3_o.png" width="251"></p> 
<h5 style="margin-left:.0001pt;text-align:justify;">(4)分发文件</h5> 
<p style="margin-left:.0001pt;text-align:justify;"><span style="background-color:#dbdbdb;">scp -r /opt/spark / slave1:/opt/</span></p> 
<p style="margin-left:.0001pt;text-align:justify;"><span style="background-color:#dbdbdb;">scp -r /opt/spark/ slave2:/opt/</span></p> 
<p style="margin-left:.0001pt;text-align:justify;"><img alt="" height="151" src="https://images2.imgbox.com/da/fe/lGIdJyhT_o.png" width="712"></p> 
<p style="margin-left:.0001pt;text-align:justify;"><img alt="" height="170" src="https://images2.imgbox.com/3d/04/kSx7RQgu_o.png" width="688"></p> 
<h5 style="margin-left:.0001pt;text-align:justify;">分别在slave1 slave2上设置环境变量</h5> 
<p style="margin-left:.0001pt;text-align:justify;">#SPARK</p> 
<p style="margin-left:.0001pt;text-align:justify;">export SPARK_HOME=/opt/spark</p> 
<p style="margin-left:.0001pt;text-align:justify;">export PATH=$PATH:${SPARK_HOME}/bin</p> 
<p style="margin-left:.0001pt;text-align:justify;">export PATH=$PATH:${SPARK_HOME}/sbin</p> 
<p style="margin-left:.0001pt;text-align:justify;"><img alt="" height="162" src="https://images2.imgbox.com/78/73/gLeZiFEa_o.png" width="454"></p> 
<h5 style="margin-left:.0001pt;text-align:justify;"><span style="background-color:#dbdbdb;">source /etc/profile使环境变量生效</span></h5> 
<p style="margin-left:.0001pt;text-align:justify;">启动集群：spark下sbin目录下：./start-all.sh 查看节点状态 在主节点master上出现Master 在s1上出现Worker在s2上出现Worker</p> 
<p style="margin-left:.0001pt;text-align:justify;">master：</p> 
<p style="margin-left:.0001pt;text-align:justify;"><img alt="" height="483" src="https://images2.imgbox.com/99/26/0l0E07u8_o.png" width="991"></p> 
<p style="margin-left:.0001pt;text-align:justify;"></p> 
<p style="margin-left:.0001pt;text-align:justify;">slave1</p> 
<p style="margin-left:.0001pt;text-align:justify;"><img alt="" height="105" src="https://images2.imgbox.com/17/e0/sRYD7vAg_o.png" width="475"></p> 
<p style="margin-left:.0001pt;text-align:justify;">slave2</p> 
<p style="margin-left:.0001pt;text-align:justify;"><img alt="" height="80" src="https://images2.imgbox.com/77/be/GG6SvC2A_o.png" width="561"></p> 
<p style="margin-left:.0001pt;text-align:justify;"></p> 
<h5 style="margin-left:.0001pt;text-align:justify;">查看spark是否安装成功 返回主目录下输入Spark-shell</h5> 
<p style="margin-left:.0001pt;text-align:justify;"><img alt="" height="341" src="https://images2.imgbox.com/69/ce/q8QMGpRm_o.png" width="812"></p> 
<p style="margin-left:.0001pt;text-align:justify;"></p> 
<p style="margin-left:.0001pt;text-align:justify;"></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/ef7fb55ef1c8fbf826b472d008634ac2/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">【前端】处理一次性十万条数据渲染方案（不考虑后端分页）</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/b34d7cbb000a248071367397633a9c35/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Linux-一篇文章，速通Hadoop集群之伪分布式，完全分布式，高可用搭建（附zookeeper，jdk介绍与安装）。</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程学习者.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>