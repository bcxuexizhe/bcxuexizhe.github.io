<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>对大模型和AI的认识与思考 - 编程学习者</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcxuexizhe.github.io/posts/d55b2b3c80a1d8215460c50b74f87c5d/">
  <meta property="og:site_name" content="编程学习者">
  <meta property="og:title" content="对大模型和AI的认识与思考">
  <meta property="og:description" content="1. 写在前面 自从OpenAI在2022年11月30日发布了引领新一轮AI革命浪潮的产品ChatGPT以来，大模型和生成式AI这把大火在2023年越烧越旺，各种技术和应用层出不穷；而2023年11月，同样是OpenAI CEO山姆·奥特曼(Sam Altman)被开除后有回归，这100小时的宫斗赚足了媒体和世界网名的关注，引出了大家对AI安全的遐想和担忧。
以OpenAI开始，以OpenAI收尾，至此已经两年有余了。这一年AI做出了令人瞩目的成绩，确似乎才刚刚开始。我、我的朋友、我的同事以及网络上的网友，都切实可行的从AI技术上获得了效率和便捷性大幅度提升的好处。
做为一名技术人，在2023年，笔者也参与了各种学习和实践，从大语言模型、多模态算法，文生图（Stable Diffusion）技术，到prompt工程实践和搭建文生图（Stable Diffusion）webui实操环境。在此对谈谈对大模型和AI的认识与思考，是为总结。
2. 生成式AI元年 2023无疑是生成式AI的元年，英伟达的CEO黄仁勋曾说过：人工智能已经到了iPhone时刻；或许离真正的AGI还有一定的距离，但AI确实展现出人类基本常识和推理的能力，特别是模型越来越大的加持虾出现的涌现能力。就在最近Google发布最新人工智能模型Gemini，声称性能超越GPT-4和人类专家，从宣传视频上看，Gemini已经具备人类的视觉（图像识别），听觉（语音识别）和自然语言理解的基本技能。
我们一起来回顾下生成式AI的发展。
2.1 GPT的发展 如果说大语言模型存在一个分水岭的话，我觉得是2017年Google提出了一种全新的模型Transformer，Transformer是典型的encoder-decoder结构，最早是用来做机器翻译的。Transformer中最重要的结构是Multi-Head的Self-Attention机制。在Transformer之前，自然语言处理（NLP）一般采用循环神经网络RNN，以及变种如双向的RNN、LSTM和GRU等，但都存在一定的问题，如长文本序列上下文遗忘，难以并行等，而Transformer较好的解决了这些问题。
Transformer推出之后，被循序了应用到自然语言处理的各个领域，同样也在机器视觉领域和传统的CNN一较高下，并拔得头筹。Transformer的火爆可见一斑，值得一提的当前Transformer的几个作者都开始加入大模型创业浪潮，虏获资本的厉害，如Adept、Essential AI、Cohere。
说回到Transformer的生态树，Transformer之后，出现了三个较大的分支:
一个是以BERT为代表的以decoder-only的模型，还有百度的ERNIE
另一个是以GPT为代表的encoder模型，还有谷歌的Bard，claude，cohere，百度的ERNIE 3.0（当前的文心一言）
第三个分支则是encoder&#43;decoder的模型（就是整个Transformer），这里有清华系的GLM和chatGLM，还有谷歌的T5,Meta的LLAMa
BERT以完形填空的方式开启的大语言的预训练模型之路，一个pre-trained Model可以快速的迁移后下游的任务。而GPT走的是另外一条更艰难的道路，生成式模型，预测下一个词，一开始GPT1性能不如BERT，于是GPT开始了大，更大，最大的模式，从GPT1的1.17亿参数量到GPT3的1750亿参数量，开始了大力出奇迹的真正大模型之路。
在GPT3中，使得提示（Prompt）的重要性越来越被重视，逐步变成当前的Prompt Engineering。Prompt engineering是创建提示或询问或指导像ChatGPT这样的语言模型的输出的指令。它允许用户控制模型的输出并生成文本根据他们的具体需求量身定制。如何有效清晰明确的表达你的意愿，对于使用大模型是至关重要的。
在GPT3之后，OpenAI做了不同的调优，如针对代码的Codex，特别是InstructGPT引入了强化学习的机制来使得大语言模型的生成结果和人类进行对齐，而ChatGPT是在此基础上加入了有监督的学习指导，可以说是更强的对齐（OpenAI最近成立SuperAlign超级对齐部门专门解决AI和人类的对齐问题）。至此ChatGPT问世，GPT4则加入多模态使得GPT可以有处理图像的能力。
2.2 开源GPT 我们知道，OpenAI在GPT3之后就采用封闭的方式不公开代码和模型，只提供API来供使用。谷歌的Bard和PaLM也是封闭的。国外大厂里只有Meta提供了大模型的开源，如OPT、BLOOM、LLaMa。
开源社区也针对公开的模型，训练更小的模型，并希望和GPT性能对齐。比较早期的有斯坦福大学的Alpaca（羊驼），清华系的ChatGLM-6B，复旦MOSS，Vicuna-13B 和mini-GPT4。
当然后续国内外也有公司开源了较小的模型，如百川2-13B,通义千问-72B（Qwen-72B）等，这些模型都可以在modelscope上下载获得。
感谢开源！
2.3 国内的GPT们 在ChatGPT爆红之后，国内的大厂们也开启GPT模式，进入百模大战模式。百度的文心一言先开始拉开序幕，还有阿里云的通义千问，华为盘古，商汤日日新，360的360智脑，京东的言犀大模型，腾讯的HunYuan大模型，科大讯飞的讯飞星火，还有chatGLM的智谱清言。
大家都在追赶GPT，目前看百度的文心一言4.0是比较接近ChatGPT，当然如何有效的评测大模型的性能也是一门学问，可以参考Holistic Evaluation of Language Models。
2.4 文生图赛道 今年除了ChatGPT这个语言生成模型比较火之外，另一个比较火的生成式AI就是Text-to-Image文生图。就是通过文字描述来生成一个和文字描述相关的图片。
Text-to-Image的代表应用是Midjourney，还有OpenAI的DALE-2和DALE-3，以及开源的Stable diffusion。
文生图可以通过文字描述来生成逼真的图画，这让许多没有绘画基础的人们带来了福音，只要你有想象力就可以。同时，文生图还开始席卷了需要图片的行业，比如游戏原画设计，logo设计，电商模特，海报设计，视频剪辑等等。
AI生成图片可以追溯到VAE，GAN，而当前最流行都是Diffusion扩散模型,这些事图生图的范式。
而文生图，就是在图生图之前加入文本的encoder，并加入图生图的过程，来影响图片的生成，借用李宏毅老师的一个框架，著名的DALE-2和Stable diffusion以及谷歌的Imagen都是套用此方法。
3. 大模型和AI应用和思考 如果说以大模型为代表的AI模型是人工智能的iphone时刻的话，那么iphone的APP有哪些？这或许是作为开发者的一个新的机会，在最近的OpenAI开发者大会上，OpenAI发布了GPTs和GPT store，通过GPTs人们可以构建自己的应用，而GPT store是针对垂直领域的大模型微调版本。另外一种形象的说法是大模型是底座操作系统，而运行上在这平台上的软件和app才刚刚开始，是为机会。毕竟大模型的训练是需要很大成本的，而开发一个APP是有可能的。
那我们如何利用这个大模型呢？
3.1 效率提升，解决业务痛点 通过分析下当前业务中的痛点和效率低下的环节，评估下是否接入成熟AI工具如ChatGPT或者文生图，当然也要考虑成本因素。这是当前比较主流的应用方式。比如游戏设计中的原画设计，可以接入Midjourney来做初稿和创意设计，来大大加快效率；视频或者文字内容创造者，可以用ChatGPT来文案设计，用Midjourney来插画或者视频素材；培训工作者如教师可以用ChatGPT来做备课工具，提升效率。
这个阶段注重和自身业务的契合点，直接使用工具解决问题。
3.2 提升易用性，做垂直应用 当前大模型的一个重要的环节是prompt（提示），不同的prompt可以有截然不同的结果，这个也是当前大模型使用的一个门槛。如何提升工具的易用性，是一个值得关注的方向。
prompt分享平台：分享不同的prompt展示平台，甚至拿prompt做为产品来销售，以及prompt培训
能不能只写简单的prompt就能有很好的结果，比较典型的就是做垂直领域的应用，总结垂直领域特别的prompt作为潜在的prompt添加到使用者的prompt之后进行简化使用
垂直领域应用：用产品思维的方式，分析垂直领域的特点，综合大模型和其他领域知识，打造更加智能化的垂直应用">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-05-07T09:59:53+08:00">
    <meta property="article:modified_time" content="2024-05-07T09:59:53+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程学习者" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程学习者</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">对大模型和AI的认识与思考</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h3><a id="1__0"></a>1. 写在前面</h3> 
<p>自从OpenAI在2022年11月30日发布了引领新一轮AI革命浪潮的产品ChatGPT以来，大模型和生成式AI这把大火在2023年越烧越旺，各种技术和应用层出不穷；而2023年11月，同样是OpenAI CEO山姆·奥特曼(Sam Altman)被开除后有回归，这100小时的宫斗赚足了媒体和世界网名的关注，引出了大家对AI安全的遐想和担忧。</p> 
<p>以OpenAI开始，以OpenAI收尾，至此已经两年有余了。这一年AI做出了令人瞩目的成绩，确似乎才刚刚开始。我、我的朋友、我的同事以及网络上的网友，都切实可行的从AI技术上获得了效率和便捷性大幅度提升的好处。</p> 
<p>做为一名技术人，在2023年，笔者也参与了各种学习和实践，从大语言模型、多模态算法，文生图（Stable Diffusion）技术，到prompt工程实践和搭建文生图（Stable Diffusion）webui实操环境。在此对谈谈对大模型和AI的认识与思考，是为总结。</p> 
<h3><a id="2_AI_9"></a>2. 生成式AI元年</h3> 
<p>2023无疑是生成式AI的元年，英伟达的CEO黄仁勋曾说过：人工智能已经到了iPhone时刻；或许离真正的AGI还有一定的距离，但AI确实展现出人类基本常识和推理的能力，特别是模型越来越大的加持虾出现的涌现能力。就在最近Google发布最新人工智能模型Gemini，声称性能超越GPT-4和人类专家，从宣传视频上看，Gemini已经具备人类的视觉（图像识别），听觉（语音识别）和自然语言理解的基本技能。</p> 
<p>我们一起来回顾下生成式AI的发展。</p> 
<h4><a id="21_GPT_16"></a>2.1 GPT的发展</h4> 
<p>如果说大语言模型存在一个分水岭的话，我觉得是2017年Google提出了一种全新的模型Transformer，Transformer是典型的encoder-decoder结构，最早是用来做机器翻译的。Transformer中最重要的结构是Multi-Head的Self-Attention机制。在Transformer之前，自然语言处理（NLP）一般采用循环神经网络RNN，以及变种如双向的RNN、LSTM和GRU等，但都存在一定的问题，如长文本序列上下文遗忘，难以并行等，而Transformer较好的解决了这些问题。</p> 
<p><img src="https://images2.imgbox.com/da/d6/yljzzPoQ_o.png" alt=""></p> 
<p>Transformer推出之后，被循序了应用到自然语言处理的各个领域，同样也在机器视觉领域和传统的CNN一较高下，并拔得头筹。Transformer的火爆可见一斑，值得一提的当前Transformer的几个作者都开始加入大模型创业浪潮，虏获资本的厉害，如Adept、Essential AI、Cohere。</p> 
<p><img src="https://images2.imgbox.com/fd/a3/eS1o8C3z_o.png" alt=""></p> 
<p>说回到Transformer的生态树，Transformer之后，出现了三个较大的分支:</p> 
<ul><li> <p>一个是以BERT为代表的以decoder-only的模型，还有百度的ERNIE</p> </li><li> <p>另一个是以GPT为代表的encoder模型，还有谷歌的Bard，claude，cohere，百度的ERNIE 3.0（当前的文心一言）</p> </li><li> <p>第三个分支则是encoder+decoder的模型（就是整个Transformer），这里有清华系的GLM和chatGLM，还有谷歌的T5,Meta的LLAMa</p> </li></ul> 
<p><img src="https://images2.imgbox.com/01/58/qcBLX3mK_o.png" alt=""></p> 
<p><img src="https://images2.imgbox.com/8a/8e/u8qq9CVB_o.png" alt=""></p> 
<p>BERT以完形填空的方式开启的大语言的预训练模型之路，一个pre-trained Model可以快速的迁移后下游的任务。而GPT走的是另外一条更艰难的道路，生成式模型，预测下一个词，一开始GPT1性能不如BERT，于是GPT开始了大，更大，最大的模式，从GPT1的1.17亿参数量到GPT3的1750亿参数量，开始了大力出奇迹的真正大模型之路。</p> 
<p><img src="https://images2.imgbox.com/ca/a3/piUC4ihb_o.png" alt=""></p> 
<p>在GPT3中，使得提示（Prompt）的重要性越来越被重视，逐步变成当前的Prompt Engineering。Prompt engineering是创建提示或询问或指导像ChatGPT这样的语言模型的输出的指令。它允许用户控制模型的输出并生成文本根据他们的具体需求量身定制。如何有效清晰明确的表达你的意愿，对于使用大模型是至关重要的。</p> 
<p><img src="https://images2.imgbox.com/91/be/0sFhMT1o_o.png" alt=""></p> 
<p>在GPT3之后，OpenAI做了不同的调优，如针对代码的Codex，特别是InstructGPT引入了强化学习的机制来使得大语言模型的生成结果和人类进行对齐，而ChatGPT是在此基础上加入了有监督的学习指导，可以说是更强的对齐（OpenAI最近成立SuperAlign超级对齐部门专门解决AI和人类的对齐问题）。至此ChatGPT问世，GPT4则加入多模态使得GPT可以有处理图像的能力。</p> 
<p><img src="https://images2.imgbox.com/94/06/C7qcTtdo_o.png" alt=""></p> 
<h4><a id="22_GPT_51"></a>2.2 开源GPT</h4> 
<p>我们知道，OpenAI在GPT3之后就采用封闭的方式不公开代码和模型，只提供API来供使用。谷歌的Bard和PaLM也是封闭的。国外大厂里只有Meta提供了大模型的开源，如OPT、BLOOM、LLaMa。</p> 
<p>开源社区也针对公开的模型，训练更小的模型，并希望和GPT性能对齐。比较早期的有斯坦福大学的Alpaca（羊驼），清华系的ChatGLM-6B，复旦MOSS，Vicuna-13B 和mini-GPT4。</p> 
<p>当然后续国内外也有公司开源了较小的模型，如百川2-13B,通义千问-72B（Qwen-72B）等，这些模型都可以在modelscope上下载获得。</p> 
<p>感谢开源！</p> 
<h4><a id="23_GPT_61"></a>2.3 国内的GPT们</h4> 
<p>在ChatGPT爆红之后，国内的大厂们也开启GPT模式，进入百模大战模式。百度的文心一言先开始拉开序幕，还有阿里云的通义千问，华为盘古，商汤日日新，360的360智脑，京东的言犀大模型，腾讯的HunYuan大模型，科大讯飞的讯飞星火，还有chatGLM的智谱清言。</p> 
<p>大家都在追赶GPT，目前看百度的文心一言4.0是比较接近ChatGPT，当然如何有效的评测大模型的性能也是一门学问，可以参考Holistic Evaluation of Language Models。</p> 
<h4><a id="24__67"></a>2.4 文生图赛道</h4> 
<p>今年除了ChatGPT这个语言生成模型比较火之外，另一个比较火的生成式AI就是Text-to-Image文生图。就是通过文字描述来生成一个和文字描述相关的图片。</p> 
<p>Text-to-Image的代表应用是Midjourney，还有OpenAI的DALE-2和DALE-3，以及开源的Stable diffusion。</p> 
<p><img src="https://images2.imgbox.com/80/d4/9zfcEAFB_o.png" alt=""></p> 
<p><img src="https://images2.imgbox.com/67/0f/KkaGzHbI_o.png" alt=""></p> 
<p>文生图可以通过文字描述来生成逼真的图画，这让许多没有绘画基础的人们带来了福音，只要你有想象力就可以。同时，文生图还开始席卷了需要图片的行业，比如游戏原画设计，logo设计，电商模特，海报设计，视频剪辑等等。</p> 
<p>AI生成图片可以追溯到VAE，GAN，而当前最流行都是Diffusion扩散模型,这些事图生图的范式。</p> 
<p><img src="https://images2.imgbox.com/79/30/cCGjlOBf_o.png" alt=""></p> 
<p>而文生图，就是在图生图之前加入文本的encoder，并加入图生图的过程，来影响图片的生成，借用李宏毅老师的一个框架，著名的DALE-2和Stable diffusion以及谷歌的Imagen都是套用此方法。</p> 
<p><img src="https://images2.imgbox.com/1c/fc/eBqSBdK9_o.png" alt=""></p> 
<h3><a id="3_AI_87"></a>3. 大模型和AI应用和思考</h3> 
<p>如果说以大模型为代表的AI模型是人工智能的iphone时刻的话，那么iphone的APP有哪些？这或许是作为开发者的一个新的机会，在最近的OpenAI开发者大会上，OpenAI发布了GPTs和GPT store，通过GPTs人们可以构建自己的应用，而GPT store是针对垂直领域的大模型微调版本。另外一种形象的说法是大模型是底座操作系统，而运行上在这平台上的软件和app才刚刚开始，是为机会。毕竟大模型的训练是需要很大成本的，而开发一个APP是有可能的。</p> 
<p>那我们如何利用这个大模型呢？</p> 
<h4><a id="31__94"></a>3.1 效率提升，解决业务痛点</h4> 
<p>通过分析下当前业务中的痛点和效率低下的环节，评估下是否接入成熟AI工具如ChatGPT或者文生图，当然也要考虑成本因素。这是当前比较主流的应用方式。比如游戏设计中的原画设计，可以接入Midjourney来做初稿和创意设计，来大大加快效率；视频或者文字内容创造者，可以用ChatGPT来文案设计，用Midjourney来插画或者视频素材；培训工作者如教师可以用ChatGPT来做备课工具，提升效率。</p> 
<p>这个阶段注重和自身业务的契合点，直接使用工具解决问题。</p> 
<h4><a id="32__100"></a>3.2 提升易用性，做垂直应用</h4> 
<p>当前大模型的一个重要的环节是prompt（提示），不同的prompt可以有截然不同的结果，这个也是当前大模型使用的一个门槛。如何提升工具的易用性，是一个值得关注的方向。</p> 
<ul><li> <p>prompt分享平台：分享不同的prompt展示平台，甚至拿prompt做为产品来销售，以及prompt培训</p> </li><li> <p>能不能只写简单的prompt就能有很好的结果，比较典型的就是做垂直领域的应用，总结垂直领域特别的prompt作为潜在的prompt添加到使用者的prompt之后进行简化使用</p> </li><li> <p>垂直领域应用：用产品思维的方式，分析垂直领域的特点，综合大模型和其他领域知识，打造更加智能化的垂直应用</p> </li></ul> 
<p>这个阶段注重易用性的提升, 封装工具成特定领域的工具解决问题。</p> 
<h4><a id="33_AI_Agents_113"></a>3.3 AI Agents</h4> 
<p>AI Agents无疑是未来新的发展方向，AI Agents在大模型的基础上，结合其工具和知识来扩展大模型的能力，使得大模型能够拆分任务，联网分析，使用工具等。以AugoGPT以开始，如何将大模型功能扩展到更大的领域，如何做任务规划，存储记忆，以及使用工具；以及制作AI Agent的平台工具，这也是提升便利性的方向。</p> 
<p><img src="https://images2.imgbox.com/98/8a/O0bzz3l1_o.png" alt=""></p> 
<p>除了autoGPT，langchain也是一个AI-agents的开发框架，同时也可以开发定制的知识库，同时也带动了向量数据库的发展，如Milvus，faiss等。</p> 
<h4><a id="34__121"></a>3.4 产品性思维</h4> 
<p>如何依托大模型来开发APP，最重要的是产品性思维；有哪些痛点，要解决什么问题。充分分析和挖掘需求，并结合大模型的能力，开发MVP最小可行产品，快速验证试错。比如chatMind是结合chatGPT+思维导图，GPTcache是节省chatGPT开销。大模型App的开发还在早期，要抓住机会。</p> 
<h3><a id="4_AI_125"></a>4. AI安全</h3> 
<p>据传OpenAI这次100小时的宫斗，是因为OpenAI的首席科学家Ilya Sutskever对AI发展过于激进和AI安全的担忧。</p> 
<p>说到AI的安全性，狭义上看AI或者生成式AI是否生成对人类有害的内容，比如是否包含种族歧视，性别歧视，暴力色情内容等，这也是当前评测大模型性能的一个方面。从广义上说，AI的安全性就广大到AI是否威胁人类的生存，AI会不会像影视剧中一样出现意识，毁灭人类。</p> 
<p>到底会不会发生AI毁灭人类呢？不知道。不过可以讲一个实例，我们知道训练AI是通过拟合一个优化目标来完成的，这个目标是人类设定；比如我们训练AI和人类下棋对弈，而目标就是赢棋，AI可以通过多种手段来达到这个目标，我们希望AI通过学习大量棋谱和自我对弈来达到赢棋的目标，而AI可能另辟蹊径：那就是直接杀死和它下棋的人类来达到赢棋的目标，这就是激励扭曲。</p> 
<p>我们如何能够更好的让AI和人类价值观做更好的对齐，使得AI的方式和人类相同，这也许是AI安全的一个解决方案。</p> 
<p>以上是为总结，2023马上就要过去，我很想你它，我更期望崭新的2024和新的机遇。</p> 
<h3><a id="_AI__138"></a>如何学习大模型 AI ？</h3> 
<p>由于新岗位的生产效率，要优于被取代岗位的生产效率，所以实际上整个社会的生产效率是提升的。</p> 
<p>但是具体到个人，只能说是：</p> 
<p><strong>“最先掌握AI的人，将会比较晚掌握AI的人有竞争优势”。</strong></p> 
<p>这句话，放在计算机、互联网、移动互联网的开局时期，都是一样的道理。</p> 
<p>我在一线互联网企业工作十余年里，指导过不少同行后辈。帮助很多人得到了学习和成长。</p> 
<p>我意识到有很多经验和知识值得分享给大家，也可以通过我们的能力和经验解答大家在人工智能学习中的很多困惑，所以在工作繁忙的情况下还是坚持各种整理和分享。但苦于知识传播途径有限，很多互联网行业朋友无法获得正确的资料得到学习提升，故此将并将重要的AI大模型资料包括AI大模型入门学习思维导图、精品AI大模型学习书籍手册、视频教程、实战学习等录播视频免费分享出来。</p> 
<p><img src="https://images2.imgbox.com/7d/9d/fLun6ISB_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="10_156"></a>第一阶段（10天）：初阶应用</h3> 
<p>该阶段让大家对大模型 AI有一个最前沿的认识，对大模型 AI 的理解超过 95% 的人，可以在相关讨论时发表高级、不跟风、又接地气的见解，别人只会和 AI 聊天，而你能调教 AI，并能用代码将大模型和业务衔接。</p> 
<ul><li>大模型 AI 能干什么？</li><li>大模型是怎样获得「智能」的？</li><li>用好 AI 的核心心法</li><li>大模型应用业务架构</li><li>大模型应用技术架构</li><li>代码示例：向 GPT-3.5 灌入新知识</li><li>提示工程的意义和核心思想</li><li>Prompt 典型构成</li><li>指令调优方法论</li><li>思维链和思维树</li><li>Prompt 攻击和防范</li><li>…</li></ul> 
<h3><a id="30_177"></a>第二阶段（30天）：高阶应用</h3> 
<p>该阶段我们正式进入大模型 AI 进阶实战学习，学会构造私有知识库，扩展 AI 的能力。快速开发一个完整的基于 agent 对话机器人。掌握功能最强的大模型开发框架，抓住最新的技术进展，适合 Python 和 JavaScript 程序员。</p> 
<ul><li>为什么要做 RAG</li><li>搭建一个简单的 ChatPDF</li><li>检索的基础概念</li><li>什么是向量表示（Embeddings）</li><li>向量数据库与向量检索</li><li>基于向量检索的 RAG</li><li>搭建 RAG 系统的扩展知识</li><li>混合检索与 RAG-Fusion 简介</li><li>向量模型本地部署</li><li>…</li></ul> 
<h3><a id="30_193"></a>第三阶段（30天）：模型训练</h3> 
<p>恭喜你，如果学到这里，你基本可以找到一份大模型 AI相关的工作，自己也能训练 GPT 了！通过微调，训练自己的垂直大模型，能独立训练开源多模态大模型，掌握更多技术方案。</p> 
<p>到此为止，大概2个月的时间。你已经成为了一名“AI小子”。那么你还想往下探索吗？</p> 
<ul><li>为什么要做 RAG</li><li>什么是模型</li><li>什么是模型训练</li><li>求解器 &amp; 损失函数简介</li><li>小实验2：手写一个简单的神经网络并训练它</li><li>什么是训练/预训练/微调/轻量化微调</li><li>Transformer结构简介</li><li>轻量化微调</li><li>实验数据集的构建</li><li>…</li></ul> 
<h3><a id="20_211"></a>第四阶段（20天）：商业闭环</h3> 
<p>对全球大模型从性能、吞吐量、成本等方面有一定的认知，可以在云端和本地等多种环境下部署大模型，找到适合自己的项目/创业方向，做一名被 AI 武装的产品经理。</p> 
<ul><li>硬件选型</li><li>带你了解全球大模型</li><li>使用国产大模型服务</li><li>搭建 OpenAI 代理</li><li>热身：基于阿里云 PAI 部署 Stable Diffusion</li><li>在本地计算机运行大模型</li><li>大模型的私有化部署</li><li>基于 vLLM 部署大模型</li><li>案例：如何优雅地在阿里云私有部署开源大模型</li><li>部署一套开源 LLM 项目</li><li>内容安全</li><li>互联网信息服务算法备案</li><li>…</li></ul> 
<p>学习是一个过程，只要学习就会有挑战。天道酬勤，你越努力，就会成为越优秀的自己。</p> 
<p>如果你能在15天内完成所有的任务，那你堪称天才。然而，如果你能完成 60-70% 的内容，你就已经开始具备成为一名大模型 AI 的正确特征了。</p> 
<h6><a id="httpsblogcsdnnetJavachichiarticledetails122513096spm1001201430015501httpsblogcsdnnetm0_57081622articledetails122378123spm1001201430015501_AI_CSDNCSDN100_235"></a><a href="https://blog.csdn.net/Javachichi/article/details/122513096?spm=1001.2014.3001.5501"></a><a href="https://blog.csdn.net/m0_57081622/article/details/122378123?spm=1001.2014.3001.5501"></a>这份完整版的大模型 AI 学习资料已经上传CSDN，朋友们如果需要可以微信扫描下方CSDN官方认证二维码免费领取【<code>保证100%免费</code>】</h6> 
<p>123?spm=1001.2014.3001.5501)这份完整版的大模型 AI 学习资料已经上传CSDN，朋友们如果需要可以微信扫描下方CSDN官方认证二维码免费领取【<code>保证100%免费</code>】</p> 
<p><img src="https://images2.imgbox.com/9a/d2/aILHTAY8_o.png" alt="在这里插入图片描述"></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/348323857daca741b83ad3133b354a1a/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">【Java】文件操作</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/a876e8215d706f91e6bd0ba0c707f140/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Spring Gateway的核心功能：路由、过滤、限流一网打尽</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程学习者.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>