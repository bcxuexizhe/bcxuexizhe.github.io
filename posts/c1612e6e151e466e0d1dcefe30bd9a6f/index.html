<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>【生成模型】Stable Diffusion原理&#43;代码 - 编程学习者</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcxuexizhe.github.io/posts/c1612e6e151e466e0d1dcefe30bd9a6f/">
  <meta property="og:site_name" content="编程学习者">
  <meta property="og:title" content="【生成模型】Stable Diffusion原理&#43;代码">
  <meta property="og:description" content="文章目录 前言一、Latent space二、AutoEncoder 和 VAE1.AutoEncoder:2.VAE： 三、Diffusion扩散模型1.前向过程2.逆向过程 四、多模态 cross attention五、Stable Diffusion原理1.训练过程：ResnetBlockSpatial Transformer(Cross Attention)DownSample/UpSample 2.前向过程 六、代码解析*0.安装提示1.整体代码2.unet解析1、self.input_blocks2、middle_blocks3、self.output_blocks 总结 前言 Stable diffusion是一个基于 Latent Diffusion Models（潜在扩散模型，LDMs）的文图生成（text-to-image）模型。具体来说，得益于 Stability AI 的计算资源支持和在 LAION-5B 的一个子集数据支持训练，用于文图生成。
Latent Diffusion Models 通过在一个潜在表示空间中迭代“去噪”数据来生成图像，然后将表示结果解码为完整的图像，让文图生成能够在消费级GPU上，在10秒级别时间生成图片。目前，Stable Diffusion发布了v2版本。v1版是Latent Diffusion Models的一个具体实现，模型架构设置：自动编码器下采样因子为8，UNet大小为860M，文本编码器为CLIP ViT-L/14。官方目前提供了以下权重：
提示：以下是本篇文章正文内容，下面案例可供参考
一、Latent space 隐空间是压缩数据的一个表示。数据压缩的目的是学习数据中较重要的信息。以编码器-解码器网络为例，首先使用全卷积神经网(FCN)络学习图片特征，我们将特征提取中对数据的降维看作一种有损压缩。由于解码器需要重建(reconstruct)数据，模型必须学习如何储存所有相关信息并且忽略噪音，压缩（降维）的好处在于可以去掉多余的信息从而关注于最关键的特征。
二、AutoEncoder 和 VAE 1.AutoEncoder: (1)AE是一个预训练的自编码器，优化目标是通过 Encoder 压缩数据，再通过decoder 还原数据，使得输入输出的数据尽量相同
(2)对于图像数据，decoder 还原数据可以看做是一个生成器，由于 decoder 输入数据z属于R空间，输入z的分布无法被固定住，所以大部分生成的图片是无意义的。
2.VAE： (1)给定输入解码器的z一个分布可以解决上述问题，假设一个服从标准多元高斯分布的多维随机变量的数据集X，根据已知分布采样得到的zi，来训练decoder神经网络，从而得到多元高斯分布的均值和方差，从而成功得到一个逼近真实分布p(X)的p’(X)
(2)求解p’(X|z)的概率分布
(3)通过极大似然估计，最大化p’(X)的概率，但由于xi的维度很大，zi的维度也很大，需要准确找到与xi分布相关的zi，需要大量的采样，因此需要在encoder中引入后验分布p’(z|xi)，让xi与zi关联起来
(4)利用encoder通过假设已知数据的分布，拟合其参数，从而逼近真实的后验分布p’(z|xi),在这里假设后验分布是基于多元高斯分布，则让encoder输出分布的均值和方差
(5)总体流程
三、Diffusion扩散模型 1.前向过程 1.t 时刻的分布等于 t-1 时刻的分布&#43;随机高斯分布的噪音，其中α是噪音的衰减值
2.任意时刻的分布 Xt ，都可以通过 X0 初始状态，以及步数计算出来：
2.逆向过程 已知 Xt，求初始状态的 X0，这里利用贝叶斯公式来预测 X0:">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2023-05-18T16:32:43+08:00">
    <meta property="article:modified_time" content="2023-05-18T16:32:43+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程学习者" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程学习者</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">【生成模型】Stable Diffusion原理&#43;代码</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p><img src="https://images2.imgbox.com/b1/f8/eXZAaryF_o.png" alt="在这里插入图片描述"></p> 
<p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><a href="#_9" rel="nofollow">前言</a></li><li><a href="#Latent_space_21" rel="nofollow">一、Latent space</a></li><li><a href="#AutoEncoder__VAE_27" rel="nofollow">二、AutoEncoder 和 VAE</a></li><li><ul><li><a href="#1AutoEncoder_28" rel="nofollow">1.AutoEncoder:</a></li><li><a href="#2VAE_32" rel="nofollow">2.VAE：</a></li></ul> 
  </li><li><a href="#Diffusion_44" rel="nofollow">三、Diffusion扩散模型</a></li><li><ul><li><a href="#1_45" rel="nofollow">1.前向过程</a></li><li><a href="#2_51" rel="nofollow">2.逆向过程</a></li></ul> 
  </li><li><a href="#_cross_attention_57" rel="nofollow">四、多模态 cross attention</a></li><li><a href="#Stable_Diffusion_63" rel="nofollow">五、Stable Diffusion原理</a></li><li><ul><li><a href="#1_65" rel="nofollow">1.训练过程：</a></li><li><ul><li><a href="#ResnetBlock_78" rel="nofollow">ResnetBlock</a></li><li><a href="#Spatial_TransformerCross_Attention_83" rel="nofollow">Spatial Transformer(Cross Attention)</a></li><li><a href="#DownSampleUpSample_86" rel="nofollow">DownSample/UpSample</a></li></ul> 
   </li><li><a href="#2_91" rel="nofollow">2.前向过程</a></li></ul> 
  </li><li><a href="#_107" rel="nofollow">六、代码解析*</a></li><li><ul><li><a href="#0_109" rel="nofollow">0.安装提示</a></li><li><a href="#1_139" rel="nofollow">1.整体代码</a></li><li><a href="#2unet_220" rel="nofollow">2.unet解析</a></li><li><ul><li><a href="#1selfinput_blocks_222" rel="nofollow">1、self.input_blocks</a></li><li><a href="#2middle_blocks_311" rel="nofollow">2、middle_blocks</a></li><li><a href="#3selfoutput_blocks_394" rel="nofollow">3、self.output_blocks</a></li></ul> 
  </li></ul> 
  </li><li><a href="#_399" rel="nofollow">总结</a></li></ul> 
</div> 
<p></p> 
<hr> 
<h2><a id="_9"></a>前言</h2> 
<p>Stable diffusion是一个基于 <strong>Latent Diffusion Models</strong>（潜在扩散模型，LDMs）的<strong>文图生成</strong>（text-to-image）模型。具体来说，得益于 <strong>Stability AI</strong> 的计算资源支持和在 <strong>LAION-5B</strong> 的一个子集数据支持训练，用于文图生成。</p> 
<p><strong>Latent Diffusion Models</strong> 通过在一个潜在表示空间中迭代“去噪”数据来生成图像，然后将表示结果解码为完整的图像，让文图生成能够在<strong>消费级GPU</strong>上，在10秒级别时间生成图片。目前，Stable Diffusion发布了v2版本。v1版是Latent Diffusion Models的一个具体实现，模型架构设置：自动编码器下采样因子为8，UNet大小为860M，文本编码器为CLIP ViT-L/14。<strong>官方目前提供了以下权重</strong>：<br> <img src="https://images2.imgbox.com/2a/f6/dxsuGnIq_o.png" alt="在这里插入图片描述"></p> 
<hr> 
<p><code>提示：以下是本篇文章正文内容，下面案例可供参考</code></p> 
<h2><a id="Latent_space_21"></a>一、Latent space</h2> 
<p>隐空间是压缩数据的一个表示。数据压缩的目的是学习数据中较重要的信息。以编码器-解码器网络为例，首先使用全卷积神经网(FCN)络学习图片特征，我们<strong>将特征提取中对数据的降维看作一种有损压缩</strong>。由于解码器需要重建(reconstruct)数据，模型必须学习如何储存所有相关信息并且忽略噪音，压缩（降维）的好处在于可以去掉多余的信息从而关注于最关键的特征。</p> 
<h2><a id="AutoEncoder__VAE_27"></a>二、AutoEncoder 和 VAE</h2> 
<h3><a id="1AutoEncoder_28"></a>1.AutoEncoder:</h3> 
<p>(1)AE是一个预训练的自编码器，优化目标是通过 Encoder 压缩数据，再通过decoder 还原数据，使得输入输出的数据尽量相同</p> 
<p>(2)对于图像数据，decoder 还原数据可以看做是一个生成器，由于 decoder 输入数据z属于R空间，输入z的分布无法被固定住，所以大部分生成的图片是无意义的。</p> 
<h3><a id="2VAE_32"></a>2.VAE：</h3> 
<p>(1)给定输入解码器的z一个分布可以解决上述问题，假设一个<strong>服从标准多元高斯分布</strong>的多维随机变量的数据集X，根据已知分布采样得到的zi，来训练decoder神经网络，从而得到多元高斯分布的均值和方差，从而成功得到一个逼近真实分布p(X)的p’(X)</p> 
<p>(2)求解p’(X|z)的概率分布<br> <img src="https://images2.imgbox.com/75/4d/7o9FHvt9_o.png" alt="在这里插入图片描述"><br> (3)通过极大似然估计，最大化p’(X)的概率，但由于xi的维度很大，zi的维度也很大，需要准确找到与xi分布相关的zi，需要大量的采样，因此需要在encoder中引入后验分布p’(z|xi)，让xi与zi关联起来</p> 
<p>(4)利用encoder通过假设已知数据的分布，拟合其参数，从而逼近真实的后验分布p’(z|xi),在这里假设后验分布是基于多元高斯分布，则让encoder输出分布的均值和方差</p> 
<p>(5)总体流程<br> <img src="https://images2.imgbox.com/d3/9e/FiA5UzOO_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="Diffusion_44"></a>三、Diffusion扩散模型</h2> 
<h3><a id="1_45"></a>1.前向过程</h3> 
<blockquote> 
 <p>1.t 时刻的分布等于 t-1 时刻的分布+随机高斯分布的噪音，其中α是噪音的衰减值<br> <img src="https://images2.imgbox.com/ef/46/I19GJAG6_o.png" alt="在这里插入图片描述"><br> 2.任意时刻的分布 <strong>X<sub>t</sub></strong> ，都可以通过 <strong>X<sub>0</sub></strong> 初始状态，以及步数计算出来：<br> <img src="https://images2.imgbox.com/df/4a/3C4e3iLZ_o.png" alt="在这里插入图片描述"></p> 
</blockquote> 
<h3><a id="2_51"></a>2.逆向过程</h3> 
<p>已知 <strong>X<sub>t</sub></strong>，求初始状态的 <strong>X<sub>0</sub></strong>，这里利用<strong>贝叶斯公式</strong>来预测 <strong>X<sub>0</sub></strong>:<br> 首先求已知 <strong>X<sub>t</sub></strong> 的分布求 **X<sub>t-1</sub>**时刻的分布 (详细推导见上篇博客) :<br> <img src="https://images2.imgbox.com/2f/9e/2KPwr2Xz_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="_cross_attention_57"></a>四、多模态 cross attention</h2> 
<p>在 <strong>Unet</strong> 中间层引入<strong>cross attention</strong>，加入多模态的条件(文本，类别，layout，mask)，实现如下：其中<strong>Q来自latent space</strong>，<strong>K，V来自文本等另一序列</strong>:<br> <img src="https://images2.imgbox.com/50/8f/jURZ3Njt_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/e5/68/9iSTZyMG_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="Stable_Diffusion_63"></a>五、Stable Diffusion原理</h2> 
<p><img src="https://images2.imgbox.com/ad/81/kMvF9V2B_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="1_65"></a>1.训练过程：</h3> 
<p>(1)使用预训练的CLIP模型，对需要训练的图像数据生成对应的描述词语。</p> 
<p>(2)使用预训练的通用VAE，先用Encoder，将输入图片降维到 <strong>latent space</strong>（通常降采样倍数4-16）</p> 
<p>(3) 将<strong>latent space</strong>输入diffusion model，进行扩散（正向采样），一步步生成噪声（在这个过程中，通过<strong>权重 β</strong> 控制每步生成噪声的强度，直到生成纯噪声，并记录每步生成噪声的数据，作为GT</p> 
<p>(4)利用cross attention 将 <strong>latent space</strong>的特征与另一模态序列的特征融合，并添加到diffusion model的逆向过程，通过Unet逆向预测每一步需要减少的噪音，通过GT噪音与预测噪音的损失函数计算梯度。</p> 
<p>(5)其中Denoising Unet的结构如下:<br> <img src="https://images2.imgbox.com/95/d6/vUG4Yw18_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="ResnetBlock_78"></a>ResnetBlock</h4> 
<p>左下角小图所示， ResnetBlock 接受两个输入：<strong>latent</strong> 向量经过卷积变换后和经过全连接投影的 <strong>timestep_embedding</strong> 做加和，再和经过 skip connection 的原始 latent 向量做加和，送入另一个卷积层，得到经 Resnet 编码变换后的 latent 输出。</p> 
<p>注意左侧的 ResnetBlock 和右侧的 ResnetBlock 的细微不同。左侧的 Resnet Block 接受的 latent 向量从 UNET 的上一层传入，而右侧的 ResnetBlock 除了接受 UNET 上一层的结果 latent 外，还需要接受左侧对应的 UNET 层的输出，两个 latent concat 起来作为 输入。所以，如果右侧的 ResnetBlock 上层的输出结果 shape 为 (64, 64, 320)，左侧对应 UNET 层的输出结果为 (64, 64, 640)，那么这个 ResnetBlock 得到的输入 latent 的 shape 为 (64, 64, 960)。</p> 
<h4><a id="Spatial_TransformerCross_Attention_83"></a>Spatial Transformer(Cross Attention)</h4> 
<p>右下角小图所示，Spatial Transformer 同样接受两个输入：经过上一个网络模块（一般为 ResnetBlock）处理和变换后的 <strong>latent 向量</strong>（对应的是是图片 token），及对应的 <strong>context embedding</strong>（文本 prompt 经过 CLIP 编码后的输出）， cross attention 之后，得到变换后的 latent 向量（通过注意力机制，将 token 对应的语义信息注入到模型认为应该影响的图片 patch 中）。 Spatial Transformer 输出的 shape 和输入一致，但在对应的位置上融合了语义信息。</p> 
<h4><a id="DownSampleUpSample_86"></a>DownSample/UpSample</h4> 
<p>DownSample 将 latent 向量的前两个轴的大小缩减 50%，而 UpSample 将 latent 向量的前两个轴的大小增大一倍。DownSample 使用一个步长为 2 的二维卷积来实现，同时将输入 latent 向量的 channel 数变化成输出 latent 向量的 channel 数；而 UpSample 使用插值算法来实现，在插值之后进行一个步长为 1 的卷积，同时通过一个步长为 1 的二维卷积来将输入 latent 向量的 channel 数变化成输出 latent 向量的 channel 数。</p> 
<p>需要注意的是，在整个 UNET 执行一次的过程中，timestep_embedding 和 content embedding 始终保持不变。而在 UNET 反复执行多次的过程中，timestep_embedding 每次都会发生变化，而 content embedding 始终保持不变。在迭代过程中，每次 UNET 输出的 noise_slice 都与原来 latent 向量相减，作为下次迭代时，UNET 的 Latent 输入。</p> 
<h3><a id="2_91"></a>2.前向过程</h3> 
<p>一个 Image Auto Encoder-Decoder，用于将 Image 编码成隐含向量<br> ，或者从隐含向量<br> 中还原出图片；<br> 一个 UNET 结构，使用 UNET 进行迭代降噪，在文本引导下进行多轮预测，将随机高斯噪声<br> 转化成图片隐含向量<br> 。</p> 
<blockquote> 
 <p>1.用<strong>文本编码器</strong>（ CLIP 的 ViT-L/14 ），将用户输入的 Prompt 文本转化成 text embedding；<br> 2.根据假定分布（一般是多元高斯分布），生成一张纯噪音图像；<br> 3.利用VAE encoder 压缩到latent space；<br> 4.执行Denoising Unet，利用cross attention融合多模态信息，并预测每一步需要减去的噪音：<br> 5.利用VAE decoder还原到同一分布下的原图大小</p> 
</blockquote> 
<h2><a id="_107"></a>六、代码解析*</h2> 
<h3><a id="0_109"></a>0.安装提示</h3> 
<p><strong>0.1 需要下载 transformers 和 diffusers</strong></p> 
<pre><code>pip install --upgrade diffusers
pip install --upgrade diffusers transformers
</code></pre> 
<p>我的版本：</p> 
<pre><code>diffusers: 0.6.0
transformers: 4.23.1
</code></pre> 
<p><strong>0.2 注册Huggingface token</strong></p> 
<p>进入官网：https://huggingface.co/ ，右上角 settings（注册token，需要邮箱链接验证）：</p> 
<p><img src="https://images2.imgbox.com/a7/8b/ODHK6RAN_o.png" alt="在这里插入图片描述"></p> 
<p><img src="https://images2.imgbox.com/92/9e/qzhgAzHy_o.png" alt="在这里插入图片描述"><br> <strong>0.3 在终端登录</strong>：huggingface-cli login</p> 
<p>命令行输入：huggingface-cli login，使用刚刚的token登陆<br> （输入的token不显示，返回successful即为成功）<br> <img src="https://images2.imgbox.com/98/59/5jaqQko0_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="1_139"></a>1.整体代码</h3> 
<pre><code class="prism language-c"><span class="token number">1</span>、prompt编码为token。编码器为FrozenCLIPEmbedde（包括<span class="token number">1</span>层的 CLIPTextEmbeddings 和<span class="token number">12</span>层的自注意力encoder）
c <span class="token operator">=</span> self<span class="token punctuation">.</span>cond_stage_model<span class="token punctuation">.</span><span class="token function">encode</span><span class="token punctuation">(</span>c<span class="token punctuation">)</span>    # （c为输入的提示语句，重复<span class="token number">2</span>次）  输出：<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">77</span><span class="token punctuation">,</span><span class="token number">768</span><span class="token punctuation">)</span>
    batch_encoding <span class="token operator">=</span> self<span class="token punctuation">.</span><span class="token function">tokenizer</span><span class="token punctuation">(</span>text<span class="token punctuation">,</span> truncation<span class="token operator">=</span>True<span class="token punctuation">,</span> max_length<span class="token operator">=</span>self<span class="token punctuation">.</span>max_length<span class="token punctuation">,</span> return_length<span class="token operator">=</span>True<span class="token punctuation">,</span>
                                        return_overflowing_tokens<span class="token operator">=</span>False<span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">"max_length"</span><span class="token punctuation">,</span> return_tensors<span class="token operator">=</span><span class="token string">"pt"</span><span class="token punctuation">)</span>
    <span class="token macro property"><span class="token directive-hash">#</span> <span class="token directive keyword">self</span><span class="token expression"><span class="token punctuation">.</span>tokenizer来自 transformers包中的 预训练CLIPTokenizer</span></span>
    tokens <span class="token operator">=</span> batch_encoding<span class="token punctuation">[</span><span class="token string">"input_ids"</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token function">to</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>device<span class="token punctuation">)</span>             # <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">77</span><span class="token punctuation">)</span>一句话编码为<span class="token number">77</span>维
    outputs <span class="token operator">=</span> self<span class="token punctuation">.</span><span class="token function">transformer</span><span class="token punctuation">(</span>input_ids<span class="token operator">=</span>tokens<span class="token punctuation">)</span><span class="token punctuation">.</span>last_hidden_state   # <span class="token number">12</span>层self<span class="token operator">-</span>atten，结果（<span class="token number">2</span>，<span class="token number">77</span>，<span class="token number">768</span>）

<span class="token number">2</span>、samples_ddim<span class="token punctuation">,</span> _ <span class="token operator">=</span> sampler<span class="token punctuation">.</span><span class="token function">sample</span><span class="token punctuation">(</span>S<span class="token operator">=</span>opt<span class="token punctuation">.</span>ddim_steps<span class="token punctuation">,</span>
                                   conditioning<span class="token operator">=</span>c<span class="token punctuation">,</span>
                                   batch_size<span class="token operator">=</span>opt<span class="token punctuation">.</span>n_samples<span class="token punctuation">,</span>
                                   shape<span class="token operator">=</span>shape<span class="token punctuation">,</span>
                                   verbose<span class="token operator">=</span>False<span class="token punctuation">,</span>
                                   unconditional_guidance_scale<span class="token operator">=</span>opt<span class="token punctuation">.</span>scale<span class="token punctuation">,</span>
                                   unconditional_conditioning<span class="token operator">=</span>uc<span class="token punctuation">,</span>
                                   eta<span class="token operator">=</span>opt<span class="token punctuation">.</span>ddim_eta<span class="token punctuation">,</span>
                                   x_T<span class="token operator">=</span>start_code<span class="token punctuation">)</span>
     <span class="token number">01</span>、self<span class="token punctuation">.</span><span class="token function">make_schedule</span><span class="token punctuation">(</span>ddim_num_steps<span class="token operator">=</span>S<span class="token punctuation">,</span> ddim_eta<span class="token operator">=</span>eta<span class="token punctuation">,</span> verbose<span class="token operator">=</span>verbose<span class="token punctuation">)</span>    # S<span class="token operator">=</span><span class="token number">50</span>
     # 这一步是ddim中，预先<span class="token keyword">register</span>超参数，如a的连乘等
     <span class="token macro property"><span class="token directive-hash">#</span> <span class="token expression">Data shape <span class="token keyword">for</span> PLMS sampling <span class="token function">is</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">)</span> </span></span>
     <span class="token number">02</span>、samples<span class="token punctuation">,</span> intermediates <span class="token operator">=</span> self<span class="token punctuation">.</span><span class="token function">plms_sampling</span><span class="token punctuation">(</span>conditioning<span class="token punctuation">,</span> size<span class="token punctuation">,</span>
                                                callback<span class="token operator">=</span>callback<span class="token punctuation">,</span>
                                                img_callback<span class="token operator">=</span>img_callback<span class="token punctuation">,</span>
                                                quantize_denoised<span class="token operator">=</span>quantize_x0<span class="token punctuation">,</span>
                                                mask<span class="token operator">=</span>mask<span class="token punctuation">,</span> x0<span class="token operator">=</span>x0<span class="token punctuation">,</span>
                                                ddim_use_original_steps<span class="token operator">=</span>False<span class="token punctuation">,</span>
                                                noise_dropout<span class="token operator">=</span>noise_dropout<span class="token punctuation">,</span>
                                                temperature<span class="token operator">=</span>temperature<span class="token punctuation">,</span>
                                                score_corrector<span class="token operator">=</span>score_corrector<span class="token punctuation">,</span>
                                                corrector_kwargs<span class="token operator">=</span>corrector_kwargs<span class="token punctuation">,</span>
                                                x_T<span class="token operator">=</span>x_T <span class="token punctuation">)</span>
          img <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token function">randn</span><span class="token punctuation">(</span>shape<span class="token punctuation">,</span> device<span class="token operator">=</span>device<span class="token punctuation">)</span>    # <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">)</span>
          <span class="token keyword">for</span> i<span class="token punctuation">,</span> step in <span class="token function">enumerate</span><span class="token punctuation">(</span>iterator<span class="token punctuation">)</span><span class="token operator">:</span>
                index <span class="token operator">=</span> total_steps <span class="token operator">-</span> i <span class="token operator">-</span> <span class="token number">1</span>                                        # index<span class="token operator">=</span><span class="token number">50</span><span class="token operator">-</span>i<span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> step<span class="token operator">=</span><span class="token number">981</span>
                ts <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token function">full</span><span class="token punctuation">(</span><span class="token punctuation">(</span>b<span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span> step<span class="token punctuation">,</span> device<span class="token operator">=</span>device<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span><span class="token keyword">long</span><span class="token punctuation">)</span>       # <span class="token punctuation">[</span><span class="token number">981</span><span class="token punctuation">,</span><span class="token number">981</span><span class="token punctuation">]</span>
                outs <span class="token operator">=</span> self<span class="token punctuation">.</span><span class="token function">p_sample_plms</span><span class="token punctuation">(</span>img<span class="token punctuation">,</span> cond<span class="token punctuation">,</span> ts<span class="token punctuation">,</span> index<span class="token operator">=</span>index<span class="token punctuation">,</span> use_original_steps<span class="token operator">=</span>ddim_use_original_steps<span class="token punctuation">,</span>
                                          quantize_denoised<span class="token operator">=</span>quantize_denoised<span class="token punctuation">,</span> temperature<span class="token operator">=</span>temperature<span class="token punctuation">,</span>
                                          noise_dropout<span class="token operator">=</span>noise_dropout<span class="token punctuation">,</span> score_corrector<span class="token operator">=</span>score_corrector<span class="token punctuation">,</span>
                                          corrector_kwargs<span class="token operator">=</span>corrector_kwargs<span class="token punctuation">,</span>
                                          unconditional_guidance_scale<span class="token operator">=</span>unconditional_guidance_scale<span class="token punctuation">,</span>
                                          unconditional_conditioning<span class="token operator">=</span>unconditional_conditioning<span class="token punctuation">,</span>
                                          old_eps<span class="token operator">=</span>old_eps<span class="token punctuation">,</span> t_next<span class="token operator">=</span>ts_next<span class="token punctuation">)</span>
                    c_in <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token function">cat</span><span class="token punctuation">(</span><span class="token punctuation">[</span>unconditional_conditioning<span class="token punctuation">,</span> c<span class="token punctuation">]</span><span class="token punctuation">)</span>    # 添加一个空字符，与promt拼接
                    e_t_uncond<span class="token punctuation">,</span> <span class="token class-name">e_t</span> <span class="token operator">=</span> self<span class="token punctuation">.</span>model<span class="token punctuation">.</span><span class="token function">apply_model</span><span class="token punctuation">(</span>x_in<span class="token punctuation">,</span> t_in<span class="token punctuation">,</span> c_in<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">chunk</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span>
                          t_emb <span class="token operator">=</span> <span class="token function">timestep_embedding</span><span class="token punctuation">(</span>timesteps<span class="token punctuation">,</span> self<span class="token punctuation">.</span>model_channels<span class="token punctuation">,</span> repeat_only<span class="token operator">=</span>False<span class="token punctuation">)</span>    # timesteps<span class="token operator">:</span><span class="token punctuation">[</span><span class="token number">981</span><span class="token punctuation">,</span><span class="token number">981</span><span class="token punctuation">,</span><span class="token number">981</span><span class="token punctuation">,</span><span class="token number">981</span><span class="token punctuation">]</span> <span class="token operator">-&gt;</span> <span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">320</span><span class="token punctuation">)</span>
                          emb <span class="token operator">=</span> self<span class="token punctuation">.</span><span class="token function">time_embed</span><span class="token punctuation">(</span>t_emb<span class="token punctuation">)</span>           # <span class="token number">2</span><span class="token operator">*</span>linear<span class="token operator">:</span><span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">320</span><span class="token punctuation">)</span> <span class="token operator">-&gt;</span> <span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">1280</span><span class="token punctuation">)</span>
                          
                          <span class="token macro property"><span class="token directive-hash">#</span> <span class="token directive keyword">unet</span><span class="token expression">中带入embed与prompt，具体代码见下节</span></span>
                          <span class="token keyword">for</span> module in self<span class="token punctuation">.</span>input_blocks<span class="token operator">:</span>
                              h <span class="token operator">=</span> <span class="token function">module</span><span class="token punctuation">(</span>h<span class="token punctuation">,</span> emb<span class="token punctuation">,</span> context<span class="token punctuation">)</span>        # 输入<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">)</span> <span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">1280</span><span class="token punctuation">)</span> <span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">77</span><span class="token punctuation">,</span><span class="token number">768</span><span class="token punctuation">)</span>
                              hs<span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span>h<span class="token punctuation">)</span>
                          h <span class="token operator">=</span> self<span class="token punctuation">.</span><span class="token function">middle_block</span><span class="token punctuation">(</span>h<span class="token punctuation">,</span> emb<span class="token punctuation">,</span> context<span class="token punctuation">)</span> 
                          <span class="token keyword">for</span> module in self<span class="token punctuation">.</span>output_blocks<span class="token operator">:</span>
                              h <span class="token operator">=</span> th<span class="token punctuation">.</span><span class="token function">cat</span><span class="token punctuation">(</span><span class="token punctuation">[</span>h<span class="token punctuation">,</span> hs<span class="token punctuation">.</span><span class="token function">pop</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>   # <span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">1280</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span> <span class="token operator">-&gt;</span> <span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">2560</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span>
                              h <span class="token operator">=</span> <span class="token function">module</span><span class="token punctuation">(</span>h<span class="token punctuation">,</span> emb<span class="token punctuation">,</span> context<span class="token punctuation">)</span>

                          <span class="token keyword">return</span> self<span class="token punctuation">.</span><span class="token function">out</span><span class="token punctuation">(</span>h<span class="token punctuation">)</span>                     # （<span class="token number">4</span>，<span class="token number">320</span>，<span class="token number">32</span>，<span class="token number">32</span>）卷积为（<span class="token number">4</span>，<span class="token number">4</span>，<span class="token number">32</span>，<span class="token number">32</span>）

<span class="token number">3</span>、e_t_uncond<span class="token punctuation">,</span> <span class="token class-name">e_t</span> <span class="token operator">=</span> self<span class="token punctuation">.</span>model<span class="token punctuation">.</span><span class="token function">apply_model</span><span class="token punctuation">(</span>x_in<span class="token punctuation">,</span> t_in<span class="token punctuation">,</span> c_in<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">chunk</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span>   # 上步中得到的结果拆开：（<span class="token number">2</span>，<span class="token number">4</span>，<span class="token number">32</span>，<span class="token number">32</span>
   <span class="token class-name">e_t</span> <span class="token operator">=</span> e_t_uncond <span class="token operator">+</span> unconditional_guidance_scale <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token class-name">e_t</span> <span class="token operator">-</span> e_t_uncond<span class="token punctuation">)</span>  # 用<span class="token number">7.5</span>乘以二者差距，再加回空语句生成的图
   x_prev<span class="token punctuation">,</span> pred_x0 <span class="token operator">=</span> <span class="token function">get_x_prev_and_pred_x0</span><span class="token punctuation">(</span><span class="token class-name">e_t</span><span class="token punctuation">,</span> index<span class="token punctuation">)</span>                  # DDIM计算：<span class="token class-name">e_t</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">)</span> index<span class="token operator">:</span><span class="token number">49</span>  <span class="token operator">-&gt;</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">)</span>

<span class="token number">4</span>、x_samples_ddim <span class="token operator">=</span> model<span class="token punctuation">.</span><span class="token function">decode_first_stage</span><span class="token punctuation">(</span>samples_ddim<span class="token punctuation">)</span>    # <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">)</span>
        h <span class="token operator">=</span> self<span class="token punctuation">.</span><span class="token function">conv_in</span><span class="token punctuation">(</span>z<span class="token punctuation">)</span>    # 卷积<span class="token number">4</span><span class="token operator">-&gt;</span><span class="token number">512</span>
        x <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional<span class="token punctuation">.</span><span class="token function">interpolate</span><span class="token punctuation">(</span>h<span class="token punctuation">,</span> scale_factor<span class="token operator">=</span><span class="token number">2.0</span><span class="token punctuation">,</span> mode<span class="token operator">=</span><span class="token string">"nearest"</span><span class="token punctuation">)</span>  #（<span class="token number">2</span>，<span class="token number">512</span>，<span class="token number">64</span>，<span class="token number">64</span>）
        h <span class="token operator">=</span> self<span class="token punctuation">.</span>up<span class="token punctuation">[</span>i_level<span class="token punctuation">]</span><span class="token punctuation">.</span>block<span class="token punctuation">[</span>i_block<span class="token punctuation">]</span><span class="token punctuation">(</span>h）    # 经过几次卷积与上采样
        h <span class="token operator">=</span> self<span class="token punctuation">.</span><span class="token function">norm_out</span><span class="token punctuation">(</span>h<span class="token punctuation">)</span>   # <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">128</span><span class="token punctuation">,</span><span class="token number">256</span><span class="token punctuation">,</span><span class="token number">256</span><span class="token punctuation">)</span>
        h <span class="token operator">=</span> <span class="token function">nonlinearity</span><span class="token punctuation">(</span>h<span class="token punctuation">)</span>    # x<span class="token operator">*</span>torch<span class="token punctuation">.</span><span class="token function">sigmoid</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        h <span class="token operator">=</span> self<span class="token punctuation">.</span><span class="token function">conv_out</span><span class="token punctuation">(</span>h<span class="token punctuation">)</span>   # <span class="token function">conv</span><span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span> <span class="token operator">-</span>》（<span class="token number">2</span>，<span class="token number">3</span>，<span class="token number">256</span>，<span class="token number">256</span>）

<span class="token number">5</span>、后处理
x_samples_ddim <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token function">clamp</span><span class="token punctuation">(</span><span class="token punctuation">(</span>x_samples_ddim <span class="token operator">+</span> <span class="token number">1.0</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">2.0</span><span class="token punctuation">,</span> min<span class="token operator">=</span><span class="token number">0.0</span><span class="token punctuation">,</span> max<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">)</span>
x_samples_ddim <span class="token operator">=</span> x_samples_ddim<span class="token punctuation">.</span><span class="token function">cpu</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">permute</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">numpy</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
x_checked_image<span class="token punctuation">,</span> has_nsfw_concept <span class="token operator">=</span> <span class="token function">check_safety</span><span class="token punctuation">(</span>x_samples_ddim<span class="token punctuation">)</span>
x_checked_image_torch <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token function">from_numpy</span><span class="token punctuation">(</span>x_checked_image<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">permute</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>
x_sample <span class="token operator">=</span> <span class="token number">255.</span> <span class="token operator">*</span> <span class="token function">rearrange</span><span class="token punctuation">(</span>x_sample<span class="token punctuation">.</span><span class="token function">cpu</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">numpy</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'c h w -&gt; h w c'</span><span class="token punctuation">)</span>
img <span class="token operator">=</span> Image<span class="token punctuation">.</span><span class="token function">fromarray</span><span class="token punctuation">(</span>x_sample<span class="token punctuation">.</span><span class="token function">astype</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>uint8<span class="token punctuation">)</span><span class="token punctuation">)</span>
img<span class="token punctuation">.</span><span class="token function">save</span><span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span><span class="token function">join</span><span class="token punctuation">(</span>sample_path<span class="token punctuation">,</span> f<span class="token string">"{base_count:05}.png"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<h3><a id="2unet_220"></a>2.unet解析</h3> 
<p>DDIM中的Unet 包含<strong>输入模块</strong>、<strong>中间模块</strong>、<strong>输出模块</strong>三部分：</p> 
<h4><a id="1selfinput_blocks_222"></a>1、self.input_blocks</h4> 
<p>包含12个不同的 <strong>TimestepEmbedSequential</strong>结构，下面列举三种：</p> 
<pre><code class="prism language-c"><span class="token number">1</span>、self<span class="token punctuation">.</span>input_blocks
<span class="token function">ModuleList</span><span class="token punctuation">(</span>
  <span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">TimestepEmbedSequential</span><span class="token punctuation">(</span>
    <span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">Conv2d</span><span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">320</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
  <span class="token punctuation">)</span>
  <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">TimestepEmbedSequential</span><span class="token punctuation">(</span>
    <span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">ResBlock</span><span class="token punctuation">(</span>
      <span class="token punctuation">(</span>in_layers<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">Sequential</span><span class="token punctuation">(</span>
        <span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">GroupNorm32</span><span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">320</span><span class="token punctuation">,</span> eps<span class="token operator">=</span><span class="token number">1e-05</span><span class="token punctuation">,</span> affine<span class="token operator">=</span>True<span class="token punctuation">)</span>
        <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">SiLU</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">Conv2d</span><span class="token punctuation">(</span><span class="token number">320</span><span class="token punctuation">,</span> <span class="token number">320</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
      <span class="token punctuation">)</span>
      <span class="token punctuation">(</span>h_upd<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">Identity</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
      <span class="token punctuation">(</span>x_upd<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">Identity</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
      <span class="token punctuation">(</span>emb_layers<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">Sequential</span><span class="token punctuation">(</span>
        <span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">SiLU</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">Linear</span><span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">1280</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token number">320</span><span class="token punctuation">,</span> bias<span class="token operator">=</span>True<span class="token punctuation">)</span>
      <span class="token punctuation">)</span>
      <span class="token punctuation">(</span>out_layers<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">Sequential</span><span class="token punctuation">(</span>
        <span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">GroupNorm32</span><span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">320</span><span class="token punctuation">,</span> eps<span class="token operator">=</span><span class="token number">1e-05</span><span class="token punctuation">,</span> affine<span class="token operator">=</span>True<span class="token punctuation">)</span>
        <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">SiLU</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">Dropout</span><span class="token punctuation">(</span>p<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span>False<span class="token punctuation">)</span>
        <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">Conv2d</span><span class="token punctuation">(</span><span class="token number">320</span><span class="token punctuation">,</span> <span class="token number">320</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
      <span class="token punctuation">)</span>
      <span class="token punctuation">(</span>skip_connection<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">Identity</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token punctuation">)</span>
    <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">SpatialTransformer</span><span class="token punctuation">(</span>
      <span class="token punctuation">(</span>norm<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">GroupNorm</span><span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">320</span><span class="token punctuation">,</span> eps<span class="token operator">=</span><span class="token number">1e-06</span><span class="token punctuation">,</span> affine<span class="token operator">=</span>True<span class="token punctuation">)</span>
      <span class="token punctuation">(</span>proj_in<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">Conv2d</span><span class="token punctuation">(</span><span class="token number">320</span><span class="token punctuation">,</span> <span class="token number">320</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
      <span class="token punctuation">(</span>transformer_blocks<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">ModuleList</span><span class="token punctuation">(</span>
        <span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">BasicTransformerBlock</span><span class="token punctuation">(</span>
          <span class="token punctuation">(</span>attn1<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">CrossAttention</span><span class="token punctuation">(</span>
            <span class="token punctuation">(</span>to_q<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">Linear</span><span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">320</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token number">320</span><span class="token punctuation">,</span> bias<span class="token operator">=</span>False<span class="token punctuation">)</span>
            <span class="token punctuation">(</span>to_k<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">Linear</span><span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">320</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token number">320</span><span class="token punctuation">,</span> bias<span class="token operator">=</span>False<span class="token punctuation">)</span>
            <span class="token punctuation">(</span>to_v<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">Linear</span><span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">320</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token number">320</span><span class="token punctuation">,</span> bias<span class="token operator">=</span>False<span class="token punctuation">)</span>
            <span class="token punctuation">(</span>to_out<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">Sequential</span><span class="token punctuation">(</span>
              <span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">Linear</span><span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">320</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token number">320</span><span class="token punctuation">,</span> bias<span class="token operator">=</span>True<span class="token punctuation">)</span>
              <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">Dropout</span><span class="token punctuation">(</span>p<span class="token operator">=</span><span class="token number">0.0</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span>False<span class="token punctuation">)</span>
            <span class="token punctuation">)</span>
          <span class="token punctuation">)</span>
          <span class="token punctuation">(</span>ff<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">FeedForward</span><span class="token punctuation">(</span>
            <span class="token punctuation">(</span>net<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">Sequential</span><span class="token punctuation">(</span>
              <span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">GEGLU</span><span class="token punctuation">(</span>
                <span class="token punctuation">(</span>proj<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">Linear</span><span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">320</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token number">2560</span><span class="token punctuation">,</span> bias<span class="token operator">=</span>True<span class="token punctuation">)</span>
              <span class="token punctuation">)</span>
              <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">Dropout</span><span class="token punctuation">(</span>p<span class="token operator">=</span><span class="token number">0.0</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span>False<span class="token punctuation">)</span>
              <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">Linear</span><span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">1280</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token number">320</span><span class="token punctuation">,</span> bias<span class="token operator">=</span>True<span class="token punctuation">)</span>
            <span class="token punctuation">)</span>
          <span class="token punctuation">)</span>
          <span class="token punctuation">(</span>attn2<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">CrossAttention</span><span class="token punctuation">(</span>
            <span class="token punctuation">(</span>to_q<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">Linear</span><span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">320</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token number">320</span><span class="token punctuation">,</span> bias<span class="token operator">=</span>False<span class="token punctuation">)</span>
            <span class="token punctuation">(</span>to_k<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">Linear</span><span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">768</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token number">320</span><span class="token punctuation">,</span> bias<span class="token operator">=</span>False<span class="token punctuation">)</span>
            <span class="token punctuation">(</span>to_v<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">Linear</span><span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">768</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token number">320</span><span class="token punctuation">,</span> bias<span class="token operator">=</span>False<span class="token punctuation">)</span>
            <span class="token punctuation">(</span>to_out<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">Sequential</span><span class="token punctuation">(</span>
              <span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">Linear</span><span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">320</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token number">320</span><span class="token punctuation">,</span> bias<span class="token operator">=</span>True<span class="token punctuation">)</span>
              <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">Dropout</span><span class="token punctuation">(</span>p<span class="token operator">=</span><span class="token number">0.0</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span>False<span class="token punctuation">)</span>
            <span class="token punctuation">)</span>
          <span class="token punctuation">)</span>
          <span class="token punctuation">(</span>norm1<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">LayerNorm</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">320</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span> eps<span class="token operator">=</span><span class="token number">1e-05</span><span class="token punctuation">,</span> elementwise_affine<span class="token operator">=</span>True<span class="token punctuation">)</span>
          <span class="token punctuation">(</span>norm2<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">LayerNorm</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">320</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span> eps<span class="token operator">=</span><span class="token number">1e-05</span><span class="token punctuation">,</span> elementwise_affine<span class="token operator">=</span>True<span class="token punctuation">)</span>
          <span class="token punctuation">(</span>norm3<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">LayerNorm</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">320</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span> eps<span class="token operator">=</span><span class="token number">1e-05</span><span class="token punctuation">,</span> elementwise_affine<span class="token operator">=</span>True<span class="token punctuation">)</span>
        <span class="token punctuation">)</span>
      <span class="token punctuation">)</span>
      <span class="token punctuation">(</span>proj_out<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">Conv2d</span><span class="token punctuation">(</span><span class="token number">320</span><span class="token punctuation">,</span> <span class="token number">320</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token punctuation">)</span>
  <span class="token punctuation">)</span>

  <span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">TimestepEmbedSequential</span><span class="token punctuation">(</span>
    <span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">Downsample</span><span class="token punctuation">(</span>
      <span class="token punctuation">(</span>op<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">Conv2d</span><span class="token punctuation">(</span><span class="token number">640</span><span class="token punctuation">,</span> <span class="token number">640</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token punctuation">)</span>
  <span class="token punctuation">)</span>
</code></pre> 
<p><strong>前向过程</strong>：<br> 为h添加emb和交与propmt的交叉注意力，会执行多次</p> 
<pre><code class="prism language-c">emb_out <span class="token operator">=</span> self<span class="token punctuation">.</span><span class="token function">emb_layers</span><span class="token punctuation">(</span>emb<span class="token punctuation">)</span>      # （<span class="token number">4</span>，<span class="token number">1280</span>）卷积为（<span class="token number">4</span>，<span class="token number">320</span>）
h <span class="token operator">=</span> h <span class="token operator">+</span> emb_out                     # （<span class="token number">4</span>，<span class="token number">320</span>，<span class="token number">32</span>，<span class="token number">32</span>）<span class="token operator">+</span>（<span class="token number">4</span>，<span class="token number">320</span>，<span class="token number">1</span>，<span class="token number">1</span>）

x <span class="token operator">=</span> self<span class="token punctuation">.</span><span class="token function">attn1</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span><span class="token function">norm1</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">+</span> x                     # 自注意力：x（<span class="token number">4</span>，<span class="token number">1024</span>，<span class="token number">320</span>）映射到qkv，均<span class="token number">320</span>维
x <span class="token operator">=</span> self<span class="token punctuation">.</span><span class="token function">attn2</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span><span class="token function">norm2</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">,</span> context<span class="token operator">=</span>context<span class="token punctuation">)</span> <span class="token operator">+</span> x    # 交叉注意力：context（<span class="token number">4</span><span class="token punctuation">,</span><span class="token number">77</span><span class="token punctuation">,</span><span class="token number">768</span>）映射到kv的<span class="token number">320</span>维
x <span class="token operator">=</span> self<span class="token punctuation">.</span><span class="token function">ff</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span><span class="token function">norm3</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">+</span> x
</code></pre> 
<p>噪音图像h（4，4，32，32）在其中变化为：（4，320，32，32）（4，320，16，16）（4，640，16，16）（4，1280，8，8）（4，1280，4，4）</p> 
<h4><a id="2middle_blocks_311"></a>2、middle_blocks</h4> 
<pre><code class="prism language-c"><span class="token function">TimestepEmbedSequential</span><span class="token punctuation">(</span>
  <span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">ResBlock</span><span class="token punctuation">(</span>
    <span class="token punctuation">(</span>in_layers<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">Sequential</span><span class="token punctuation">(</span>
      <span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">GroupNorm32</span><span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">1280</span><span class="token punctuation">,</span> eps<span class="token operator">=</span><span class="token number">1e-05</span><span class="token punctuation">,</span> affine<span class="token operator">=</span>True<span class="token punctuation">)</span>
      <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">SiLU</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
      <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">Conv2d</span><span class="token punctuation">(</span><span class="token number">1280</span><span class="token punctuation">,</span> <span class="token number">1280</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token punctuation">)</span>
    <span class="token punctuation">(</span>h_upd<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">Identity</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token punctuation">(</span>x_upd<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">Identity</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token punctuation">(</span>emb_layers<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">Sequential</span><span class="token punctuation">(</span>
      <span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">SiLU</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
      <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">Linear</span><span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">1280</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token number">1280</span><span class="token punctuation">,</span> bias<span class="token operator">=</span>True<span class="token punctuation">)</span>
    <span class="token punctuation">)</span>
    <span class="token punctuation">(</span>out_layers<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">Sequential</span><span class="token punctuation">(</span>
      <span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">GroupNorm32</span><span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">1280</span><span class="token punctuation">,</span> eps<span class="token operator">=</span><span class="token number">1e-05</span><span class="token punctuation">,</span> affine<span class="token operator">=</span>True<span class="token punctuation">)</span>
      <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">SiLU</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
      <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">Dropout</span><span class="token punctuation">(</span>p<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span>False<span class="token punctuation">)</span>
      <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">Conv2d</span><span class="token punctuation">(</span><span class="token number">1280</span><span class="token punctuation">,</span> <span class="token number">1280</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token punctuation">)</span>
    <span class="token punctuation">(</span>skip_connection<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">Identity</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
  <span class="token punctuation">)</span>
  <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">SpatialTransformer</span><span class="token punctuation">(</span>
    <span class="token punctuation">(</span>norm<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">GroupNorm</span><span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">1280</span><span class="token punctuation">,</span> eps<span class="token operator">=</span><span class="token number">1e-06</span><span class="token punctuation">,</span> affine<span class="token operator">=</span>True<span class="token punctuation">)</span>
    <span class="token punctuation">(</span>proj_in<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">Conv2d</span><span class="token punctuation">(</span><span class="token number">1280</span><span class="token punctuation">,</span> <span class="token number">1280</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token punctuation">(</span>transformer_blocks<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">ModuleList</span><span class="token punctuation">(</span>
      <span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">BasicTransformerBlock</span><span class="token punctuation">(</span>
        <span class="token punctuation">(</span>attn1<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">CrossAttention</span><span class="token punctuation">(</span>
          <span class="token punctuation">(</span>to_q<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">Linear</span><span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">1280</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token number">1280</span><span class="token punctuation">,</span> bias<span class="token operator">=</span>False<span class="token punctuation">)</span>
          <span class="token punctuation">(</span>to_k<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">Linear</span><span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">1280</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token number">1280</span><span class="token punctuation">,</span> bias<span class="token operator">=</span>False<span class="token punctuation">)</span>
          <span class="token punctuation">(</span>to_v<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">Linear</span><span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">1280</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token number">1280</span><span class="token punctuation">,</span> bias<span class="token operator">=</span>False<span class="token punctuation">)</span>
          <span class="token punctuation">(</span>to_out<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">Sequential</span><span class="token punctuation">(</span>
            <span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">Linear</span><span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">1280</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token number">1280</span><span class="token punctuation">,</span> bias<span class="token operator">=</span>True<span class="token punctuation">)</span>
            <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">Dropout</span><span class="token punctuation">(</span>p<span class="token operator">=</span><span class="token number">0.0</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span>False<span class="token punctuation">)</span>
          <span class="token punctuation">)</span>
        <span class="token punctuation">)</span>
        <span class="token punctuation">(</span>ff<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">FeedForward</span><span class="token punctuation">(</span>
          <span class="token punctuation">(</span>net<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">Sequential</span><span class="token punctuation">(</span>
            <span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">GEGLU</span><span class="token punctuation">(</span>
              <span class="token punctuation">(</span>proj<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">Linear</span><span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">1280</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token number">10240</span><span class="token punctuation">,</span> bias<span class="token operator">=</span>True<span class="token punctuation">)</span>
            <span class="token punctuation">)</span>
            <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">Dropout</span><span class="token punctuation">(</span>p<span class="token operator">=</span><span class="token number">0.0</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span>False<span class="token punctuation">)</span>
            <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">Linear</span><span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">5120</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token number">1280</span><span class="token punctuation">,</span> bias<span class="token operator">=</span>True<span class="token punctuation">)</span>
          <span class="token punctuation">)</span>
        <span class="token punctuation">)</span>
        <span class="token punctuation">(</span>attn2<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">CrossAttention</span><span class="token punctuation">(</span>
          <span class="token punctuation">(</span>to_q<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">Linear</span><span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">1280</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token number">1280</span><span class="token punctuation">,</span> bias<span class="token operator">=</span>False<span class="token punctuation">)</span>
          <span class="token punctuation">(</span>to_k<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">Linear</span><span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">768</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token number">1280</span><span class="token punctuation">,</span> bias<span class="token operator">=</span>False<span class="token punctuation">)</span>
          <span class="token punctuation">(</span>to_v<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">Linear</span><span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">768</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token number">1280</span><span class="token punctuation">,</span> bias<span class="token operator">=</span>False<span class="token punctuation">)</span>
          <span class="token punctuation">(</span>to_out<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">Sequential</span><span class="token punctuation">(</span>
            <span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">Linear</span><span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">1280</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token number">1280</span><span class="token punctuation">,</span> bias<span class="token operator">=</span>True<span class="token punctuation">)</span>
            <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">Dropout</span><span class="token punctuation">(</span>p<span class="token operator">=</span><span class="token number">0.0</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span>False<span class="token punctuation">)</span>
          <span class="token punctuation">)</span>
        <span class="token punctuation">)</span>
        <span class="token punctuation">(</span>norm1<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">LayerNorm</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1280</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span> eps<span class="token operator">=</span><span class="token number">1e-05</span><span class="token punctuation">,</span> elementwise_affine<span class="token operator">=</span>True<span class="token punctuation">)</span>
        <span class="token punctuation">(</span>norm2<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">LayerNorm</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1280</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span> eps<span class="token operator">=</span><span class="token number">1e-05</span><span class="token punctuation">,</span> elementwise_affine<span class="token operator">=</span>True<span class="token punctuation">)</span>
        <span class="token punctuation">(</span>norm3<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">LayerNorm</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1280</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span> eps<span class="token operator">=</span><span class="token number">1e-05</span><span class="token punctuation">,</span> elementwise_affine<span class="token operator">=</span>True<span class="token punctuation">)</span>
      <span class="token punctuation">)</span>
    <span class="token punctuation">)</span>
    <span class="token punctuation">(</span>proj_out<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">Conv2d</span><span class="token punctuation">(</span><span class="token number">1280</span><span class="token punctuation">,</span> <span class="token number">1280</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
  <span class="token punctuation">)</span>
  <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">ResBlock</span><span class="token punctuation">(</span>
    <span class="token punctuation">(</span>in_layers<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">Sequential</span><span class="token punctuation">(</span>
      <span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">GroupNorm32</span><span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">1280</span><span class="token punctuation">,</span> eps<span class="token operator">=</span><span class="token number">1e-05</span><span class="token punctuation">,</span> affine<span class="token operator">=</span>True<span class="token punctuation">)</span>
      <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">SiLU</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
      <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">Conv2d</span><span class="token punctuation">(</span><span class="token number">1280</span><span class="token punctuation">,</span> <span class="token number">1280</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token punctuation">)</span>
    <span class="token punctuation">(</span>h_upd<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">Identity</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token punctuation">(</span>x_upd<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">Identity</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token punctuation">(</span>emb_layers<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">Sequential</span><span class="token punctuation">(</span>
      <span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">SiLU</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
      <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">Linear</span><span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">1280</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token number">1280</span><span class="token punctuation">,</span> bias<span class="token operator">=</span>True<span class="token punctuation">)</span>
    <span class="token punctuation">)</span>
    <span class="token punctuation">(</span>out_layers<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">Sequential</span><span class="token punctuation">(</span>
      <span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">GroupNorm32</span><span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">1280</span><span class="token punctuation">,</span> eps<span class="token operator">=</span><span class="token number">1e-05</span><span class="token punctuation">,</span> affine<span class="token operator">=</span>True<span class="token punctuation">)</span>
      <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">SiLU</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
      <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">Dropout</span><span class="token punctuation">(</span>p<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span>False<span class="token punctuation">)</span>
      <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">Conv2d</span><span class="token punctuation">(</span><span class="token number">1280</span><span class="token punctuation">,</span> <span class="token number">1280</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token punctuation">)</span>
    <span class="token punctuation">(</span>skip_connection<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token function">Identity</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
  <span class="token punctuation">)</span>
</code></pre> 
<h4><a id="3selfoutput_blocks_394"></a>3、self.output_blocks</h4> 
<p>与输入模块相同，包含12个 <strong>TimestepEmbedSequential</strong>，顺序相反</p> 
<hr> 
<h2><a id="_399"></a>总结</h2> 
<p><code>整体结构比较简单，先用预训练CLIP将prompt变为token; DDIM模型将噪音与token逆扩散为图像;再采用VAE的decoder将图像复原到正常大小：</code></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/78766c8c443066b40ed2ba6027c41aed/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">头歌大数据——MapReduce 基础实战 答案 无解析</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/cbeb5e4612475505b034125863683bc1/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Open Ai 常见接口参数说明以及常见报错总结</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程学习者.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>