<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Qualcomm® AI Engine Direct 使用手册（15） - 编程学习者</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcxuexizhe.github.io/posts/70da6b6b19620b751e56f215d87630d1/">
  <meta property="og:site_name" content="编程学习者">
  <meta property="og:title" content="Qualcomm® AI Engine Direct 使用手册（15）">
  <meta property="og:description" content="Qualcomm® AI Engine Direct 使用手册（15） 6 工具6.1 型号转换6.2 模型准备 6 工具 本页介绍了适用于 Linux/Android 和 Windows 开发人员的各种 SDK 工具和功能。对于不同开发者的集成流程，请参阅概述页面了解更多信息。
笔记
在本机 Windows 中使用转换器工具时，用户需要通过Python执行（参见下面的示例）
$ python qnn-onnx-converter &lt;选项&gt;
笔记
库的扩展名命名：对于 Windows 开发人员，请将以下部分中的所有“.so”文件替换为类似的“.dll”文件。请参阅平台差异了解更多详细信息。
有关转换器的更多详细信息，请参阅转换器。
[*] Windows 平台上的 qnn-profile-viewer 不支持 libQnnGpuProfilingReader.dll。
[†] 不支持 ARM64EC/X 二进制格式。
6.1 型号转换 qnn-张量流转换器
qnn -tensorflow-converter工具将模型从 TensorFlow 框架转换为 CPP 文件，将模型表示为一系列 QNN API 调用。此外，还会生成包含模型静态权重的二进制文件。
usage: qnn-tensorflow-converter -d INPUT_NAME INPUT_DIM --out_node OUT_NAMES [--input_type INPUT_NAME INPUT_TYPE] [--input_dtype INPUT_NAME INPUT_DTYPE] [--input_encoding INPUT_ENCODING [INPUT_ENCODING .">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2023-12-28T21:09:26+08:00">
    <meta property="article:modified_time" content="2023-12-28T21:09:26+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程学习者" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程学习者</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Qualcomm® AI Engine Direct 使用手册（15）</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>Qualcomm® AI Engine Direct 使用手册（15）</h4> 
 <ul><li><a href="#6___3" rel="nofollow">6 工具</a></li><li><ul><li><a href="#61__25" rel="nofollow">6.1 型号转换</a></li><li><a href="#62__1198" rel="nofollow">6.2 模型准备</a></li></ul> 
 </li></ul> 
</div> 
<p></p> 
<hr> 
<h2><a id="6___3"></a>6 工具</h2> 
<p>本页介绍了适用于 Linux/Android 和 Windows 开发人员的各种 SDK 工具和功能。对于不同开发者的集成流程，请参阅概述页面了解更多信息。</p> 
<p><img src="https://images2.imgbox.com/54/8b/HtlY5Z4V_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/7c/fd/zkhxfnpV_o.png" alt="在这里插入图片描述"></p> 
<blockquote> 
 <p>笔记<br> 在本机 Windows 中使用转换器工具时，用户需要通过Python执行（参见下面的示例）<br> $ python qnn-onnx-converter &lt;选项&gt;</p> 
</blockquote> 
<p>笔记</p> 
<ul><li> <p>库的扩展名命名：对于 Windows 开发人员，请将以下部分中的所有“.so”文件替换为类似的“.dll”文件。请参阅平台差异了解更多详细信息。</p> </li><li> <p>有关转换器的更多详细信息，请参阅转换器。</p> </li><li> <p>[*] Windows 平台上的 qnn-profile-viewer 不支持 libQnnGpuProfilingReader.dll。</p> </li><li> <p>[†] 不支持 ARM64EC/X 二进制格式。</p> </li></ul> 
<h3><a id="61__25"></a>6.1 型号转换</h3> 
<p>qnn-张量流转换器<br> qnn -tensorflow-converter工具将模型从 TensorFlow 框架转换为 CPP 文件，将模型表示为一系列 QNN API 调用。此外，还会生成包含模型静态权重的二进制文件。</p> 
<pre><code class="prism language-cpp">usage<span class="token operator">:</span> qnn<span class="token operator">-</span>tensorflow<span class="token operator">-</span>converter <span class="token operator">-</span>d INPUT_NAME INPUT_DIM <span class="token operator">--</span>out_node OUT_NAMES
                                <span class="token punctuation">[</span><span class="token operator">--</span>input_type INPUT_NAME INPUT_TYPE<span class="token punctuation">]</span>
                                <span class="token punctuation">[</span><span class="token operator">--</span>input_dtype INPUT_NAME INPUT_DTYPE<span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token operator">--</span>input_encoding INPUT_ENCODING <span class="token punctuation">[</span>INPUT_ENCODING <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
                                <span class="token punctuation">[</span><span class="token operator">--</span>input_layout INPUT_NAME INPUT_LAYOUT<span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token operator">--</span>custom_io CUSTOM_IO<span class="token punctuation">]</span>
                                <span class="token punctuation">[</span><span class="token operator">--</span>show_unconsumed_nodes<span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token operator">--</span>saved_model_tag SAVED_MODEL_TAG<span class="token punctuation">]</span>
                                <span class="token punctuation">[</span><span class="token operator">--</span>saved_model_signature_key SAVED_MODEL_SIGNATURE_KEY<span class="token punctuation">]</span>
                                <span class="token punctuation">[</span><span class="token operator">--</span>quantization_overrides QUANTIZATION_OVERRIDES<span class="token punctuation">]</span>
                                <span class="token punctuation">[</span><span class="token operator">--</span>keep_quant_nodes<span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token operator">--</span>disable_batchnorm_folding<span class="token punctuation">]</span>
                                <span class="token punctuation">[</span><span class="token operator">--</span>keep_disconnected_nodes<span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token operator">--</span>input_list INPUT_LIST<span class="token punctuation">]</span>
                                <span class="token punctuation">[</span><span class="token operator">--</span>param_quantizer PARAM_QUANTIZER<span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token operator">--</span>act_quantizer ACT_QUANTIZER<span class="token punctuation">]</span>
                                <span class="token punctuation">[</span><span class="token operator">--</span>algorithms ALGORITHMS <span class="token punctuation">[</span>ALGORITHMS <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token operator">--</span>bias_bw BIAS_BW<span class="token punctuation">]</span>
                                <span class="token punctuation">[</span><span class="token operator">--</span>act_bw ACT_BW<span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token operator">--</span>weight_bw WEIGHT_BW<span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token operator">--</span>ignore_encodings<span class="token punctuation">]</span>
                                <span class="token punctuation">[</span><span class="token operator">--</span>use_per_row_quantization<span class="token punctuation">]</span>
                                <span class="token punctuation">[</span><span class="token operator">--</span>use_per_channel_quantization <span class="token punctuation">[</span>USE_PER_CHANNEL_QUANTIZATION <span class="token punctuation">[</span>USE_PER_CHANNEL_QUANTIZATION <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
                                <span class="token punctuation">[</span><span class="token operator">--</span>use_native_input_files<span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token operator">--</span>use_native_dtype<span class="token punctuation">]</span>
                                <span class="token punctuation">[</span><span class="token operator">--</span>use_native_output_files<span class="token punctuation">]</span> <span class="token operator">--</span>input_network INPUT_NETWORK
                                <span class="token punctuation">[</span><span class="token operator">--</span>debug <span class="token punctuation">[</span>DEBUG<span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token operator">-</span>o OUTPUT_PATH<span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token operator">--</span>copyright_file COPYRIGHT_FILE<span class="token punctuation">]</span>
                                <span class="token punctuation">[</span><span class="token operator">--</span>float_bw FLOAT_BW<span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token operator">--</span>float_bias_bw FLOAT_BIAS_BW<span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token operator">--</span>overwrite_model_prefix<span class="token punctuation">]</span>
                                <span class="token punctuation">[</span><span class="token operator">--</span>exclude_named_tensors<span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token operator">--</span>op_package_lib OP_PACKAGE_LIB<span class="token punctuation">]</span>
                                <span class="token punctuation">[</span><span class="token operator">--</span>restrict_quantization_steps ENCODING_MIN<span class="token punctuation">,</span> ENCODING_MAX<span class="token punctuation">]</span>
                                <span class="token punctuation">[</span><span class="token operator">--</span>converter_op_package_lib CONVERTER_OP_PACKAGE_LIB<span class="token punctuation">]</span>
                                <span class="token punctuation">[</span><span class="token operator">-</span>p PACKAGE_NAME <span class="token operator">|</span> <span class="token operator">--</span>op_package_config CUSTOM_OP_CONFIG_PATHS <span class="token punctuation">[</span>CUSTOM_OP_CONFIG_PATHS <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
                                <span class="token punctuation">[</span><span class="token operator">-</span>h<span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token operator">--</span>arch_checker<span class="token punctuation">]</span>

Script to convert TF model into QNN

required arguments<span class="token operator">:</span>
  <span class="token operator">-</span>d INPUT_NAME INPUT_DIM<span class="token punctuation">,</span> <span class="token operator">--</span>input_dim INPUT_NAME INPUT_DIM
                        The names <span class="token operator">and</span> dimensions of the network input layers specified in the format
                        <span class="token punctuation">[</span>input_name comma<span class="token operator">-</span>separated<span class="token operator">-</span>dimensions<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token keyword">for</span> example<span class="token operator">:</span>
                            <span class="token char">'data'</span> <span class="token number">1</span><span class="token punctuation">,</span><span class="token number">224</span><span class="token punctuation">,</span><span class="token number">224</span><span class="token punctuation">,</span><span class="token number">3</span>
                        Note that the quotes should always be included in order to
                        handlespecial characters<span class="token punctuation">,</span> spaces<span class="token punctuation">,</span> etc<span class="token punctuation">.</span>
                        For multiple inputs specify multiple <span class="token operator">--</span>input_dim on the command line like<span class="token operator">:</span>
                            <span class="token operator">--</span>input_dim <span class="token char">'data1'</span> <span class="token number">1</span><span class="token punctuation">,</span><span class="token number">224</span><span class="token punctuation">,</span><span class="token number">224</span><span class="token punctuation">,</span><span class="token number">3</span> <span class="token operator">--</span>input_dim <span class="token char">'data2'</span> <span class="token number">1</span><span class="token punctuation">,</span><span class="token number">50</span><span class="token punctuation">,</span><span class="token number">100</span><span class="token punctuation">,</span><span class="token number">3</span>
  <span class="token operator">--</span>out_node OUT_NODE<span class="token punctuation">,</span>  <span class="token operator">--</span>out_name OUT_NAMES
                        Name of the graph<span class="token number">'</span>s output nodes<span class="token punctuation">.</span> Multiple output nodes should be
                        provided separately like<span class="token operator">:</span>
                            <span class="token operator">--</span>out_node out_1 <span class="token operator">--</span>out_node out_2
  <span class="token operator">--</span>input_network INPUT_NETWORK<span class="token punctuation">,</span> <span class="token operator">-</span>i INPUT_NETWORK
                        Path to the source framework model<span class="token punctuation">.</span>

optional arguments<span class="token operator">:</span>
  <span class="token operator">--</span>input_type INPUT_NAME INPUT_TYPE<span class="token punctuation">,</span> <span class="token operator">-</span>t INPUT_NAME INPUT_TYPE
                        Type of data expected by each input op<span class="token operator">/</span>layer<span class="token punctuation">.</span> Type <span class="token keyword">for</span> each input is
                        <span class="token operator">|</span><span class="token keyword">default</span><span class="token operator">|</span> <span class="token keyword">if</span> <span class="token operator">not</span> specified<span class="token punctuation">.</span> For example<span class="token operator">:</span> <span class="token string">"data"</span> image<span class="token punctuation">.</span>Note that the quotes
                        should always be included in order to handle special characters<span class="token punctuation">,</span> spaces<span class="token punctuation">,</span>etc<span class="token punctuation">.</span>
                        For multiple inputs specify multiple <span class="token operator">--</span>input_type on the command line<span class="token punctuation">.</span>
                        Eg<span class="token operator">:</span>
                            <span class="token operator">--</span>input_type <span class="token string">"data1"</span> image <span class="token operator">--</span>input_type <span class="token string">"data2"</span> opaque
                        These options get used by DSP runtime <span class="token operator">and</span> following descriptions state how
                        input will be handled <span class="token keyword">for</span> each option<span class="token punctuation">.</span>
                        Image<span class="token operator">:</span>
                        Input is <span class="token keyword">float</span> between <span class="token number">0</span><span class="token operator">-</span><span class="token number">255</span> <span class="token operator">and</span> the input<span class="token char">'s mean is 0.0f and the input'</span>s
                        max is <span class="token number">255.0f</span><span class="token punctuation">.</span> We will cast the <span class="token keyword">float</span> to uint8ts <span class="token operator">and</span> pass the uint8ts to the
                        DSP<span class="token punctuation">.</span>
                        Default<span class="token operator">:</span>
                        Pass the input as floats to the dsp directly <span class="token operator">and</span> the DSP will quantize it<span class="token punctuation">.</span>
                        Opaque<span class="token operator">:</span>
                        Assumes input is <span class="token keyword">float</span> because the consumer <span class="token function">layer</span><span class="token punctuation">(</span>i<span class="token punctuation">.</span>e next layer<span class="token punctuation">)</span> <span class="token keyword">requires</span>
                        it as <span class="token keyword">float</span><span class="token punctuation">,</span> therefore it won<span class="token number">'</span>t be quantized<span class="token punctuation">.</span>
                        Choices supported<span class="token operator">:</span>
                            image
                            <span class="token keyword">default</span>
                            opaque
  <span class="token operator">--</span>input_dtype INPUT_NAME INPUT_DTYPE
                        The names <span class="token operator">and</span> datatype of the network input layers specified in the format
                        <span class="token punctuation">[</span>input_name datatype<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token keyword">for</span> example<span class="token operator">:</span>
                            <span class="token char">'data'</span> <span class="token char">'float32'</span><span class="token punctuation">.</span>
                        Default is float32 <span class="token keyword">if</span> <span class="token operator">not</span> specified<span class="token punctuation">.</span>
                        Note that the quotes should always be included in order to handle special
                        characters<span class="token punctuation">,</span> spaces<span class="token punctuation">,</span> etc<span class="token punctuation">.</span>
                        For multiple inputs specify multiple <span class="token operator">--</span>input_dtype on the command line like<span class="token operator">:</span>
                            <span class="token operator">--</span>input_dtype <span class="token char">'data1'</span> <span class="token char">'float32'</span> <span class="token operator">--</span>input_dtype <span class="token char">'data2'</span> <span class="token char">'float32'</span>
  <span class="token operator">--</span>input_encoding INPUT_ENCODING <span class="token punctuation">[</span>INPUT_ENCODING <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token operator">-</span>e INPUT_ENCODING <span class="token punctuation">[</span>INPUT_ENCODING <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span>
                        Usage<span class="token operator">:</span>     <span class="token operator">--</span>input_encoding <span class="token string">"INPUT_NAME"</span> INPUT_ENCODING_IN
                        <span class="token punctuation">[</span>INPUT_ENCODING_OUT<span class="token punctuation">]</span>
                        Input encoding of the network inputs<span class="token punctuation">.</span> Default is bgr<span class="token punctuation">.</span>
                        e<span class="token punctuation">.</span>g<span class="token punctuation">.</span>
                            <span class="token operator">--</span>input_encoding <span class="token string">"data"</span> rgba
                        Quotes must wrap the input node name to handle special characters<span class="token punctuation">,</span>
                        spaces<span class="token punctuation">,</span> etc<span class="token punctuation">.</span> To specify encodings <span class="token keyword">for</span> multiple inputs<span class="token punctuation">,</span> invoke
                        <span class="token operator">--</span>input_encoding <span class="token keyword">for</span> each one<span class="token punctuation">.</span>
                        e<span class="token punctuation">.</span>g<span class="token punctuation">.</span>
                            <span class="token operator">--</span>input_encoding <span class="token string">"data1"</span> rgba <span class="token operator">--</span>input_encoding <span class="token string">"data2"</span> other
                        Optionally<span class="token punctuation">,</span> an output encoding may be specified <span class="token keyword">for</span> an input node by
                        providing a second encoding<span class="token punctuation">.</span> The <span class="token keyword">default</span> output encoding is bgr<span class="token punctuation">.</span>
                        e<span class="token punctuation">.</span>g<span class="token punctuation">.</span>
                            <span class="token operator">--</span>input_encoding <span class="token string">"data3"</span> rgba rgb
                        Input encoding types<span class="token operator">:</span>
                            image color encodings<span class="token operator">:</span> bgr<span class="token punctuation">,</span>rgb<span class="token punctuation">,</span> nv21<span class="token punctuation">,</span> nv12<span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
                            time_series<span class="token operator">:</span> <span class="token keyword">for</span> inputs of rnn models<span class="token punctuation">;</span>
                            other<span class="token operator">:</span> <span class="token operator">not</span> available above <span class="token operator">or</span> is unknown<span class="token punctuation">.</span>
                        Supported encodings<span class="token operator">:</span>
                            bgr
                            rgb
                            rgba
                            argb32
                            nv21
                            nv12
                            time_series
                            other
  <span class="token operator">--</span>input_layout INPUT_NAME INPUT_LAYOUT<span class="token punctuation">,</span> <span class="token operator">-</span>l INPUT_NAME INPUT_LAYOUT
                        Layout of each input tensor<span class="token punctuation">.</span> If <span class="token operator">not</span> specified<span class="token punctuation">,</span> it will use the <span class="token keyword">default</span>
                        based on the Source Framework<span class="token punctuation">,</span> shape of input <span class="token operator">and</span> input encoding<span class="token punctuation">.</span>
                        Accepted values are<span class="token operator">-</span>
                            NCDHW<span class="token punctuation">,</span> NDHWC<span class="token punctuation">,</span> NCHW<span class="token punctuation">,</span> NHWC<span class="token punctuation">,</span> NFC<span class="token punctuation">,</span> NCF<span class="token punctuation">,</span> NTF<span class="token punctuation">,</span> TNF<span class="token punctuation">,</span> NF<span class="token punctuation">,</span> NC<span class="token punctuation">,</span> F<span class="token punctuation">,</span> NONTRIVIAL
                        N <span class="token operator">=</span> Batch<span class="token punctuation">,</span> C <span class="token operator">=</span> Channels<span class="token punctuation">,</span> D <span class="token operator">=</span> Depth<span class="token punctuation">,</span> H <span class="token operator">=</span> Height<span class="token punctuation">,</span> W <span class="token operator">=</span> Width<span class="token punctuation">,</span> F <span class="token operator">=</span> Feature<span class="token punctuation">,</span> T <span class="token operator">=</span> Time
                        NDHWC<span class="token operator">/</span>NCDHW used <span class="token keyword">for</span> <span class="token number">5</span>d inputs
                        NHWC<span class="token operator">/</span>NCHW used <span class="token keyword">for</span> <span class="token number">4</span>d image<span class="token operator">-</span>like inputs
                        NFC<span class="token operator">/</span>NCF used <span class="token keyword">for</span> inputs to Conv1D <span class="token operator">or</span> other <span class="token number">1</span>D ops
                        NTF<span class="token operator">/</span>TNF used <span class="token keyword">for</span> inputs with time steps like the ones used <span class="token keyword">for</span> LSTM op
                        NF used <span class="token keyword">for</span> <span class="token number">2</span>D inputs<span class="token punctuation">,</span> like the inputs to Dense<span class="token operator">/</span>FullyConnected layers
                        NC used <span class="token keyword">for</span> <span class="token number">2</span>D inputs with <span class="token number">1</span> <span class="token keyword">for</span> batch <span class="token operator">and</span> other <span class="token keyword">for</span> <span class="token function">Channels</span> <span class="token punctuation">(</span>rarely used<span class="token punctuation">)</span>
                        F used <span class="token keyword">for</span> <span class="token number">1</span>D inputs<span class="token punctuation">,</span> e<span class="token punctuation">.</span>g<span class="token punctuation">.</span> Bias tensor
                        NONTRIVIAL <span class="token keyword">for</span> everything elseFor multiple inputs specify multiple
                        <span class="token operator">--</span>input_layout on the command line<span class="token punctuation">.</span>
                        Eg<span class="token operator">:</span>
                           <span class="token operator">--</span>input_layout <span class="token string">"data1"</span> NCHW <span class="token operator">--</span>input_layout <span class="token string">"data2"</span> NCHW
  <span class="token operator">--</span>custom_io CUSTOM_IO
                        Use <span class="token keyword">this</span> option to specify a yaml file <span class="token keyword">for</span> custom IO
  <span class="token operator">--</span>show_unconsumed_nodes
                        Displays a list of unconsumed nodes<span class="token punctuation">,</span> <span class="token keyword">if</span> there any are found<span class="token punctuation">.</span> Nodes which are
                        unconsumed <span class="token keyword">do</span> <span class="token operator">not</span> violate the structural fidelity of thegenerated graph<span class="token punctuation">.</span>
  <span class="token operator">--</span>saved_model_tag SAVED_MODEL_TAG
                        Specify the tag to seletet a MetaGraph from savedmodel<span class="token punctuation">.</span> ex<span class="token operator">:</span>
                        <span class="token operator">--</span>saved_model_tag serve<span class="token punctuation">.</span> Default value will be <span class="token char">'serve'</span> when it is <span class="token operator">not</span>
                        assigned<span class="token punctuation">.</span>
  <span class="token operator">--</span>saved_model_signature_key SAVED_MODEL_SIGNATURE_KEY
                        Specify signature key to select input <span class="token operator">and</span> output of the model<span class="token punctuation">.</span> ex<span class="token operator">:</span>
                        <span class="token operator">--</span>saved_model_signature_key serving_default<span class="token punctuation">.</span> Default value will be
                        <span class="token char">'serving_default'</span> when it is <span class="token operator">not</span> assigned
  <span class="token operator">--</span>disable_batchnorm_folding
  <span class="token operator">--</span>keep_disconnected_nodes
                        Disable Optimization that removes Ops <span class="token operator">not</span> connected to the main graph<span class="token punctuation">.</span>
                        This optimization uses output names provided over commandline OR
                        inputs<span class="token operator">/</span>outputs extracted from the Source model to determine the main graph
  <span class="token operator">--</span>debug <span class="token punctuation">[</span>DEBUG<span class="token punctuation">]</span>       Run the converter in debug mode<span class="token punctuation">.</span>
  <span class="token operator">-</span>o OUTPUT_PATH<span class="token punctuation">,</span> <span class="token operator">--</span>output_path OUTPUT_PATH
                        Path where the converted Output model should be saved<span class="token punctuation">.</span>If <span class="token operator">not</span> specified<span class="token punctuation">,</span> the
                        converter model will be written to a file with same name as the input model
  <span class="token operator">--</span>copyright_file COPYRIGHT_FILE
                        Path to copyright file<span class="token punctuation">.</span> If provided<span class="token punctuation">,</span> the content of the file will be added
                        to the output model<span class="token punctuation">.</span>
  <span class="token operator">--</span>float_bw FLOAT_BW   Use the <span class="token operator">--</span>float_bw option to select the bitwidth to use when <span class="token keyword">using</span> <span class="token keyword">float</span> <span class="token keyword">for</span>
                        <span class="token function">parameters</span><span class="token punctuation">(</span>weights<span class="token operator">/</span>bias<span class="token punctuation">)</span> <span class="token operator">and</span> activations <span class="token keyword">for</span> all ops  <span class="token operator">or</span> specific <span class="token function">Op</span> <span class="token punctuation">(</span>via
                        encodings<span class="token punctuation">)</span> selected through encoding<span class="token punctuation">,</span> either <span class="token number">32</span> <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span> <span class="token operator">or</span> <span class="token number">16.</span>
  <span class="token operator">--</span>overwrite_model_prefix
                        If option passed<span class="token punctuation">,</span> model generator will use the output path name to use as
                        model prefix to name functions in <span class="token operator">&lt;</span>qnn_model_name<span class="token operator">&gt;</span><span class="token punctuation">.</span>cpp<span class="token punctuation">.</span> <span class="token punctuation">(</span>Useful <span class="token keyword">for</span> running
                        multiple models at once<span class="token punctuation">)</span> eg<span class="token operator">:</span> ModelName_composeGraphs<span class="token punctuation">.</span> Default is to use
                        generic <span class="token string">"QnnModel_"</span><span class="token punctuation">.</span>
  <span class="token operator">--</span>exclude_named_tensors
                        Remove <span class="token keyword">using</span> source framework tensorNames<span class="token punctuation">;</span> instead use a counter <span class="token keyword">for</span> naming
                        tensors<span class="token punctuation">.</span> Note<span class="token operator">:</span> This can potentially help to reduce the <span class="token keyword">final</span> model library
                        that will be <span class="token function">generated</span><span class="token punctuation">(</span>Recommended <span class="token keyword">for</span> deploying model<span class="token punctuation">)</span><span class="token punctuation">.</span> Default is False<span class="token punctuation">.</span>
  <span class="token operator">-</span>h<span class="token punctuation">,</span> <span class="token operator">--</span>help            show <span class="token keyword">this</span> help message <span class="token operator">and</span> exit

Quantizer Options<span class="token operator">:</span>
  <span class="token operator">--</span>quantization_overrides QUANTIZATION_OVERRIDES
                        Use <span class="token keyword">this</span> option to specify a json file with parameters to use <span class="token keyword">for</span>
                        quantization<span class="token punctuation">.</span> These will <span class="token keyword">override</span> any quantization data carried from
                        <span class="token function">conversion</span> <span class="token punctuation">(</span>eg TF fake quantization<span class="token punctuation">)</span> <span class="token operator">or</span> calculated during the normal
                        quantization process<span class="token punctuation">.</span> Format defined as per AIMET specification<span class="token punctuation">.</span>
  <span class="token operator">--</span>keep_quant_nodes    Use <span class="token keyword">this</span> option to keep activation quantization nodes in the graph rather
                        than stripping them<span class="token punctuation">.</span>
  <span class="token operator">--</span>input_list INPUT_LIST
                        Path to a file specifying the input data<span class="token punctuation">.</span> This file should be a plain text
                        file<span class="token punctuation">,</span> containing one <span class="token operator">or</span> more absolute file paths per line<span class="token punctuation">.</span> Each path is
                        expected to point to a binary file containing one input in the <span class="token string">"raw"</span> format<span class="token punctuation">,</span>
                        ready to be consumed by the quantizer without any further preprocessing<span class="token punctuation">.</span>
                        Multiple files per line separated by spaces indicate multiple inputs to the
                        network<span class="token punctuation">.</span> See documentation <span class="token keyword">for</span> more details<span class="token punctuation">.</span> Must be specified <span class="token keyword">for</span>
                        quantization<span class="token punctuation">.</span> All subsequent quantization options are ignored when <span class="token keyword">this</span> is
                        <span class="token operator">not</span> provided<span class="token punctuation">.</span>
  <span class="token operator">--</span>param_quantizer PARAM_QUANTIZER
                        Optional parameter to indicate the weight<span class="token operator">/</span>bias quantizer to use<span class="token punctuation">.</span> Must be
                        followed by one of the following options<span class="token operator">:</span> <span class="token string">"tf"</span><span class="token operator">:</span> Uses the real min<span class="token operator">/</span>max of the
                        data <span class="token operator">and</span> specified <span class="token function">bitwidth</span> <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span> <span class="token string">"enhanced"</span><span class="token operator">:</span> Uses an algorithm useful
                        <span class="token keyword">for</span> quantizing models with <span class="token keyword">long</span> tails present in the weight distribution
                        <span class="token string">"adjusted"</span><span class="token operator">:</span> Uses an adjusted min<span class="token operator">/</span>max <span class="token keyword">for</span> computing the range<span class="token punctuation">,</span> particularly
                        good <span class="token keyword">for</span> denoise models <span class="token string">"symmetric"</span><span class="token operator">:</span> Ensures min <span class="token operator">and</span> max have the same
                        absolute values about zero<span class="token punctuation">.</span> Data will be stored as <span class="token keyword">int</span>#_t data such that the
                        offset is always <span class="token number">0.</span>
  <span class="token operator">--</span>act_quantizer ACT_QUANTIZER
                        Optional parameter to indicate the activation quantizer to use<span class="token punctuation">.</span> Must be
                        followed by one of the following options<span class="token operator">:</span> <span class="token string">"tf"</span><span class="token operator">:</span> Uses the real min<span class="token operator">/</span>max of the
                        data <span class="token operator">and</span> specified <span class="token function">bitwidth</span> <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span> <span class="token string">"enhanced"</span><span class="token operator">:</span> Uses an algorithm useful
                        <span class="token keyword">for</span> quantizing models with <span class="token keyword">long</span> tails present in the weight distribution
                        <span class="token string">"adjusted"</span><span class="token operator">:</span> Uses an adjusted min<span class="token operator">/</span>max <span class="token keyword">for</span> computing the range<span class="token punctuation">,</span> particularly
                        good <span class="token keyword">for</span> denoise models <span class="token string">"symmetric"</span><span class="token operator">:</span> Ensures min <span class="token operator">and</span> max have the same
                        absolute values about zero<span class="token punctuation">.</span> Data will be stored as <span class="token keyword">int</span>#_t data such that the
                        offset is always <span class="token number">0.</span>
  <span class="token operator">--</span>algorithms ALGORITHMS <span class="token punctuation">[</span>ALGORITHMS <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span>
                        Use <span class="token keyword">this</span> option to enable <span class="token keyword">new</span> optimization algorithms<span class="token punctuation">.</span> Usage is<span class="token operator">:</span>
                        <span class="token operator">--</span>algorithms <span class="token operator">&lt;</span>algo_name1<span class="token operator">&gt;</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> The available optimization algorithms are<span class="token operator">:</span>
                        <span class="token string">"cle"</span> <span class="token operator">-</span> Cross layer equalization includes a number of methods <span class="token keyword">for</span> equalizing
                        weights <span class="token operator">and</span> biases across layers in order to rectify imbalances that cause
                        quantization errors<span class="token punctuation">.</span>
  <span class="token operator">--</span>bias_bw BIAS_BW     Use the <span class="token operator">--</span>bias_bw option to select the bitwidth to use when quantizing the
                        biases<span class="token punctuation">,</span> either <span class="token number">8</span> <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span> <span class="token operator">or</span> <span class="token number">32.</span>
  <span class="token operator">--</span>act_bw ACT_BW       Use the <span class="token operator">--</span>act_bw option to select the bitwidth to use when quantizing the
                        activations<span class="token punctuation">,</span> either <span class="token number">8</span> <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span> <span class="token operator">or</span> <span class="token number">16.</span>
  <span class="token operator">--</span>weight_bw WEIGHT_BW
                        Use the <span class="token operator">--</span>weight_bw option to select the bitwidth to use when quantizing the
                        weights<span class="token punctuation">,</span> currently only <span class="token number">8</span> <span class="token function">bit</span> <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span> supported<span class="token punctuation">.</span>
 <span class="token operator">--</span>float_bias_bw FLOAT_BIAS_BW
                        Use the <span class="token operator">--</span>float_bias_bw option to select the bitwidth to use when biases are
                        in <span class="token keyword">float</span><span class="token punctuation">,</span> either <span class="token number">32</span> <span class="token operator">or</span> <span class="token number">16.</span>
  <span class="token operator">--</span>ignore_encodings    Use only quantizer generated encodings<span class="token punctuation">,</span> ignoring any user <span class="token operator">or</span> model provided
                        encodings<span class="token punctuation">.</span>
                        Note<span class="token operator">:</span> Cannot use <span class="token operator">--</span>ignore_encodings with <span class="token operator">--</span>quantization_overrides
  <span class="token operator">--</span>use_per_row_quantization
                        Use <span class="token keyword">this</span> option to enable rowwise quantization of Matmul <span class="token operator">and</span> FullyConnected
                        ops<span class="token punctuation">.</span>
  <span class="token operator">--</span>use_per_channel_quantization <span class="token punctuation">[</span>USE_PER_CHANNEL_QUANTIZATION <span class="token punctuation">[</span>USE_PER_CHANNEL_QUANTIZATION <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
                        Use per<span class="token operator">-</span>channel quantization <span class="token keyword">for</span> convolution<span class="token operator">-</span>based op weights<span class="token punctuation">.</span>
                        Note<span class="token operator">:</span> This will replace built<span class="token operator">-</span>in model QAT encodings when used <span class="token keyword">for</span> a given
                        weight<span class="token punctuation">.</span>Usage <span class="token string">"--use_per_channel_quantization"</span> to enable <span class="token operator">or</span> "<span class="token operator">--</span>
                        use_per_channel_quantization <span class="token boolean">false</span>" <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span> to disable
  <span class="token operator">--</span>use_native_input_files
                        Boolean flag to indicate how to read input files<span class="token operator">:</span>
                        <span class="token number">1.</span> <span class="token keyword">float</span> <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">:</span> reads inputs as floats <span class="token operator">and</span> quantizes <span class="token keyword">if</span> necessary based
                        on quantization parameters in the model<span class="token punctuation">.</span>
                        <span class="token number">2.</span> native<span class="token operator">:</span> reads inputs assuming the data type to be native to the
                        model<span class="token punctuation">.</span> For ex<span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token keyword">uint8_t</span><span class="token punctuation">.</span>
  <span class="token operator">--</span>use_native_dtype    Note<span class="token operator">:</span> This option is deprecated<span class="token punctuation">,</span> use <span class="token operator">--</span>use_native_input_files option in
                        future<span class="token punctuation">.</span>
                        Boolean flag to indicate how to read input files<span class="token operator">:</span>
                        <span class="token number">1.</span> <span class="token keyword">float</span> <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">:</span> reads inputs as floats <span class="token operator">and</span> quantizes <span class="token keyword">if</span> necessary based
                        on quantization parameters in the model<span class="token punctuation">.</span>
                        <span class="token number">2.</span> native<span class="token operator">:</span> reads inputs assuming the data type to be native to the
                        model<span class="token punctuation">.</span> For ex<span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token keyword">uint8_t</span><span class="token punctuation">.</span>
  <span class="token operator">--</span>use_native_output_files
                        Use <span class="token keyword">this</span> option to indicate the data type of the output files
                        <span class="token number">1.</span> <span class="token keyword">float</span> <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">:</span> output the file as floats<span class="token punctuation">.</span>
                        <span class="token number">2.</span> native<span class="token operator">:</span> outputs the file that is native to the model<span class="token punctuation">.</span> For ex<span class="token punctuation">.</span><span class="token punctuation">,</span>
                        <span class="token keyword">uint8_t</span><span class="token punctuation">.</span>
  <span class="token operator">--</span>restrict_quantization_steps ENCODING_MIN<span class="token punctuation">,</span> ENCODING_MAX
                        Specifies the number of steps to use <span class="token keyword">for</span> computing quantization encodings
                        such that scale <span class="token operator">=</span> <span class="token punctuation">(</span>max <span class="token operator">-</span> min<span class="token punctuation">)</span> <span class="token operator">/</span> number of quantization steps<span class="token punctuation">.</span>
                        The option should be passed as a space separated pair of hexadecimal string
                        minimum <span class="token operator">and</span> maximum values<span class="token punctuation">.</span> i<span class="token punctuation">.</span>e<span class="token punctuation">.</span> <span class="token operator">--</span>restrict_quantization_steps <span class="token string">"MIN MAX"</span><span class="token punctuation">.</span>
                        Please note that <span class="token keyword">this</span> is a hexadecimal string literal <span class="token operator">and</span> <span class="token operator">not</span> a <span class="token keyword">signed</span>
                        integer<span class="token punctuation">,</span> to supply a negative value an <span class="token keyword">explicit</span> minus sign is required<span class="token punctuation">.</span>
                        E<span class="token punctuation">.</span>g<span class="token punctuation">.</span><span class="token operator">--</span>restrict_quantization_steps <span class="token string">"-0x80 0x7F"</span> indicates an example <span class="token number">8</span> bit range<span class="token punctuation">,</span>
                        <span class="token operator">--</span>restrict_quantization_steps <span class="token string">"-0x8000 0x7F7F"</span> indicates an example <span class="token number">16</span>
                        bit range<span class="token punctuation">.</span> This argument is required <span class="token keyword">for</span> <span class="token number">16</span><span class="token operator">-</span>bit Matmul operations<span class="token punctuation">.</span>


 Custom Op Package Options<span class="token operator">:</span>
  <span class="token operator">--</span>op_package_lib OP_PACKAGE_LIB<span class="token punctuation">,</span> <span class="token operator">-</span>opl OP_PACKAGE_LIB
                        Use <span class="token keyword">this</span> argument to pass an op package library <span class="token keyword">for</span> quantization<span class="token punctuation">.</span> Must be in
                        the form
                        <span class="token operator">&lt;</span>op_package_lib_path<span class="token operator">:</span>interfaceProviderName<span class="token operator">&gt;</span> <span class="token operator">and</span> be separated by a
                        comma <span class="token keyword">for</span> multiple package libs
  <span class="token operator">-</span>p PACKAGE_NAME<span class="token punctuation">,</span> <span class="token operator">--</span>package_name PACKAGE_NAME
                        A global package name to be used <span class="token keyword">for</span> each node in the Model<span class="token punctuation">.</span>cpp file<span class="token punctuation">.</span>
                        Defaults to Qnn header defined package name
  <span class="token operator">--</span>converter_op_package_lib CONVERTER_OP_PACKAGE_LIB<span class="token punctuation">,</span> <span class="token operator">-</span>cpl CONVERTER_OP_PACKAGE_LIB
                        Absolute path to converter op package library compiled by the OpPackage
                        generator<span class="token punctuation">.</span> Must be separated by a comma <span class="token keyword">for</span> multiple package libraries<span class="token punctuation">.</span>
                        Note<span class="token operator">:</span> Libraries must follow the same order as the xml files<span class="token punctuation">.</span>
                        E<span class="token punctuation">.</span>g<span class="token punctuation">.</span><span class="token number">1</span><span class="token operator">:</span> <span class="token operator">--</span>converter_op_package_lib absolute_path_to<span class="token operator">/</span>libExample<span class="token punctuation">.</span>so
                        E<span class="token punctuation">.</span>g<span class="token punctuation">.</span><span class="token number">2</span><span class="token operator">:</span> <span class="token operator">-</span>cpl absolute_path_to<span class="token operator">/</span>libExample1<span class="token punctuation">.</span>so<span class="token punctuation">,</span>absolute_path_to<span class="token operator">/</span>libExample2<span class="token punctuation">.</span>so
  <span class="token operator">--</span>op_package_config OP_PACKAGE_CONFIG <span class="token punctuation">[</span>OP_PACKAGE_CONFIG <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token operator">-</span>opc OP_PACKAGE_CONFIG <span class="token punctuation">[</span>OP_PACKAGE_CONFIG <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span>
                        Path to a Qnn Op Package XML configuration file that contains user defined
                        custom operations<span class="token punctuation">.</span>

Architecture Checker <span class="token function">Options</span><span class="token punctuation">(</span>Experimental<span class="token punctuation">)</span><span class="token operator">:</span>
  <span class="token operator">--</span>arch_checker        Note<span class="token operator">:</span> This option will be soon deprecated<span class="token punctuation">.</span> Use the qnn<span class="token operator">-</span>architecture<span class="token operator">-</span>checker tool to achieve the same result<span class="token punctuation">.</span>

Note<span class="token operator">:</span> Only one of<span class="token operator">:</span> <span class="token punctuation">{<!-- --></span><span class="token char">'package_name'</span><span class="token punctuation">,</span> <span class="token char">'op_package_config'</span><span class="token punctuation">}</span> can be specified

</code></pre> 
<p>基本命令行用法如下：</p> 
<pre><code class="prism language-cpp">$ qnn<span class="token operator">-</span>tensorflow<span class="token operator">-</span>converter <span class="token operator">-</span>i <span class="token operator">&lt;</span>path<span class="token operator">&gt;</span><span class="token operator">/</span>frozen_graph<span class="token punctuation">.</span>pb
                    <span class="token operator">-</span>d <span class="token operator">&lt;</span>network_input_name<span class="token operator">&gt;</span> <span class="token operator">&lt;</span>dims<span class="token operator">&gt;</span>
                    <span class="token operator">--</span>out_node <span class="token operator">&lt;</span>network_output_name<span class="token operator">&gt;</span>
                    <span class="token operator">-</span>o <span class="token operator">&lt;</span>optional_output_path<span class="token operator">&gt;</span>
                    <span class="token operator">--</span>allow_unconsumed_nodes  # optional<span class="token punctuation">,</span> but most likely will be need <span class="token keyword">for</span> larger models
                    <span class="token operator">-</span>p <span class="token operator">&lt;</span>optional_package_name<span class="token operator">&gt;</span> # Defaults to <span class="token string">"qti.aisw"</span>

</code></pre> 
<p>qnn-tflite-转换器<br> qnn-tflite-converter工具将 TFLite 模型转换为 CPP 文件，将模型表示为一系列 QNN API 调用。此外，还会生成包含模型静态权重的二进制文件。</p> 
<pre><code class="prism language-cpp">usage<span class="token operator">:</span> qnn<span class="token operator">-</span>tflite<span class="token operator">-</span>converter <span class="token operator">-</span>d INPUT_NAME INPUT_DIM <span class="token punctuation">[</span><span class="token operator">--</span>out_node OUT_NAMES<span class="token punctuation">]</span>
                            <span class="token punctuation">[</span><span class="token operator">--</span>input_type INPUT_NAME INPUT_TYPE<span class="token punctuation">]</span>
                            <span class="token punctuation">[</span><span class="token operator">--</span>input_dtype INPUT_NAME INPUT_DTYPE<span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token operator">--</span>input_encoding INPUT_ENCODING <span class="token punctuation">[</span>INPUT_ENCODING <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
                            <span class="token punctuation">[</span><span class="token operator">--</span>input_layout INPUT_NAME INPUT_LAYOUT<span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token operator">--</span>custom_io CUSTOM_IO<span class="token punctuation">]</span>
                            <span class="token punctuation">[</span><span class="token operator">--</span>dump_relay DUMP_RELAY<span class="token punctuation">]</span>
                            <span class="token punctuation">[</span><span class="token operator">--</span>quantization_overrides QUANTIZATION_OVERRIDES<span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token operator">--</span>keep_quant_nodes<span class="token punctuation">]</span>
                            <span class="token punctuation">[</span><span class="token operator">--</span>disable_batchnorm_folding<span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token operator">--</span>keep_disconnected_nodes<span class="token punctuation">]</span>
                            <span class="token punctuation">[</span><span class="token operator">--</span>input_list INPUT_LIST<span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token operator">--</span>param_quantizer PARAM_QUANTIZER<span class="token punctuation">]</span>
                            <span class="token punctuation">[</span><span class="token operator">--</span>act_quantizer ACT_QUANTIZER<span class="token punctuation">]</span>
                            <span class="token punctuation">[</span><span class="token operator">--</span>algorithms ALGORITHMS <span class="token punctuation">[</span>ALGORITHMS <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token operator">--</span>bias_bw BIAS_BW<span class="token punctuation">]</span>
                            <span class="token punctuation">[</span><span class="token operator">--</span>act_bw ACT_BW<span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token operator">--</span>weight_bw WEIGHT_BW<span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token operator">--</span>ignore_encodings<span class="token punctuation">]</span>
                            <span class="token punctuation">[</span><span class="token operator">--</span>use_per_row_quantization<span class="token punctuation">]</span>
                            <span class="token punctuation">[</span><span class="token operator">--</span>use_per_channel_quantization <span class="token punctuation">[</span>USE_PER_CHANNEL_QUANTIZATION <span class="token punctuation">[</span>USE_PER_CHANNEL_QUANTIZATION <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
                            <span class="token punctuation">[</span><span class="token operator">--</span>use_native_input_files<span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token operator">--</span>use_native_dtype<span class="token punctuation">]</span>
                            <span class="token punctuation">[</span><span class="token operator">--</span>use_native_output_files<span class="token punctuation">]</span> <span class="token operator">--</span>input_network INPUT_NETWORK
                            <span class="token punctuation">[</span><span class="token operator">--</span>debug <span class="token punctuation">[</span>DEBUG<span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token operator">-</span>o OUTPUT_PATH<span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token operator">--</span>copyright_file COPYRIGHT_FILE<span class="token punctuation">]</span>
                            <span class="token punctuation">[</span><span class="token operator">--</span>float_bw FLOAT_BW<span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token operator">--</span>float_bias_bw FLOAT_BIAS_BW<span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token operator">--</span>overwrite_model_prefix<span class="token punctuation">]</span>
                            <span class="token punctuation">[</span><span class="token operator">--</span>exclude_named_tensors<span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token operator">--</span>op_package_lib OP_PACKAGE_LIB<span class="token punctuation">]</span>
                            <span class="token punctuation">[</span><span class="token operator">--</span>restrict_quantization_steps ENCODING_MIN<span class="token punctuation">,</span> ENCODING_MAX<span class="token punctuation">]</span>
                            <span class="token punctuation">[</span><span class="token operator">--</span>converter_op_package_lib CONVERTER_OP_PACKAGE_LIB<span class="token punctuation">]</span>
                            <span class="token punctuation">[</span><span class="token operator">-</span>p PACKAGE_NAME <span class="token operator">|</span> <span class="token operator">--</span>op_package_config CUSTOM_OP_CONFIG_PATHS <span class="token punctuation">[</span>CUSTOM_OP_CONFIG_PATHS <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
                            <span class="token punctuation">[</span><span class="token operator">-</span>h<span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token operator">--</span>arch_checker<span class="token punctuation">]</span>

Script to convert TFLite model into QNN

required arguments<span class="token operator">:</span>
  <span class="token operator">-</span>d INPUT_NAME INPUT_DIM<span class="token punctuation">,</span> <span class="token operator">--</span>input_dim INPUT_NAME INPUT_DIM
                        The names <span class="token operator">and</span> dimensions of the network input layers specified in the format
                        <span class="token punctuation">[</span>input_name comma<span class="token operator">-</span>separated<span class="token operator">-</span>dimensions<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token keyword">for</span> example<span class="token operator">:</span>
                            <span class="token char">'data'</span> <span class="token number">1</span><span class="token punctuation">,</span><span class="token number">224</span><span class="token punctuation">,</span><span class="token number">224</span><span class="token punctuation">,</span><span class="token number">3</span> Note that the quotes should always be included in order to handle special
                        characters<span class="token punctuation">,</span> spaces<span class="token punctuation">,</span> etc<span class="token punctuation">.</span> For multiple inputs specify multiple <span class="token operator">--</span>input_dim on the command
                        line like<span class="token operator">:</span>
                            <span class="token operator">--</span>input_dim <span class="token char">'data1'</span> <span class="token number">1</span><span class="token punctuation">,</span><span class="token number">224</span><span class="token punctuation">,</span><span class="token number">224</span><span class="token punctuation">,</span><span class="token number">3</span> <span class="token operator">--</span>input_dim <span class="token char">'data2'</span> <span class="token number">1</span><span class="token punctuation">,</span><span class="token number">50</span><span class="token punctuation">,</span><span class="token number">100</span><span class="token punctuation">,</span><span class="token number">3</span>
  <span class="token operator">--</span>input_network INPUT_NETWORK<span class="token punctuation">,</span> <span class="token operator">-</span>i INPUT_NETWORK
                        Path to the source framework model<span class="token punctuation">.</span>

optional arguments<span class="token operator">:</span>
  <span class="token operator">--</span>out_node OUT_NAMES<span class="token punctuation">,</span> <span class="token operator">--</span>out_name OUT_NAMES
                        Name of the graph<span class="token number">'</span>s output Tensor Names<span class="token punctuation">.</span> Multiple output names should be
                        provided separately like<span class="token operator">:</span>
                            <span class="token operator">--</span>out_name out_1 <span class="token operator">--</span>out_name out_2
  <span class="token operator">--</span>input_type INPUT_NAME INPUT_TYPE<span class="token punctuation">,</span> <span class="token operator">-</span>t INPUT_NAME INPUT_TYPE
                        Type of data expected by each input op<span class="token operator">/</span>layer<span class="token punctuation">.</span> Type <span class="token keyword">for</span> each input is
                        <span class="token operator">|</span><span class="token keyword">default</span><span class="token operator">|</span> <span class="token keyword">if</span> <span class="token operator">not</span> specified<span class="token punctuation">.</span> For example<span class="token operator">:</span> <span class="token string">"data"</span> image<span class="token punctuation">.</span>Note that the quotes
                        should always be included in order to handle special characters<span class="token punctuation">,</span> spaces<span class="token punctuation">,</span>etc<span class="token punctuation">.</span>
                        For multiple inputs specify multiple <span class="token operator">--</span>input_type on the command line<span class="token punctuation">.</span>
                        Eg<span class="token operator">:</span>
                            <span class="token operator">--</span>input_type <span class="token string">"data1"</span> image <span class="token operator">--</span>input_type <span class="token string">"data2"</span> opaque
                        These options get used by DSP runtime <span class="token operator">and</span> following descriptions state how
                        input will be handled <span class="token keyword">for</span> each option<span class="token punctuation">.</span>
                        Image<span class="token operator">:</span>
                        Input is <span class="token keyword">float</span> between <span class="token number">0</span><span class="token operator">-</span><span class="token number">255</span> <span class="token operator">and</span> the input<span class="token char">'s mean is 0.0f and the input'</span>s
                        max is <span class="token number">255.0f</span><span class="token punctuation">.</span> We will cast the <span class="token keyword">float</span> to uint8ts <span class="token operator">and</span> pass the uint8ts to the
                        DSP<span class="token punctuation">.</span>
                        Default<span class="token operator">:</span>
                        Pass the input as floats to the dsp directly <span class="token operator">and</span> the DSP will quantize it<span class="token punctuation">.</span>
                        Opaque<span class="token operator">:</span>
                        Assumes input is <span class="token keyword">float</span> because the consumer <span class="token function">layer</span><span class="token punctuation">(</span>i<span class="token punctuation">.</span>e next layer<span class="token punctuation">)</span> <span class="token keyword">requires</span>
                        it as <span class="token keyword">float</span><span class="token punctuation">,</span> therefore it won<span class="token number">'</span>t be quantized<span class="token punctuation">.</span>
                        Choices supported<span class="token operator">:</span>
                            image
                            <span class="token keyword">default</span>
                            opaque
  <span class="token operator">--</span>input_dtype INPUT_NAME INPUT_DTYPE
                        The names <span class="token operator">and</span> datatype of the network input layers specified in the format
                        <span class="token punctuation">[</span>input_name datatype<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token keyword">for</span> example<span class="token operator">:</span>
                            <span class="token char">'data'</span> <span class="token char">'float32'</span>
                        Default is float32 <span class="token keyword">if</span> <span class="token operator">not</span> specified
                        Note that the quotes should always be included in order to handlespecial
                        characters<span class="token punctuation">,</span> spaces<span class="token punctuation">,</span> etc<span class="token punctuation">.</span>
                        For multiple inputs specify multiple <span class="token operator">--</span>input_dtype on the command line like<span class="token operator">:</span>
                            <span class="token operator">--</span>input_dtype <span class="token char">'data1'</span> <span class="token char">'float32'</span> <span class="token operator">--</span>input_dtype <span class="token char">'data2'</span> <span class="token char">'float32'</span>
  <span class="token operator">--</span>input_encoding INPUT_ENCODING <span class="token punctuation">[</span>INPUT_ENCODING <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token operator">-</span>e INPUT_ENCODING <span class="token punctuation">[</span>INPUT_ENCODING <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span>
                        Usage<span class="token operator">:</span>     <span class="token operator">--</span>input_encoding <span class="token string">"INPUT_NAME"</span> INPUT_ENCODING_IN
                        <span class="token punctuation">[</span>INPUT_ENCODING_OUT<span class="token punctuation">]</span>
                        Input encoding of the network inputs<span class="token punctuation">.</span> Default is bgr<span class="token punctuation">.</span>
                        e<span class="token punctuation">.</span>g<span class="token punctuation">.</span>
                            <span class="token operator">--</span>input_encoding <span class="token string">"data"</span> rgba
                        Quotes must wrap the input node name to handle special characters<span class="token punctuation">,</span>
                        spaces<span class="token punctuation">,</span> etc<span class="token punctuation">.</span> To specify encodings <span class="token keyword">for</span> multiple inputs<span class="token punctuation">,</span> invoke
                        <span class="token operator">--</span>input_encoding <span class="token keyword">for</span> each one<span class="token punctuation">.</span>
                        e<span class="token punctuation">.</span>g<span class="token punctuation">.</span>
                            <span class="token operator">--</span>input_encoding <span class="token string">"data1"</span> rgba <span class="token operator">--</span>input_encoding <span class="token string">"data2"</span> other
                        Optionally<span class="token punctuation">,</span> an output encoding may be specified <span class="token keyword">for</span> an input node by
                        providing a second encoding<span class="token punctuation">.</span> The <span class="token keyword">default</span> output encoding is bgr<span class="token punctuation">.</span>
                        e<span class="token punctuation">.</span>g<span class="token punctuation">.</span>
                            <span class="token operator">--</span>input_encoding <span class="token string">"data3"</span> rgba rgb
                        Input encoding types<span class="token operator">:</span>
                            image color encodings<span class="token operator">:</span> bgr<span class="token punctuation">,</span>rgb<span class="token punctuation">,</span> nv21<span class="token punctuation">,</span> nv12<span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
                            time_series<span class="token operator">:</span> <span class="token keyword">for</span> inputs of rnn models<span class="token punctuation">;</span>
                            other<span class="token operator">:</span> <span class="token operator">not</span> available above <span class="token operator">or</span> is unknown<span class="token punctuation">.</span>
                        Supported encodings<span class="token operator">:</span>
                            bgr
                            rgb
                            rgba
                            argb32
                            nv21
                            nv12
                            time_series
                            other
  <span class="token operator">--</span>input_layout INPUT_NAME INPUT_LAYOUT<span class="token punctuation">,</span> <span class="token operator">-</span>l INPUT_NAME INPUT_LAYOUT
                        Layout of each input tensor<span class="token punctuation">.</span> If <span class="token operator">not</span> specified<span class="token punctuation">,</span> it will use the <span class="token keyword">default</span>
                        based on the Source Framework<span class="token punctuation">,</span> shape of input <span class="token operator">and</span> input encoding<span class="token punctuation">.</span>
                        Accepted values are<span class="token operator">-</span>
                            NCDHW<span class="token punctuation">,</span> NDHWC<span class="token punctuation">,</span> NCHW<span class="token punctuation">,</span> NHWC<span class="token punctuation">,</span> NFC<span class="token punctuation">,</span> NCF<span class="token punctuation">,</span> NTF<span class="token punctuation">,</span> TNF<span class="token punctuation">,</span> NF<span class="token punctuation">,</span> NC<span class="token punctuation">,</span> F<span class="token punctuation">,</span> NONTRIVIAL
                        N <span class="token operator">=</span> Batch<span class="token punctuation">,</span> C <span class="token operator">=</span> Channels<span class="token punctuation">,</span> D <span class="token operator">=</span> Depth<span class="token punctuation">,</span> H <span class="token operator">=</span> Height<span class="token punctuation">,</span> W <span class="token operator">=</span> Width<span class="token punctuation">,</span> F <span class="token operator">=</span> Feature<span class="token punctuation">,</span> T <span class="token operator">=</span> Time
                        NDHWC<span class="token operator">/</span>NCDHW used <span class="token keyword">for</span> <span class="token number">5</span>d inputs
                        NHWC<span class="token operator">/</span>NCHW used <span class="token keyword">for</span> <span class="token number">4</span>d image<span class="token operator">-</span>like inputs
                        NFC<span class="token operator">/</span>NCF used <span class="token keyword">for</span> inputs to Conv1D <span class="token operator">or</span> other <span class="token number">1</span>D ops
                        NTF<span class="token operator">/</span>TNF used <span class="token keyword">for</span> inputs with time steps like the ones used <span class="token keyword">for</span> LSTM op
                        NF used <span class="token keyword">for</span> <span class="token number">2</span>D inputs<span class="token punctuation">,</span> like the inputs to Dense<span class="token operator">/</span>FullyConnected layers
                        NC used <span class="token keyword">for</span> <span class="token number">2</span>D inputs with <span class="token number">1</span> <span class="token keyword">for</span> batch <span class="token operator">and</span> other <span class="token keyword">for</span> <span class="token function">Channels</span> <span class="token punctuation">(</span>rarely used<span class="token punctuation">)</span>
                        F used <span class="token keyword">for</span> <span class="token number">1</span>D inputs<span class="token punctuation">,</span> e<span class="token punctuation">.</span>g<span class="token punctuation">.</span> Bias tensor
                        NONTRIVIAL <span class="token keyword">for</span> everything elseFor multiple inputs specify multiple
                        <span class="token operator">--</span>input_layout on the command line<span class="token punctuation">.</span>
                        Eg<span class="token operator">:</span>
                           <span class="token operator">--</span>input_layout <span class="token string">"data1"</span> NCHW <span class="token operator">--</span>input_layout <span class="token string">"data2"</span> NCHW
  <span class="token operator">--</span>custom_io CUSTOM_IO
                        Use <span class="token keyword">this</span> option to specify a yaml file <span class="token keyword">for</span> custom IO<span class="token punctuation">.</span>
  <span class="token operator">--</span>dump_relay DUMP_RELAY
                        Dump Relay ASM <span class="token operator">and</span> Params at the path provided with the argument
                        Usage<span class="token operator">:</span> <span class="token operator">--</span>dump_relay <span class="token operator">&lt;</span>path_to_dump<span class="token operator">&gt;</span>
  <span class="token operator">--</span>show_unconsumed_nodes
                        Displays a list of unconsumed nodes<span class="token punctuation">,</span> <span class="token keyword">if</span> there any are
                        found<span class="token punctuation">.</span> Nodeswhich are unconsumed <span class="token keyword">do</span> <span class="token operator">not</span> violate the
                        structural fidelity of thegenerated graph<span class="token punctuation">.</span>
  <span class="token operator">--</span>disable_batchnorm_folding
  <span class="token operator">--</span>keep_disconnected_nodes
                        Disable Optimization that removes Ops <span class="token operator">not</span> connected to the main graph<span class="token punctuation">.</span>
                        This optimization uses output names provided over commandline OR
                        inputs<span class="token operator">/</span>outputs extracted from the Source model to determine the main graph
  <span class="token operator">-</span>o OUTPUT_PATH<span class="token punctuation">,</span> <span class="token operator">--</span>output_path OUTPUT_PATH
                        Path where the converted Output model should be saved<span class="token punctuation">.</span>If <span class="token operator">not</span> specified<span class="token punctuation">,</span> the
                        converter model will be written to a file with same name as the input model
  <span class="token operator">--</span>copyright_file COPYRIGHT_FILE
                        Path to copyright file<span class="token punctuation">.</span> If provided<span class="token punctuation">,</span> the content of the file will be added
                        to the output model<span class="token punctuation">.</span>
  <span class="token operator">--</span>float_bw FLOAT_BW   Use the <span class="token operator">--</span>float_bw option to select the bitwidth to use when <span class="token keyword">using</span> <span class="token keyword">float</span> <span class="token keyword">for</span>
                        <span class="token function">parameters</span><span class="token punctuation">(</span>weights<span class="token operator">/</span>bias<span class="token punctuation">)</span> <span class="token operator">and</span> activations <span class="token keyword">for</span> all ops  <span class="token operator">or</span> specific <span class="token function">Op</span> <span class="token punctuation">(</span>via
                        encodings<span class="token punctuation">)</span> selected through encoding<span class="token punctuation">,</span> either <span class="token number">32</span> <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span> <span class="token operator">or</span> <span class="token number">16.</span>
  <span class="token operator">--</span>overwrite_model_prefix
                        If option passed<span class="token punctuation">,</span> model generator will use the output path name to use as
                        model prefix to name functions in <span class="token operator">&lt;</span>qnn_model_name<span class="token operator">&gt;</span><span class="token punctuation">.</span>cpp<span class="token punctuation">.</span> <span class="token punctuation">(</span>Useful <span class="token keyword">for</span> running
                        multiple models at once<span class="token punctuation">)</span> eg<span class="token operator">:</span> ModelName_composeGraphs<span class="token punctuation">.</span> Default is to use
                        generic <span class="token string">"QnnModel_"</span><span class="token punctuation">.</span>
  <span class="token operator">--</span>exclude_named_tensors
                        Remove <span class="token keyword">using</span> source framework tensorNames<span class="token punctuation">;</span> instead use a counter <span class="token keyword">for</span> naming
                        tensors<span class="token punctuation">.</span> Note<span class="token operator">:</span> This can potentially help to reduce the <span class="token keyword">final</span> model library
                        that will be <span class="token function">generated</span><span class="token punctuation">(</span>Recommended <span class="token keyword">for</span> deploying model<span class="token punctuation">)</span><span class="token punctuation">.</span> Default is False<span class="token punctuation">.</span>
  <span class="token operator">-</span>h<span class="token punctuation">,</span> <span class="token operator">--</span>help            show <span class="token keyword">this</span> help message <span class="token operator">and</span> exit

Quantizer Options<span class="token operator">:</span>
  <span class="token operator">--</span>quantization_overrides QUANTIZATION_OVERRIDES
                        Use <span class="token keyword">this</span> option to specify a json file with parameters to use <span class="token keyword">for</span>
                        quantization<span class="token punctuation">.</span> These will <span class="token keyword">override</span> any quantization data carried from
                        <span class="token function">conversion</span> <span class="token punctuation">(</span>eg TF fake quantization<span class="token punctuation">)</span> <span class="token operator">or</span> calculated during the normal
                        quantization process<span class="token punctuation">.</span> Format defined as per AIMET specification<span class="token punctuation">.</span>
  <span class="token operator">--</span>keep_quant_nodes    Use <span class="token keyword">this</span> option to keep activation quantization nodes in the graph rather
                        than stripping them<span class="token punctuation">.</span>
  <span class="token operator">--</span>input_list INPUT_LIST
                        Path to a file specifying the input data<span class="token punctuation">.</span> This file should be a plain text
                        file<span class="token punctuation">,</span> containing one <span class="token operator">or</span> more absolute file paths per line<span class="token punctuation">.</span> Each path is
                        expected to point to a binary file containing one input in the <span class="token string">"raw"</span> format<span class="token punctuation">,</span>
                        ready to be consumed by the quantizer without any further preprocessing<span class="token punctuation">.</span>
                        Multiple files per line separated by spaces indicate multiple inputs to the
                        network<span class="token punctuation">.</span> See documentation <span class="token keyword">for</span> more details<span class="token punctuation">.</span> Must be specified <span class="token keyword">for</span>
                        quantization<span class="token punctuation">.</span> All subsequent quantization options are ignored when <span class="token keyword">this</span> is
                        <span class="token operator">not</span> provided<span class="token punctuation">.</span>
  <span class="token operator">--</span>param_quantizer PARAM_QUANTIZER
                        Optional parameter to indicate the weight<span class="token operator">/</span>bias quantizer to use<span class="token punctuation">.</span> Must be
                        followed by one of the following options<span class="token operator">:</span> <span class="token string">"tf"</span><span class="token operator">:</span> Uses the real min<span class="token operator">/</span>max of the
                        data <span class="token operator">and</span> specified <span class="token function">bitwidth</span> <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span> <span class="token string">"enhanced"</span><span class="token operator">:</span> Uses an algorithm useful
                        <span class="token keyword">for</span> quantizing models with <span class="token keyword">long</span> tails present in the weight distribution
                        <span class="token string">"adjusted"</span><span class="token operator">:</span> Uses an adjusted min<span class="token operator">/</span>max <span class="token keyword">for</span> computing the range<span class="token punctuation">,</span> particularly
                        good <span class="token keyword">for</span> denoise models <span class="token string">"symmetric"</span><span class="token operator">:</span> Ensures min <span class="token operator">and</span> max have the same
                        absolute values about zero<span class="token punctuation">.</span> Data will be stored as <span class="token keyword">int</span>#_t data such that the
                        offset is always <span class="token number">0.</span>
  <span class="token operator">--</span>act_quantizer ACT_QUANTIZER
                        Optional parameter to indicate the activation quantizer to use<span class="token punctuation">.</span> Must be
                        followed by one of the following options<span class="token operator">:</span> <span class="token string">"tf"</span><span class="token operator">:</span> Uses the real min<span class="token operator">/</span>max of the
                        data <span class="token operator">and</span> specified <span class="token function">bitwidth</span> <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span> <span class="token string">"enhanced"</span><span class="token operator">:</span> Uses an algorithm useful
                        <span class="token keyword">for</span> quantizing models with <span class="token keyword">long</span> tails present in the weight distribution
                        <span class="token string">"adjusted"</span><span class="token operator">:</span> Uses an adjusted min<span class="token operator">/</span>max <span class="token keyword">for</span> computing the range<span class="token punctuation">,</span> particularly
                        good <span class="token keyword">for</span> denoise models <span class="token string">"symmetric"</span><span class="token operator">:</span> Ensures min <span class="token operator">and</span> max have the same
                        absolute values about zero<span class="token punctuation">.</span> Data will be stored as <span class="token keyword">int</span>#_t data such that the
                        offset is always <span class="token number">0.</span>
  <span class="token operator">--</span>algorithms ALGORITHMS <span class="token punctuation">[</span>ALGORITHMS <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span>
                        Use <span class="token keyword">this</span> option to enable <span class="token keyword">new</span> optimization algorithms<span class="token punctuation">.</span> Usage is<span class="token operator">:</span>
                        <span class="token operator">--</span>algorithms <span class="token operator">&lt;</span>algo_name1<span class="token operator">&gt;</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> The available optimization algorithms are<span class="token operator">:</span>
                        <span class="token string">"cle"</span> <span class="token operator">-</span> Cross layer equalization includes a number of methods <span class="token keyword">for</span> equalizing
                        weights <span class="token operator">and</span> biases across layers in order to rectify imbalances that cause
                        quantization errors<span class="token punctuation">.</span>
  <span class="token operator">--</span>bias_bw BIAS_BW     Use the <span class="token operator">--</span>bias_bw option to select the bitwidth to use when quantizing the
                        biases<span class="token punctuation">,</span> either <span class="token number">8</span> <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span> <span class="token operator">or</span> <span class="token number">32.</span>
  <span class="token operator">--</span>act_bw ACT_BW       Use the <span class="token operator">--</span>act_bw option to select the bitwidth to use when quantizing the
                        activations<span class="token punctuation">,</span> either <span class="token number">8</span> <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span> <span class="token operator">or</span> <span class="token number">16.</span>
  <span class="token operator">--</span>weight_bw WEIGHT_BW
                        Use the <span class="token operator">--</span>weight_bw option to select the bitwidth to use when quantizing the
                        weights<span class="token punctuation">,</span> currently only <span class="token number">8</span> <span class="token function">bit</span> <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span> supported<span class="token punctuation">.</span>
  <span class="token operator">--</span>float_bias_bw FLOAT_BIAS_BW
                        Use the <span class="token operator">--</span>float_bias_bw option to select the bitwidth to use when biases are
                        in <span class="token keyword">float</span><span class="token punctuation">,</span> either <span class="token number">32</span> <span class="token operator">or</span> <span class="token number">16.</span>
  <span class="token operator">--</span>ignore_encodings    Use only quantizer generated encodings<span class="token punctuation">,</span> ignoring any user <span class="token operator">or</span> model provided
                        encodings<span class="token punctuation">.</span>
                        Note<span class="token operator">:</span> Cannot use <span class="token operator">--</span>ignore_encodings with <span class="token operator">--</span>quantization_overrides
  <span class="token operator">--</span>use_per_row_quantization
                        Use <span class="token keyword">this</span> option to enable rowwise quantization of Matmul <span class="token operator">and</span> FullyConnected
                        ops<span class="token punctuation">.</span>
  <span class="token operator">--</span>use_per_channel_quantization <span class="token punctuation">[</span>USE_PER_CHANNEL_QUANTIZATION <span class="token punctuation">[</span>USE_PER_CHANNEL_QUANTIZATION <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
                        Use per<span class="token operator">-</span>channel quantization <span class="token keyword">for</span> convolution<span class="token operator">-</span>based op weights<span class="token punctuation">.</span>
                        Note<span class="token operator">:</span> This will replace built<span class="token operator">-</span>in model QAT encodings when used <span class="token keyword">for</span> a given
                        weight<span class="token punctuation">.</span>Usage <span class="token string">"--use_per_channel_quantization"</span> to enable <span class="token operator">or</span> "<span class="token operator">--</span>
                        use_per_channel_quantization <span class="token boolean">false</span>" <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span> to disable
  <span class="token operator">--</span>use_native_input_files
                        Boolean flag to indicate how to read input files<span class="token operator">:</span>
                        <span class="token number">1.</span> <span class="token keyword">float</span> <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">:</span> reads inputs as floats <span class="token operator">and</span> quantizes <span class="token keyword">if</span> necessary based
                        on quantization parameters in the model<span class="token punctuation">.</span>
                        <span class="token number">2.</span> native<span class="token operator">:</span> reads inputs assuming the data type to be native to the
                        model<span class="token punctuation">.</span> For ex<span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token keyword">uint8_t</span><span class="token punctuation">.</span>
  <span class="token operator">--</span>use_native_dtype    Note<span class="token operator">:</span> This option is deprecated<span class="token punctuation">,</span> use <span class="token operator">--</span>use_native_input_files option in
                        future<span class="token punctuation">.</span>
                        Boolean flag to indicate how to read input files<span class="token operator">:</span>
                        <span class="token number">1.</span> <span class="token keyword">float</span> <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">:</span> reads inputs as floats <span class="token operator">and</span> quantizes <span class="token keyword">if</span> necessary based
                        on quantization parameters in the model<span class="token punctuation">.</span>
                        <span class="token number">2.</span> native<span class="token operator">:</span> reads inputs assuming the data type to be native to the
                        model<span class="token punctuation">.</span> For ex<span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token keyword">uint8_t</span><span class="token punctuation">.</span>
  <span class="token operator">--</span>use_native_output_files
                        Use <span class="token keyword">this</span> option to indicate the data type of the output files
                        <span class="token number">1.</span> <span class="token keyword">float</span> <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">:</span> output the file as floats<span class="token punctuation">.</span>
                        <span class="token number">2.</span> native<span class="token operator">:</span> outputs the file that is native to the model<span class="token punctuation">.</span> For ex<span class="token punctuation">.</span><span class="token punctuation">,</span>
                        <span class="token keyword">uint8_t</span><span class="token punctuation">.</span>
  <span class="token operator">--</span>restrict_quantization_steps ENCODING_MIN<span class="token punctuation">,</span> ENCODING_MAX
                        Specifies the number of steps to use <span class="token keyword">for</span> computing quantization encodings
                        such that scale <span class="token operator">=</span> <span class="token punctuation">(</span>max <span class="token operator">-</span> min<span class="token punctuation">)</span> <span class="token operator">/</span> number of quantization steps<span class="token punctuation">.</span>
                        The option should be passed as a space separated pair of hexadecimal string
                        minimum <span class="token operator">and</span> maximum values<span class="token punctuation">.</span> i<span class="token punctuation">.</span>e<span class="token punctuation">.</span> <span class="token operator">--</span>restrict_quantization_steps <span class="token string">"MIN MAX"</span><span class="token punctuation">.</span>
                        Please note that <span class="token keyword">this</span> is a hexadecimal string literal <span class="token operator">and</span> <span class="token operator">not</span> a <span class="token keyword">signed</span>
                        integer<span class="token punctuation">,</span> to supply a negative value an <span class="token keyword">explicit</span> minus sign is required<span class="token punctuation">.</span>
                        E<span class="token punctuation">.</span>g<span class="token punctuation">.</span><span class="token operator">--</span>restrict_quantization_steps <span class="token string">"-0x80 0x7F"</span> indicates an example <span class="token number">8</span> bit range<span class="token punctuation">,</span>
                        <span class="token operator">--</span>restrict_quantization_steps <span class="token string">"-0x8000 0x7F7F"</span> indicates an example <span class="token number">16</span>
                        bit range<span class="token punctuation">.</span>

Custom Op Package Options<span class="token operator">:</span>
  <span class="token operator">--</span>op_package_lib OP_PACKAGE_LIB<span class="token punctuation">,</span> <span class="token operator">-</span>opl OP_PACKAGE_LIB
                        Use <span class="token keyword">this</span> argument to pass an op package library <span class="token keyword">for</span> quantization<span class="token punctuation">.</span> Must be in
                        the form <span class="token operator">&lt;</span>op_package_lib_path<span class="token operator">:</span>interfaceProviderName<span class="token operator">&gt;</span> <span class="token operator">and</span> be separated by a
                        comma <span class="token keyword">for</span> multiple package libs
  <span class="token operator">--</span>converter_op_package_lib CONVERTER_OP_PACKAGE_LIB<span class="token punctuation">,</span> <span class="token operator">-</span>cpl CONVERTER_OP_PACKAGE_LIB
                        Absolute path to converter op package library compiled by the OpPackage
                        generator<span class="token punctuation">.</span> Must be separated by a comma <span class="token keyword">for</span> multiple package libraries<span class="token punctuation">.</span>
                        Note<span class="token operator">:</span> Libraries must follow the same order as the xml files<span class="token punctuation">.</span>
                        E<span class="token punctuation">.</span>g<span class="token punctuation">.</span><span class="token number">1</span><span class="token operator">:</span> <span class="token operator">--</span>converter_op_package_lib absolute_path_to<span class="token operator">/</span>libExample<span class="token punctuation">.</span>so
                        E<span class="token punctuation">.</span>g<span class="token punctuation">.</span><span class="token number">2</span><span class="token operator">:</span> <span class="token operator">-</span>cpl absolute_path_to<span class="token operator">/</span>libExample1<span class="token punctuation">.</span>so<span class="token punctuation">,</span>absolute_path_to<span class="token operator">/</span>libExample2<span class="token punctuation">.</span>so
  <span class="token operator">-</span>p PACKAGE_NAME<span class="token punctuation">,</span> <span class="token operator">--</span>package_name PACKAGE_NAME
                        A global package name to be used <span class="token keyword">for</span> each node in the Model<span class="token punctuation">.</span>cpp file<span class="token punctuation">.</span>
                        Defaults to Qnn header defined package name
  <span class="token operator">--</span>op_package_config OP_PACKAGE_CONFIG <span class="token punctuation">[</span>OP_PACKAGE_CONFIG <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token operator">-</span>opc OP_PACKAGE_CONFIG <span class="token punctuation">[</span>OP_PACKAGE_CONFIG <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span>
                        Path to a Qnn Op Package XML configuration file that contains user defined
                        custom operations<span class="token punctuation">.</span>

Architecture Checker <span class="token function">Options</span><span class="token punctuation">(</span>Experimental<span class="token punctuation">)</span><span class="token operator">:</span>
  <span class="token operator">--</span>arch_checker        Note<span class="token operator">:</span> This option will be soon deprecated<span class="token punctuation">.</span> Use the qnn<span class="token operator">-</span>architecture<span class="token operator">-</span>checker tool to achieve the same result<span class="token punctuation">.</span>

Note<span class="token operator">:</span> Only one of<span class="token operator">:</span> <span class="token punctuation">{<!-- --></span><span class="token char">'package_name'</span><span class="token punctuation">,</span> <span class="token char">'op_package_config'</span><span class="token punctuation">}</span> can be specified

</code></pre> 
<p>基本命令行用法如下：</p> 
<pre><code class="prism language-cpp">$ qnn<span class="token operator">-</span>tflite<span class="token operator">-</span>converter <span class="token operator">-</span>i <span class="token operator">&lt;</span>path<span class="token operator">&gt;</span><span class="token operator">/</span>model<span class="token punctuation">.</span>tflite
                       <span class="token operator">-</span>d <span class="token operator">&lt;</span>network_input_name<span class="token operator">&gt;</span> <span class="token operator">&lt;</span>dims<span class="token operator">&gt;</span>
                       <span class="token operator">-</span>o <span class="token operator">&lt;</span>optional_output_path<span class="token operator">&gt;</span>
                       <span class="token operator">-</span>p <span class="token operator">&lt;</span>optional_package_name<span class="token operator">&gt;</span> # Defaults to <span class="token string">"qti.aisw"</span>

</code></pre> 
<p>qnn-pytorch-转换器<br> qnn-pytorch-converter工具将 PyTorch 模型转换为 CPP 文件，将模型表示为一系列 QNN API 调用。此外，还会生成包含模型静态权重的二进制文件。</p> 
<pre><code class="prism language-cpp">usage<span class="token operator">:</span> qnn<span class="token operator">-</span>pytorch<span class="token operator">-</span>converter <span class="token operator">-</span>d INPUT_NAME INPUT_DIM <span class="token punctuation">[</span><span class="token operator">--</span>out_node OUT_NAMES<span class="token punctuation">]</span>
                          <span class="token punctuation">[</span><span class="token operator">--</span>input_type INPUT_NAME INPUT_TYPE<span class="token punctuation">]</span>
                          <span class="token punctuation">[</span><span class="token operator">--</span>input_dtype INPUT_NAME INPUT_DTYPE<span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token operator">--</span>input_encoding INPUT_ENCODING <span class="token punctuation">[</span>INPUT_ENCODING <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
                          <span class="token punctuation">[</span><span class="token operator">--</span>input_layout INPUT_NAME INPUT_LAYOUT<span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token operator">--</span>custom_io CUSTOM_IO<span class="token punctuation">]</span>
                          <span class="token punctuation">[</span><span class="token operator">--</span>dump_relay DUMP_RELAY<span class="token punctuation">]</span>
                          <span class="token punctuation">[</span><span class="token operator">--</span>quantization_overrides QUANTIZATION_OVERRIDES<span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token operator">--</span>keep_quant_nodes<span class="token punctuation">]</span>
                          <span class="token punctuation">[</span><span class="token operator">--</span>disable_batchnorm_folding<span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token operator">--</span>keep_disconnected_nodes<span class="token punctuation">]</span>
                          <span class="token punctuation">[</span><span class="token operator">--</span>input_list INPUT_LIST<span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token operator">--</span>param_quantizer PARAM_QUANTIZER<span class="token punctuation">]</span>
                          <span class="token punctuation">[</span><span class="token operator">--</span>act_quantizer ACT_QUANTIZER<span class="token punctuation">]</span>
                          <span class="token punctuation">[</span><span class="token operator">--</span>algorithms ALGORITHMS <span class="token punctuation">[</span>ALGORITHMS <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token operator">--</span>bias_bw BIAS_BW<span class="token punctuation">]</span>
                          <span class="token punctuation">[</span><span class="token operator">--</span>act_bw ACT_BW<span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token operator">--</span>weight_bw WEIGHT_BW<span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token operator">--</span>ignore_encodings<span class="token punctuation">]</span>
                          <span class="token punctuation">[</span><span class="token operator">--</span>use_per_row_quantization<span class="token punctuation">]</span>
                          <span class="token punctuation">[</span><span class="token operator">--</span>use_per_channel_quantization <span class="token punctuation">[</span>USE_PER_CHANNEL_QUANTIZATION <span class="token punctuation">[</span>USE_PER_CHANNEL_QUANTIZATION <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
                          <span class="token punctuation">[</span><span class="token operator">--</span>use_native_input_files<span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token operator">--</span>use_native_dtype<span class="token punctuation">]</span>
                          <span class="token punctuation">[</span><span class="token operator">--</span>use_native_output_files<span class="token punctuation">]</span> <span class="token operator">--</span>input_network INPUT_NETWORK
                          <span class="token punctuation">[</span><span class="token operator">--</span>debug <span class="token punctuation">[</span>DEBUG<span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token operator">-</span>o OUTPUT_PATH<span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token operator">--</span>copyright_file COPYRIGHT_FILE<span class="token punctuation">]</span>
                          <span class="token punctuation">[</span><span class="token operator">--</span>float_bw FLOAT_BW<span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token operator">--</span>float_bias_bw FLOAT_BIAS_BW<span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token operator">--</span>overwrite_model_prefix<span class="token punctuation">]</span>
                          <span class="token punctuation">[</span><span class="token operator">--</span>exclude_named_tensors<span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token operator">--</span>op_package_lib OP_PACKAGE_LIB<span class="token punctuation">]</span>
                          <span class="token punctuation">[</span><span class="token operator">--</span>restrict_quantization_steps ENCODING_MIN<span class="token punctuation">,</span> ENCODING_MAX<span class="token punctuation">]</span>
                          <span class="token punctuation">[</span><span class="token operator">--</span>converter_op_package_lib CONVERTER_OP_PACKAGE_LIB<span class="token punctuation">]</span>
                          <span class="token punctuation">[</span><span class="token operator">-</span>p PACKAGE_NAME <span class="token operator">|</span> <span class="token operator">--</span>op_package_config CUSTOM_OP_CONFIG_PATHS <span class="token punctuation">[</span>CUSTOM_OP_CONFIG_PATHS <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
                          <span class="token punctuation">[</span><span class="token operator">-</span>h<span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token operator">--</span>arch_checker<span class="token punctuation">]</span>

Script to convert PyTorch model into QNN

required arguments<span class="token operator">:</span>
  <span class="token operator">-</span>d INPUT_NAME INPUT_DIM<span class="token punctuation">,</span> <span class="token operator">--</span>input_dim INPUT_NAME INPUT_DIM
                        The names <span class="token operator">and</span> dimensions of the network input layers specified in the format
                        <span class="token punctuation">[</span>input_name comma<span class="token operator">-</span>separated<span class="token operator">-</span>
                        dimensions<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token keyword">for</span> example<span class="token operator">:</span>
                            <span class="token char">'data'</span> <span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">224</span><span class="token punctuation">,</span><span class="token number">224</span>
                        Note that the quotes should always be included in order to handle special
                        characters<span class="token punctuation">,</span> spaces<span class="token punctuation">,</span> etc<span class="token punctuation">.</span>
                        For multiple inputs specify multiple <span class="token operator">--</span>input_dim on the command line like<span class="token operator">:</span>
                            <span class="token operator">--</span>input_dim <span class="token char">'data1'</span> <span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">224</span><span class="token punctuation">,</span><span class="token number">224</span> <span class="token operator">--</span>input_dim <span class="token char">'data2'</span> <span class="token number">1</span><span class="token punctuation">,</span><span class="token number">50</span><span class="token punctuation">,</span><span class="token number">100</span><span class="token punctuation">,</span><span class="token number">3</span>
  <span class="token operator">--</span>input_network INPUT_NETWORK<span class="token punctuation">,</span> <span class="token operator">-</span>i INPUT_NETWORK
                        Path to the source framework model<span class="token punctuation">.</span>

optional arguments<span class="token operator">:</span>
  <span class="token operator">--</span>out_node OUT_NAMES<span class="token punctuation">,</span> <span class="token operator">--</span>out_name OUT_NAMES
                        Name of the graph<span class="token number">'</span>s output Tensor Names<span class="token punctuation">.</span> Multiple output names should be
                        provided separately like<span class="token operator">:</span>
                            <span class="token operator">--</span>out_name out_1 <span class="token operator">--</span>out_name out_2
  <span class="token operator">--</span>input_type INPUT_NAME INPUT_TYPE<span class="token punctuation">,</span> <span class="token operator">-</span>t INPUT_NAME INPUT_TYPE
                        Type of data expected by each input op<span class="token operator">/</span>layer<span class="token punctuation">.</span> Type <span class="token keyword">for</span> each input is
                        <span class="token operator">|</span><span class="token keyword">default</span><span class="token operator">|</span> <span class="token keyword">if</span> <span class="token operator">not</span> specified<span class="token punctuation">.</span> For example<span class="token operator">:</span> <span class="token string">"data"</span> image<span class="token punctuation">.</span>Note that the quotes
                        should always be included in order to handle special characters<span class="token punctuation">,</span> spaces<span class="token punctuation">,</span> etc<span class="token punctuation">.</span>
                        For multiple inputs specify multiple <span class="token operator">--</span>input_type on the command line<span class="token punctuation">.</span>
                        Eg<span class="token operator">:</span>
                            <span class="token operator">--</span>input_type <span class="token string">"data1"</span> image <span class="token operator">--</span>input_type <span class="token string">"data2"</span> opaque
                        These options get used by DSP runtime <span class="token operator">and</span> following descriptions state how
                        input will be handled <span class="token keyword">for</span> each option<span class="token punctuation">.</span>
                        Image<span class="token operator">:</span>
                        Input is <span class="token keyword">float</span> between <span class="token number">0</span><span class="token operator">-</span><span class="token number">255</span> <span class="token operator">and</span> the input<span class="token char">'s mean is 0.0f and the input'</span>s
                        max is <span class="token number">255.0f</span><span class="token punctuation">.</span> We will cast the <span class="token keyword">float</span> to uint8ts <span class="token operator">and</span> pass the uint8ts to the
                        DSP<span class="token punctuation">.</span>
                        Default<span class="token operator">:</span>
                        Pass the input as floats to the dsp directly <span class="token operator">and</span> the DSP will quantize it<span class="token punctuation">.</span>
                        Opaque<span class="token operator">:</span>
                        Assumes
                        input is <span class="token keyword">float</span> because the consumer <span class="token function">layer</span><span class="token punctuation">(</span>i<span class="token punctuation">.</span>e next layer<span class="token punctuation">)</span> <span class="token keyword">requires</span>
                        it as <span class="token keyword">float</span><span class="token punctuation">,</span> therefore it won<span class="token number">'</span>t be quantized<span class="token punctuation">.</span>
                        Choices supported<span class="token operator">:</span>
                            image
                            <span class="token keyword">default</span>
                            opaque
  <span class="token operator">--</span>input_dtype INPUT_NAME INPUT_DTYPE
                        The names <span class="token operator">and</span> datatype of the network input layers specified in the format
                        <span class="token punctuation">[</span>input_name datatype<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token keyword">for</span> example<span class="token operator">:</span>
                            <span class="token char">'data'</span> <span class="token char">'float32'</span>
                        Default is float32 <span class="token keyword">if</span> <span class="token operator">not</span> specified
                        Note that the quotes should always be included in order to handlespecial
                        characters<span class="token punctuation">,</span> spaces<span class="token punctuation">,</span> etc<span class="token punctuation">.</span>
                        For multiple inputs specify multiple <span class="token operator">--</span>input_dtype on the command line like<span class="token operator">:</span>
                            <span class="token operator">--</span>input_dtype <span class="token char">'data1'</span> <span class="token char">'float32'</span> <span class="token operator">--</span>input_dtype <span class="token char">'data2'</span> <span class="token char">'float32'</span>
  <span class="token operator">--</span>input_encoding INPUT_ENCODING <span class="token punctuation">[</span>INPUT_ENCODING <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token operator">-</span>e INPUT_ENCODING <span class="token punctuation">[</span>INPUT_ENCODING <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span>
                        Usage<span class="token operator">:</span>     <span class="token operator">--</span>input_encoding <span class="token string">"INPUT_NAME"</span> INPUT_ENCODING_IN
                        <span class="token punctuation">[</span>INPUT_ENCODING_OUT<span class="token punctuation">]</span>
                        Input encoding of the network inputs<span class="token punctuation">.</span> Default is bgr<span class="token punctuation">.</span>
                        e<span class="token punctuation">.</span>g<span class="token punctuation">.</span>
                            <span class="token operator">--</span>input_encoding <span class="token string">"data"</span> rgba
                        Quotes must wrap the input node name to handle special characters<span class="token punctuation">,</span>
                        spaces<span class="token punctuation">,</span> etc<span class="token punctuation">.</span> To specify encodings <span class="token keyword">for</span> multiple inputs<span class="token punctuation">,</span> invoke
                        <span class="token operator">--</span>input_encoding <span class="token keyword">for</span> each one<span class="token punctuation">.</span>
                        e<span class="token punctuation">.</span>g<span class="token punctuation">.</span>
                            <span class="token operator">--</span>input_encoding <span class="token string">"data1"</span> rgba <span class="token operator">--</span>input_encoding <span class="token string">"data2"</span> other
                        Optionally<span class="token punctuation">,</span> an output encoding may be specified <span class="token keyword">for</span> an input node by
                        providing a second encoding<span class="token punctuation">.</span> The <span class="token keyword">default</span> output encoding is bgr<span class="token punctuation">.</span>
                        e<span class="token punctuation">.</span>g<span class="token punctuation">.</span>
                            <span class="token operator">--</span>input_encoding <span class="token string">"data3"</span> rgba rgb
                        Input encoding types<span class="token operator">:</span>
                            image color encodings<span class="token operator">:</span> bgr<span class="token punctuation">,</span>rgb<span class="token punctuation">,</span> nv21<span class="token punctuation">,</span> nv12<span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
                            time_series<span class="token operator">:</span> <span class="token keyword">for</span> inputs of rnn models<span class="token punctuation">;</span>
                            other<span class="token operator">:</span> <span class="token operator">not</span> available above <span class="token operator">or</span> is unknown<span class="token punctuation">.</span>
                        Supported encodings<span class="token operator">:</span>
                            bgr
                            rgb
                            rgba
                            argb32
                            nv21
                            nv12
                            time_series
                            other
  <span class="token operator">--</span>input_layout INPUT_NAME INPUT_LAYOUT<span class="token punctuation">,</span> <span class="token operator">-</span>l INPUT_NAME INPUT_LAYOUT
                        Layout of each input tensor<span class="token punctuation">.</span> If <span class="token operator">not</span> specified<span class="token punctuation">,</span> it will use the <span class="token keyword">default</span>
                        based on the Source Framework<span class="token punctuation">,</span> shape of input <span class="token operator">and</span> input encoding<span class="token punctuation">.</span>
                        Accepted values are<span class="token operator">-</span>
                            NCDHW<span class="token punctuation">,</span> NDHWC<span class="token punctuation">,</span> NCHW<span class="token punctuation">,</span> NHWC<span class="token punctuation">,</span> NFC<span class="token punctuation">,</span> NCF<span class="token punctuation">,</span> NTF<span class="token punctuation">,</span> TNF<span class="token punctuation">,</span> NF<span class="token punctuation">,</span> NC<span class="token punctuation">,</span> F<span class="token punctuation">,</span> NONTRIVIAL
                        N <span class="token operator">=</span> Batch<span class="token punctuation">,</span> C <span class="token operator">=</span> Channels<span class="token punctuation">,</span> D <span class="token operator">=</span> Depth<span class="token punctuation">,</span> H <span class="token operator">=</span> Height<span class="token punctuation">,</span> W <span class="token operator">=</span> Width<span class="token punctuation">,</span> F <span class="token operator">=</span> Feature<span class="token punctuation">,</span> T <span class="token operator">=</span> Time
                        NDHWC<span class="token operator">/</span>NCDHW used <span class="token keyword">for</span> <span class="token number">5</span>d inputs
                        NHWC<span class="token operator">/</span>NCHW used <span class="token keyword">for</span> <span class="token number">4</span>d image<span class="token operator">-</span>like inputs
                        NFC<span class="token operator">/</span>NCF used <span class="token keyword">for</span> inputs to Conv1D <span class="token operator">or</span> other <span class="token number">1</span>D ops
                        NTF<span class="token operator">/</span>TNF used <span class="token keyword">for</span> inputs with time steps like the ones used <span class="token keyword">for</span> LSTM op
                        NF used <span class="token keyword">for</span> <span class="token number">2</span>D inputs<span class="token punctuation">,</span> like the inputs to Dense<span class="token operator">/</span>FullyConnected layers
                        NC used <span class="token keyword">for</span> <span class="token number">2</span>D inputs with <span class="token number">1</span> <span class="token keyword">for</span> batch <span class="token operator">and</span> other <span class="token keyword">for</span> <span class="token function">Channels</span> <span class="token punctuation">(</span>rarely used<span class="token punctuation">)</span>
                        F used <span class="token keyword">for</span> <span class="token number">1</span>D inputs<span class="token punctuation">,</span> e<span class="token punctuation">.</span>g<span class="token punctuation">.</span> Bias tensor
                        NONTRIVIAL <span class="token keyword">for</span> everything elseFor multiple inputs specify multiple
                        <span class="token operator">--</span>input_layout on the command line<span class="token punctuation">.</span>
                        Eg<span class="token operator">:</span>
                           <span class="token operator">--</span>input_layout <span class="token string">"data1"</span> NCHW <span class="token operator">--</span>input_layout <span class="token string">"data2"</span> NCHW
  <span class="token operator">--</span>custom_io CUSTOM_IO
                        Use <span class="token keyword">this</span> option to specify a yaml file <span class="token keyword">for</span> custom IO<span class="token punctuation">.</span>
  <span class="token operator">--</span>dump_relay DUMP_RELAY
                        Dump Relay ASM <span class="token operator">and</span> Params at the path provided with the argument
                        Usage<span class="token operator">:</span> <span class="token operator">--</span>dump_relay <span class="token operator">&lt;</span>path_to_dump<span class="token operator">&gt;</span>
  <span class="token operator">--</span>disable_batchnorm_folding
  <span class="token operator">--</span>keep_disconnected_nodes
                        Disable Optimization that removes Ops <span class="token operator">not</span> connected to the main graph<span class="token punctuation">.</span>
                        This optimization uses output names provided over commandline OR
                        inputs<span class="token operator">/</span>outputs extracted from the Source model to determine the main graph
  <span class="token operator">--</span>debug <span class="token punctuation">[</span>DEBUG<span class="token punctuation">]</span>       Run the converter in debug mode<span class="token punctuation">.</span>
  <span class="token operator">-</span>o OUTPUT_PATH<span class="token punctuation">,</span> <span class="token operator">--</span>output_path OUTPUT_PATH
                        Path where the converted Output model should be saved<span class="token punctuation">.</span>If <span class="token operator">not</span> specified<span class="token punctuation">,</span> the
                        converter model will be written to a file with same name as the input model
  <span class="token operator">--</span>copyright_file COPYRIGHT_FILE
                        Path to copyright file<span class="token punctuation">.</span> If provided<span class="token punctuation">,</span> the content of the file will be added
                        to the output model<span class="token punctuation">.</span>
  <span class="token operator">--</span>overwrite_model_prefix
                        If option passed<span class="token punctuation">,</span> model generator will use the output path name to use as
                        model prefix to name functions in <span class="token operator">&lt;</span>qnn_model_name<span class="token operator">&gt;</span><span class="token punctuation">.</span>cpp<span class="token punctuation">.</span> <span class="token punctuation">(</span>Useful <span class="token keyword">for</span> running
                        multiple models at once<span class="token punctuation">)</span> eg<span class="token operator">:</span> ModelName_composeGraphs<span class="token punctuation">.</span> Default is to use
                        generic <span class="token string">"QnnModel_"</span><span class="token punctuation">.</span>
  <span class="token operator">--</span>exclude_named_tensors
                        Remove <span class="token keyword">using</span> source framework tensorNames<span class="token punctuation">;</span> instead use a counter <span class="token keyword">for</span> naming
                        tensors<span class="token punctuation">.</span> Note<span class="token operator">:</span> This can potentially help to reduce the <span class="token keyword">final</span> model library
                        that will be <span class="token function">generated</span><span class="token punctuation">(</span>Recommended <span class="token keyword">for</span> deploying model<span class="token punctuation">)</span><span class="token punctuation">.</span> Default is False<span class="token punctuation">.</span>
  <span class="token operator">-</span>h<span class="token punctuation">,</span> <span class="token operator">--</span>help            show <span class="token keyword">this</span> help message <span class="token operator">and</span> exit

Quantizer Options<span class="token operator">:</span>
  <span class="token operator">--</span>quantization_overrides QUANTIZATION_OVERRIDES
                        Use <span class="token keyword">this</span> option to specify a json file with parameters to use <span class="token keyword">for</span>
                        quantization<span class="token punctuation">.</span> These will <span class="token keyword">override</span> any quantization data carried from
                        <span class="token function">conversion</span> <span class="token punctuation">(</span>eg TF fake quantization<span class="token punctuation">)</span> <span class="token operator">or</span> calculated during the normal
                        quantization process<span class="token punctuation">.</span> Format defined as per AIMET specification<span class="token punctuation">.</span>
  <span class="token operator">--</span>keep_quant_nodes    Use <span class="token keyword">this</span> option to keep activation quantization nodes in the graph rather
                        than stripping them<span class="token punctuation">.</span>
  <span class="token operator">--</span>input_list INPUT_LIST
                        Path to a file specifying the input data<span class="token punctuation">.</span> This file should be a plain text
                        file<span class="token punctuation">,</span> containing one <span class="token operator">or</span> more absolute file paths per line<span class="token punctuation">.</span> Each path is
                        expected to point to a binary file containing one input in the <span class="token string">"raw"</span> format<span class="token punctuation">,</span>
                        ready to be consumed by the quantizer without any further preprocessing<span class="token punctuation">.</span>
                        Multiple files per line separated by spaces indicate multiple inputs to the
                        network<span class="token punctuation">.</span> See documentation <span class="token keyword">for</span> more details<span class="token punctuation">.</span> Must be specified <span class="token keyword">for</span>
                        quantization<span class="token punctuation">.</span> All subsequent quantization options are ignored when <span class="token keyword">this</span> is
                        <span class="token operator">not</span> provided<span class="token punctuation">.</span>
  <span class="token operator">--</span>param_quantizer PARAM_QUANTIZER
                        Optional parameter to indicate the weight<span class="token operator">/</span>bias quantizer to use<span class="token punctuation">.</span> Must be
                        followed by one of the following options<span class="token operator">:</span> <span class="token string">"tf"</span><span class="token operator">:</span> Uses the real min<span class="token operator">/</span>max of the
                        data <span class="token operator">and</span> specified <span class="token function">bitwidth</span> <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span> <span class="token string">"enhanced"</span><span class="token operator">:</span> Uses an algorithm useful
                        <span class="token keyword">for</span> quantizing models with <span class="token keyword">long</span> tails present in the weight distribution
                        <span class="token string">"adjusted"</span><span class="token operator">:</span> Uses an adjusted min<span class="token operator">/</span>max <span class="token keyword">for</span> computing the range<span class="token punctuation">,</span> particularly
                        good <span class="token keyword">for</span> denoise models <span class="token string">"symmetric"</span><span class="token operator">:</span> Ensures min <span class="token operator">and</span> max have the same
                        absolute values about zero<span class="token punctuation">.</span> Data will be stored as <span class="token keyword">int</span>#_t data such that the
                        offset is always <span class="token number">0.</span>
  <span class="token operator">--</span>act_quantizer ACT_QUANTIZER
                        Optional parameter to indicate the activation quantizer to use<span class="token punctuation">.</span> Must be
                        followed by one of the following options<span class="token operator">:</span> <span class="token string">"tf"</span><span class="token operator">:</span> Uses the real min<span class="token operator">/</span>max of the
                        data <span class="token operator">and</span> specified <span class="token function">bitwidth</span> <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span> <span class="token string">"enhanced"</span><span class="token operator">:</span> Uses an algorithm useful
                        <span class="token keyword">for</span> quantizing models with <span class="token keyword">long</span> tails present in the weight distribution
                        <span class="token string">"adjusted"</span><span class="token operator">:</span> Uses an adjusted min<span class="token operator">/</span>max <span class="token keyword">for</span> computing the range<span class="token punctuation">,</span> particularly
                        good <span class="token keyword">for</span> denoise models <span class="token string">"symmetric"</span><span class="token operator">:</span> Ensures min <span class="token operator">and</span> max have the same
                        absolute values about zero<span class="token punctuation">.</span> Data will be stored as <span class="token keyword">int</span>#_t data such that the
                        offset is always <span class="token number">0.</span>
  <span class="token operator">--</span>algorithms ALGORITHMS <span class="token punctuation">[</span>ALGORITHMS <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span>
                        Use <span class="token keyword">this</span> option to enable <span class="token keyword">new</span> optimization algorithms<span class="token punctuation">.</span> Usage is<span class="token operator">:</span>
                        <span class="token operator">--</span>algorithms <span class="token operator">&lt;</span>algo_name1<span class="token operator">&gt;</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> The available optimization algorithms are<span class="token operator">:</span>
                        <span class="token string">"cle"</span> <span class="token operator">-</span> Cross layer equalization includes a number of methods <span class="token keyword">for</span> equalizing
                        weights <span class="token operator">and</span> biases across layers in order to rectify imbalances that cause
                        quantization errors<span class="token punctuation">.</span>
  <span class="token operator">--</span>bias_bw BIAS_BW     Use the <span class="token operator">--</span>bias_bw option to select the bitwidth to use when quantizing the
                        biases<span class="token punctuation">,</span> either <span class="token number">8</span> <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span> <span class="token operator">or</span> <span class="token number">32.</span>
  <span class="token operator">--</span>act_bw ACT_BW       Use the <span class="token operator">--</span>act_bw option to select the bitwidth to use when quantizing the
                        activations<span class="token punctuation">,</span> either <span class="token number">8</span> <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span> <span class="token operator">or</span> <span class="token number">16.</span>
  <span class="token operator">--</span>weight_bw WEIGHT_BW
                        Use the <span class="token operator">--</span>weight_bw option to select the bitwidth to use when quantizing the
                        weights<span class="token punctuation">,</span> currently only <span class="token number">8</span> <span class="token function">bit</span> <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span> supported<span class="token punctuation">.</span>
  <span class="token operator">--</span>float_bias_bw FLOAT_BIAS_BW
                        Use the <span class="token operator">--</span>float_bias_bw option to select the bitwidth to use when biases are
                        in <span class="token keyword">float</span><span class="token punctuation">,</span> either <span class="token number">32</span> <span class="token operator">or</span> <span class="token number">16.</span>
  <span class="token operator">--</span>ignore_encodings    Use only quantizer generated encodings<span class="token punctuation">,</span> ignoring any user <span class="token operator">or</span> model provided
                        encodings<span class="token punctuation">.</span>
                        Note<span class="token operator">:</span> Cannot use <span class="token operator">--</span>ignore_encodings with <span class="token operator">--</span>quantization_overrides
  <span class="token operator">--</span>use_per_row_quantization
                        Use <span class="token keyword">this</span> option to enable rowwise quantization of Matmul <span class="token operator">and</span> FullyConnected
                        ops<span class="token punctuation">.</span>
  <span class="token operator">--</span>use_per_channel_quantization <span class="token punctuation">[</span>USE_PER_CHANNEL_QUANTIZATION <span class="token punctuation">[</span>USE_PER_CHANNEL_QUANTIZATION <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
                        Use per<span class="token operator">-</span>channel quantization <span class="token keyword">for</span> convolution<span class="token operator">-</span>based op weights<span class="token punctuation">.</span>
                        Note<span class="token operator">:</span> This will replace built<span class="token operator">-</span>in model QAT encodings when used <span class="token keyword">for</span> a given
                        weight<span class="token punctuation">.</span>Usage <span class="token string">"--use_per_channel_quantization"</span> to enable <span class="token operator">or</span> "<span class="token operator">--</span>
                        use_per_channel_quantization <span class="token boolean">false</span>" <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span> to disable
  <span class="token operator">--</span>use_native_input_files
                        Boolean flag to indicate how to read input files<span class="token operator">:</span>
                        <span class="token number">1.</span> <span class="token keyword">float</span> <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">:</span> reads inputs as floats <span class="token operator">and</span> quantizes <span class="token keyword">if</span> necessary based
                        on quantization parameters in the model<span class="token punctuation">.</span>
                        <span class="token number">2.</span> native<span class="token operator">:</span> reads inputs assuming the data type to be native to the
                        model<span class="token punctuation">.</span> For ex<span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token keyword">uint8_t</span><span class="token punctuation">.</span>
  <span class="token operator">--</span>use_native_dtype    Note<span class="token operator">:</span> This option is deprecated<span class="token punctuation">,</span> use <span class="token operator">--</span>use_native_input_files option in
                        future<span class="token punctuation">.</span>
                        Boolean flag to indicate how to read input files<span class="token operator">:</span>
                        <span class="token number">1.</span> <span class="token keyword">float</span> <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">:</span> reads inputs as floats <span class="token operator">and</span> quantizes <span class="token keyword">if</span> necessary based
                        on quantization parameters in the model<span class="token punctuation">.</span>
                        <span class="token number">2.</span> native<span class="token operator">:</span> reads inputs assuming the data type to be native to the
                        model<span class="token punctuation">.</span> For ex<span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token keyword">uint8_t</span><span class="token punctuation">.</span>
  <span class="token operator">--</span>use_native_output_files
                        Use <span class="token keyword">this</span> option to indicate the data type of the output files
                        <span class="token number">1.</span> <span class="token keyword">float</span> <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">:</span> output the file as floats<span class="token punctuation">.</span>
                        <span class="token number">2.</span> native<span class="token operator">:</span> outputs the file that is native to the model<span class="token punctuation">.</span> For ex<span class="token punctuation">.</span><span class="token punctuation">,</span>
                        <span class="token keyword">uint8_t</span><span class="token punctuation">.</span>
  <span class="token operator">--</span>restrict_quantization_steps ENCODING_MIN<span class="token punctuation">,</span> ENCODING_MAX
                        Specifies the number of steps to use <span class="token keyword">for</span> computing quantization encodings
                        such that scale <span class="token operator">=</span> <span class="token punctuation">(</span>max <span class="token operator">-</span> min<span class="token punctuation">)</span> <span class="token operator">/</span> number of quantization steps<span class="token punctuation">.</span>
                        The option should be passed as a space separated pair of hexadecimal string
                        minimum <span class="token operator">and</span> maximum values<span class="token punctuation">.</span> i<span class="token punctuation">.</span>e<span class="token punctuation">.</span> <span class="token operator">--</span>restrict_quantization_steps <span class="token string">"MIN MAX"</span><span class="token punctuation">.</span>
                        Please note that <span class="token keyword">this</span> is a hexadecimal string literal <span class="token operator">and</span> <span class="token operator">not</span> a <span class="token keyword">signed</span>
                        integer<span class="token punctuation">,</span> to supply a negative value an <span class="token keyword">explicit</span> minus sign is required<span class="token punctuation">.</span>
                        E<span class="token punctuation">.</span>g<span class="token punctuation">.</span><span class="token operator">--</span>restrict_quantization_steps <span class="token string">"-0x80 0x7F"</span> indicates an example <span class="token number">8</span> bit range<span class="token punctuation">,</span>
                        <span class="token operator">--</span>restrict_quantization_steps <span class="token string">"-0x8000 0x7F7F"</span> indicates an example <span class="token number">16</span>
                        bit range<span class="token punctuation">.</span>

Custom Op Package Options<span class="token operator">:</span>
  <span class="token operator">--</span>op_package_lib OP_PACKAGE_LIB<span class="token punctuation">,</span> <span class="token operator">-</span>opl OP_PACKAGE_LIB
                        Use <span class="token keyword">this</span> argument to pass an op package library <span class="token keyword">for</span> quantization<span class="token punctuation">.</span> Must be in
                        the form <span class="token operator">&lt;</span>op_package_lib_path<span class="token operator">:</span>interfaceProviderName<span class="token operator">&gt;</span> <span class="token operator">and</span> be separated by a
                        comma <span class="token keyword">for</span> multiple package libs
  <span class="token operator">--</span>converter_op_package_lib CONVERTER_OP_PACKAGE_LIB<span class="token punctuation">,</span> <span class="token operator">-</span>cpl CONVERTER_OP_PACKAGE_LIB
                        Absolute path to converter op package library compiled by the OpPackage
                        generator<span class="token punctuation">.</span> Must be separated by a comma <span class="token keyword">for</span> multiple package libraries<span class="token punctuation">.</span>
                        Note<span class="token operator">:</span> Libraries must follow the same order as the xml files<span class="token punctuation">.</span>
                        E<span class="token punctuation">.</span>g<span class="token punctuation">.</span><span class="token number">1</span><span class="token operator">:</span> <span class="token operator">--</span>converter_op_package_lib absolute_path_to<span class="token operator">/</span>libExample<span class="token punctuation">.</span>so
                        E<span class="token punctuation">.</span>g<span class="token punctuation">.</span><span class="token number">2</span><span class="token operator">:</span> <span class="token operator">-</span>cpl absolute_path_to<span class="token operator">/</span>libExample1<span class="token punctuation">.</span>so<span class="token punctuation">,</span>absolute_path_to<span class="token operator">/</span>libExample2<span class="token punctuation">.</span>so
  <span class="token operator">-</span>p PACKAGE_NAME<span class="token punctuation">,</span> <span class="token operator">--</span>package_name PACKAGE_NAME
                        A global package name to be used <span class="token keyword">for</span> each node in the Model<span class="token punctuation">.</span>cpp file<span class="token punctuation">.</span>
                        Defaults to Qnn header defined package name
  <span class="token operator">--</span>op_package_config CUSTOM_OP_CONFIG_PATHS <span class="token punctuation">[</span>CUSTOM_OP_CONFIG_PATHS <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token operator">-</span>opc CUSTOM_OP_CONFIG_PATHS <span class="token punctuation">[</span>CUSTOM_OP_CONFIG_PATHS <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span>
                        Path to a Qnn Op Package XML configuration file that contains user defined
                        custom operations<span class="token punctuation">.</span>

Architecture Checker <span class="token function">Options</span><span class="token punctuation">(</span>Experimental<span class="token punctuation">)</span><span class="token operator">:</span>
  <span class="token operator">--</span>arch_checker        Note<span class="token operator">:</span> This option will be soon deprecated<span class="token punctuation">.</span> Use the qnn<span class="token operator">-</span>architecture<span class="token operator">-</span>checker tool to achieve the same result<span class="token punctuation">.</span>

</code></pre> 
<p>注意：只能指定以下之一：{‘package_name’, ‘op_package_config’}</p> 
<p>基本命令行用法如下：</p> 
<pre><code class="prism language-cpp">$ qnn<span class="token operator">-</span>pytorch<span class="token operator">-</span>converter <span class="token operator">-</span>i <span class="token operator">&lt;</span>path<span class="token operator">&gt;</span><span class="token operator">/</span>model<span class="token punctuation">.</span>pt
                       <span class="token operator">-</span>d <span class="token operator">&lt;</span>network_input_name<span class="token operator">&gt;</span> <span class="token operator">&lt;</span>dims<span class="token operator">&gt;</span>
                       <span class="token operator">-</span>o <span class="token operator">&lt;</span>optional_output_path<span class="token operator">&gt;</span>
                       <span class="token operator">-</span>p <span class="token operator">&lt;</span>optional_package_name<span class="token operator">&gt;</span> # Defaults to <span class="token string">"qti.aisw"</span>

</code></pre> 
<p>qnn-onnx-转换器<br> qnn -onnx-converter工具将模型从 ONNX 框架转换为 CPP 文件，将模型表示为一系列 QNN API 调用。此外，还会生成包含模型静态权重的二进制文件。</p> 
<pre><code class="prism language-cpp">usage<span class="token operator">:</span> qnn<span class="token operator">-</span>onnx<span class="token operator">-</span>converter <span class="token punctuation">[</span><span class="token operator">--</span>out_node OUT_NAMES<span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token operator">--</span>input_type INPUT_NAME INPUT_TYPE<span class="token punctuation">]</span>
            <span class="token punctuation">[</span><span class="token operator">--</span>input_dtype INPUT_NAME INPUT_DTYPE<span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token operator">--</span>input_encoding INPUT_ENCODING <span class="token punctuation">[</span>INPUT_ENCODING <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
            <span class="token punctuation">[</span><span class="token operator">--</span>input_layout INPUT_NAME INPUT_LAYOUT<span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token operator">--</span>custom_io CUSTOM_IO<span class="token punctuation">]</span>
            <span class="token punctuation">[</span><span class="token operator">--</span>dry_run <span class="token punctuation">[</span>DRY_RUN<span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token operator">-</span>d INPUT_NAME INPUT_DIM<span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token operator">-</span>n<span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token operator">-</span>b BATCH<span class="token punctuation">]</span>
            <span class="token punctuation">[</span><span class="token operator">-</span>s SYMBOL_NAME VALUE<span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token operator">--</span>preserve_io PRESERVE_IO<span class="token punctuation">]</span>
            <span class="token punctuation">[</span><span class="token operator">--</span>dump_custom_io_config_template DUMP_CUSTOM_IO_CONFIG_TEMPLATE<span class="token punctuation">]</span>
            <span class="token punctuation">[</span><span class="token operator">--</span>quantization_overrides QUANTIZATION_OVERRIDES<span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token operator">--</span>keep_quant_nodes<span class="token punctuation">]</span>
            <span class="token punctuation">[</span><span class="token operator">--</span>disable_batchnorm_folding<span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token operator">--</span>keep_disconnected_nodes<span class="token punctuation">]</span>
            <span class="token punctuation">[</span><span class="token operator">--</span>input_list INPUT_LIST<span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token operator">--</span>param_quantizer PARAM_QUANTIZER<span class="token punctuation">]</span>
            <span class="token punctuation">[</span><span class="token operator">--</span>act_quantizer ACT_QUANTIZER<span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token operator">--</span>algorithms ALGORITHMS <span class="token punctuation">[</span>ALGORITHMS <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
            <span class="token punctuation">[</span><span class="token operator">--</span>bias_bw BIAS_BW<span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token operator">--</span>act_bw ACT_BW<span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token operator">--</span>weight_bw WEIGHT_BW<span class="token punctuation">]</span>
            <span class="token punctuation">[</span><span class="token operator">--</span>ignore_encodings<span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token operator">--</span>use_per_row_quantization<span class="token punctuation">]</span>
            <span class="token punctuation">[</span><span class="token operator">--</span>use_per_channel_quantization <span class="token punctuation">[</span>USE_PER_CHANNEL_QUANTIZATION <span class="token punctuation">[</span>USE_PER_CHANNEL_QUANTIZATION <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
            <span class="token punctuation">[</span><span class="token operator">--</span>use_native_input_files<span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token operator">--</span>use_native_dtype<span class="token punctuation">]</span>
            <span class="token punctuation">[</span><span class="token operator">--</span>use_native_output_files<span class="token punctuation">]</span> <span class="token operator">--</span>input_network INPUT_NETWORK
            <span class="token punctuation">[</span><span class="token operator">--</span>debug <span class="token punctuation">[</span>DEBUG<span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token operator">-</span>o OUTPUT_PATH<span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token operator">--</span>copyright_file COPYRIGHT_FILE<span class="token punctuation">]</span>
            <span class="token punctuation">[</span><span class="token operator">--</span>float_bw FLOAT_BW<span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token operator">--</span>float_bias_bw FLOAT_BIAS_BW<span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token operator">--</span>overwrite_model_prefix<span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token operator">--</span>exclude_named_tensors<span class="token punctuation">]</span>
            <span class="token punctuation">[</span><span class="token operator">--</span>restrict_quantization_steps ENCODING_MIN<span class="token punctuation">,</span> ENCODING_MAX<span class="token punctuation">]</span>
            <span class="token punctuation">[</span><span class="token operator">--</span>op_package_lib OP_PACKAGE_LIB<span class="token punctuation">]</span>
            <span class="token punctuation">[</span><span class="token operator">--</span>converter_op_package_lib CONVERTER_OP_PACKAGE_LIB<span class="token punctuation">]</span>
            <span class="token punctuation">[</span><span class="token operator">-</span>p PACKAGE_NAME <span class="token operator">|</span> <span class="token operator">--</span>op_package_config CUSTOM_OP_CONFIG_PATHS <span class="token punctuation">[</span>CUSTOM_OP_CONFIG_PATHS <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
            <span class="token punctuation">[</span><span class="token operator">-</span>h<span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token operator">--</span>arch_checker<span class="token punctuation">]</span>

Script to convert ONNX model into QNN

required arguments<span class="token operator">:</span>
  <span class="token operator">--</span>input_network INPUT_NETWORK<span class="token punctuation">,</span> <span class="token operator">-</span>i INPUT_NETWORK
                        Path to the source framework model<span class="token punctuation">.</span>

optional arguments<span class="token operator">:</span>
  <span class="token operator">--</span>out_node OUT_NAMES<span class="token punctuation">,</span> <span class="token operator">--</span>out_name OUT_NAMES
                        Name of the graph<span class="token number">'</span>s output tensor names<span class="token punctuation">.</span> Multiple output
                        nodes should be provided separately like<span class="token operator">:</span>
                            <span class="token operator">--</span>out_name out_1 <span class="token operator">--</span>out_name out_2
  <span class="token operator">--</span>input_type INPUT_NAME INPUT_TYPE<span class="token punctuation">,</span> <span class="token operator">-</span>t INPUT_NAME INPUT_TYPE
                        Type of data expected by each input op<span class="token operator">/</span>layer<span class="token punctuation">.</span> Type <span class="token keyword">for</span>
                        each input is <span class="token operator">|</span><span class="token keyword">default</span><span class="token operator">|</span> <span class="token keyword">if</span> <span class="token operator">not</span> specified<span class="token punctuation">.</span> For example<span class="token operator">:</span>
                        <span class="token string">"data"</span> image<span class="token punctuation">.</span>Note that the quotes should always be
                        included in order to handle special characters<span class="token punctuation">,</span>
                        spaces<span class="token punctuation">,</span>etc<span class="token punctuation">.</span> For multiple inputs specify multiple
                        <span class="token operator">--</span>input_type on the command line<span class="token punctuation">.</span> Eg<span class="token operator">:</span>
                            <span class="token operator">--</span>input_type <span class="token string">"data1"</span> image <span class="token operator">--</span>input_type <span class="token string">"data2"</span> opaque
                        These options get used by DSP runtime <span class="token operator">and</span> following
                        descriptions state how input will be handled <span class="token keyword">for</span> each
                        option<span class="token punctuation">.</span>
                        Image<span class="token operator">:</span>
                        Input is <span class="token keyword">float</span> between <span class="token number">0</span><span class="token operator">-</span><span class="token number">255</span> <span class="token operator">and</span> the input<span class="token char">'s mean is 0.0f and the input'</span>s
                        max is <span class="token number">255.0f</span><span class="token punctuation">.</span> We will cast the <span class="token keyword">float</span> to uint8ts <span class="token operator">and</span> pass the uint8ts to
                        the DSP<span class="token punctuation">.</span>
                        Default<span class="token operator">:</span>
                        Pass the input as floats to the dsp
                        directly <span class="token operator">and</span> the DSP will quantize it<span class="token punctuation">.</span>
                        Opaque<span class="token operator">:</span>
                        Assumes input is <span class="token keyword">float</span> because the consumer <span class="token function">layer</span><span class="token punctuation">(</span>i<span class="token punctuation">.</span>e next
                        layer<span class="token punctuation">)</span> <span class="token keyword">requires</span> it as <span class="token keyword">float</span><span class="token punctuation">,</span> therefore it won<span class="token number">'</span>t be
                        quantized<span class="token punctuation">.</span>
                        Choices supported<span class="token operator">:</span>
                            image
                            <span class="token keyword">default</span>
                            opaque
  <span class="token operator">--</span>input_dtype INPUT_NAME INPUT_DTYPE
                        The names <span class="token operator">and</span> datatype of the network input layers
                        specified in the format <span class="token punctuation">[</span>input_name datatype<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token keyword">for</span>
                        example<span class="token operator">:</span>
                            <span class="token char">'data'</span> <span class="token char">'float32'</span><span class="token punctuation">.</span>
                        Default is float32 <span class="token keyword">if</span> <span class="token operator">not</span> specified<span class="token punctuation">.</span>
                        Note that the quotes should always be included in order to handle special
                        characters<span class="token punctuation">,</span> spaces<span class="token punctuation">,</span> etc<span class="token punctuation">.</span>
                        For multiple inputs specify multiple <span class="token operator">--</span>input_dtype on the command line like<span class="token operator">:</span>
                            <span class="token operator">--</span>input_dtype <span class="token char">'data1'</span> <span class="token char">'float32'</span> <span class="token operator">--</span>input_dtype <span class="token char">'data2'</span> <span class="token char">'float32'</span>
  <span class="token operator">--</span>input_encoding INPUT_ENCODING <span class="token punctuation">[</span>INPUT_ENCODING <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token operator">-</span>e INPUT_ENCODING <span class="token punctuation">[</span>INPUT_ENCODING <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span>
                        Usage<span class="token operator">:</span>     <span class="token operator">--</span>input_encoding <span class="token string">"INPUT_NAME"</span> INPUT_ENCODING_IN
                        <span class="token punctuation">[</span>INPUT_ENCODING_OUT<span class="token punctuation">]</span>
                        e<span class="token punctuation">.</span>g<span class="token punctuation">.</span>
                            <span class="token operator">--</span>input_encoding <span class="token string">"data"</span> rgba
                        Quotes must wrap the input node name to handle special characters<span class="token punctuation">,</span>
                        spaces<span class="token punctuation">,</span> etc<span class="token punctuation">.</span> To specify encodings <span class="token keyword">for</span> multiple inputs<span class="token punctuation">,</span> invoke
                        <span class="token operator">--</span>input_encoding <span class="token keyword">for</span> each one<span class="token punctuation">.</span>
                        e<span class="token punctuation">.</span>g<span class="token punctuation">.</span>
                            <span class="token operator">--</span>input_encoding <span class="token string">"data1"</span> rgba <span class="token operator">--</span>input_encoding <span class="token string">"data2"</span> other
                        Optionally<span class="token punctuation">,</span> an output encoding may be specified <span class="token keyword">for</span> an input node by
                        providing a second encoding<span class="token punctuation">.</span> The <span class="token keyword">default</span> output encoding is bgr<span class="token punctuation">.</span>
                        e<span class="token punctuation">.</span>g<span class="token punctuation">.</span>
                            <span class="token operator">--</span>input_encoding <span class="token string">"data3"</span> rgba rgb
                        Input encoding types<span class="token operator">:</span>
                            image color encodings<span class="token operator">:</span> bgr<span class="token punctuation">,</span>rgb<span class="token punctuation">,</span> nv21<span class="token punctuation">,</span> nv12<span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
                            time_series<span class="token operator">:</span> <span class="token keyword">for</span> inputs of rnn models<span class="token punctuation">;</span>
                            other<span class="token operator">:</span> <span class="token operator">not</span> available above <span class="token operator">or</span> is unknown<span class="token punctuation">.</span>
                        Supported encodings<span class="token operator">:</span>
                            bgr
                            rgb
                            rgba
                            argb32
                            nv21
                            nv12
                            time_series
                            other
  <span class="token operator">--</span>input_layout INPUT_NAME INPUT_LAYOUT<span class="token punctuation">,</span> <span class="token operator">-</span>l INPUT_NAME INPUT_LAYOUT
                        Layout of each input tensor<span class="token punctuation">.</span> If <span class="token operator">not</span> specified<span class="token punctuation">,</span> it will use the <span class="token keyword">default</span>
                        based on the Source Framework<span class="token punctuation">,</span> shape of input <span class="token operator">and</span> input encoding<span class="token punctuation">.</span>
                        Accepted values are<span class="token operator">-</span>
                            NCDHW<span class="token punctuation">,</span> NDHWC<span class="token punctuation">,</span> NCHW<span class="token punctuation">,</span> NHWC<span class="token punctuation">,</span> NFC<span class="token punctuation">,</span> NCF<span class="token punctuation">,</span> NTF<span class="token punctuation">,</span> TNF<span class="token punctuation">,</span> NF<span class="token punctuation">,</span> NC<span class="token punctuation">,</span> F<span class="token punctuation">,</span> NONTRIVIAL
                        N <span class="token operator">=</span> Batch<span class="token punctuation">,</span> C <span class="token operator">=</span> Channels<span class="token punctuation">,</span> D <span class="token operator">=</span> Depth<span class="token punctuation">,</span> H <span class="token operator">=</span> Height<span class="token punctuation">,</span> W <span class="token operator">=</span> Width<span class="token punctuation">,</span> F <span class="token operator">=</span> Feature<span class="token punctuation">,</span> T <span class="token operator">=</span> Time
                        NDHWC<span class="token operator">/</span>NCDHW used <span class="token keyword">for</span> <span class="token number">5</span>d inputs
                        NHWC<span class="token operator">/</span>NCHW used <span class="token keyword">for</span> <span class="token number">4</span>d image<span class="token operator">-</span>like inputs
                        NFC<span class="token operator">/</span>NCF used <span class="token keyword">for</span> inputs to Conv1D <span class="token operator">or</span> other <span class="token number">1</span>D ops
                        NTF<span class="token operator">/</span>TNF used <span class="token keyword">for</span> inputs with time steps like the ones used <span class="token keyword">for</span> LSTM op
                        NF used <span class="token keyword">for</span> <span class="token number">2</span>D inputs<span class="token punctuation">,</span> like the inputs to Dense<span class="token operator">/</span>FullyConnected layers
                        NC used <span class="token keyword">for</span> <span class="token number">2</span>D inputs with <span class="token number">1</span> <span class="token keyword">for</span> batch <span class="token operator">and</span> other <span class="token keyword">for</span> <span class="token function">Channels</span> <span class="token punctuation">(</span>rarely used<span class="token punctuation">)</span>
                        F used <span class="token keyword">for</span> <span class="token number">1</span>D inputs<span class="token punctuation">,</span> e<span class="token punctuation">.</span>g<span class="token punctuation">.</span> Bias tensor
                        NONTRIVIAL <span class="token keyword">for</span> everything elseFor multiple inputs specify multiple
                        <span class="token operator">--</span>input_layout on the command line<span class="token punctuation">.</span>
                        Eg<span class="token operator">:</span>
                            <span class="token operator">--</span>input_layout <span class="token string">"data1"</span> NCHW <span class="token operator">--</span>input_layout <span class="token string">"data2"</span> NCHW
                        Note<span class="token operator">:</span> This flag does <span class="token operator">not</span> set the layout of the input tensor in the converted DLC<span class="token punctuation">.</span>
                            Please use <span class="token operator">--</span>custom_io <span class="token keyword">for</span> that<span class="token punctuation">.</span>
  <span class="token operator">--</span>custom_io CUSTOM_IO
                        Use <span class="token keyword">this</span> option to specify a yaml file <span class="token keyword">for</span> custom IO<span class="token punctuation">.</span>
  <span class="token operator">--</span>preserve_io PRESERVE_IO
                        Use <span class="token keyword">this</span> option to preserve IO layout <span class="token operator">and</span> datatype<span class="token punctuation">.</span> The different ways of <span class="token keyword">using</span>
                        <span class="token keyword">this</span> option are as follows<span class="token operator">:</span>
                            <span class="token operator">--</span>preserve_io layout <span class="token operator">&lt;</span>space separated list of names of inputs <span class="token operator">and</span> outputs of the graph<span class="token operator">&gt;</span>
                            <span class="token operator">--</span>preserve_io datatype <span class="token operator">&lt;</span>space separated list of names of inputs <span class="token operator">and</span> outputs of the graph<span class="token operator">&gt;</span>
                        In <span class="token keyword">this</span> <span class="token keyword">case</span><span class="token punctuation">,</span> user should also specify the string <span class="token operator">-</span> layout <span class="token operator">or</span> datatype in the command
                        to indicate that converter needs to preserve the layout <span class="token operator">or</span> datatype<span class="token punctuation">.</span> e<span class="token punctuation">.</span>g<span class="token punctuation">.</span>
                            <span class="token operator">--</span>preserve_io layout input1 input2 output1
                            <span class="token operator">--</span>preserve_io datatype input1 input2 output1
                        Optionally<span class="token punctuation">,</span> the user may choose to preserve the layout <span class="token operator">and</span><span class="token operator">/</span><span class="token operator">or</span> datatype <span class="token keyword">for</span> all
                        the inputs <span class="token operator">and</span> outputs of the graph<span class="token punctuation">.</span> This can be done in the following two ways<span class="token operator">:</span>
                            <span class="token operator">--</span>preserve_io layout
                            <span class="token operator">--</span>preserve_io datatype
                        Additionally<span class="token punctuation">,</span> the user may choose to preserve both layout <span class="token operator">and</span> datatypes <span class="token keyword">for</span> all
                        IO tensors by just passing the option as follows<span class="token operator">:</span>
                            <span class="token operator">--</span>preserve_io
                        Note<span class="token operator">:</span> Only one of the above usages are allowed at a time<span class="token punctuation">.</span>
                        Note<span class="token operator">:</span> <span class="token operator">--</span>custom_io gets higher precedence than <span class="token operator">--</span>preserve_io<span class="token punctuation">.</span>
  <span class="token operator">--</span>dry_run <span class="token punctuation">[</span>DRY_RUN<span class="token punctuation">]</span>   Evaluates the model without actually converting any ops<span class="token punctuation">,</span> <span class="token operator">and</span> returns
                        unsupported ops<span class="token operator">/</span>attributes as well as unused inputs <span class="token operator">and</span><span class="token operator">/</span><span class="token operator">or</span> outputs <span class="token keyword">if</span> any<span class="token punctuation">.</span>
                        Leave empty <span class="token operator">or</span> specify <span class="token string">"info"</span> to see dry run as a table<span class="token punctuation">,</span> <span class="token operator">or</span> specify <span class="token string">"debug"</span>
                        to show more detailed messages only"
  <span class="token operator">-</span>d INPUT_NAME INPUT_DIM<span class="token punctuation">,</span> <span class="token operator">--</span>input_dim INPUT_NAME INPUT_DIM
                        The name <span class="token operator">and</span> dimension of all the input buffers to the network specified in
                        the format <span class="token punctuation">[</span>input_name comma<span class="token operator">-</span>separated<span class="token operator">-</span>dimensions<span class="token punctuation">]</span><span class="token punctuation">,</span>
                        <span class="token keyword">for</span> example<span class="token operator">:</span> <span class="token char">'data'</span> <span class="token number">1</span><span class="token punctuation">,</span><span class="token number">224</span><span class="token punctuation">,</span><span class="token number">224</span><span class="token punctuation">,</span><span class="token number">3.</span>
                        Note that the quotes should always be included in order to handle special
                        characters<span class="token punctuation">,</span> spaces<span class="token punctuation">,</span> etc<span class="token punctuation">.</span>
                        NOTE<span class="token operator">:</span> This feature works only with Onnx <span class="token number">1.6</span><span class="token punctuation">.</span><span class="token number">0</span> <span class="token operator">and</span> above
  <span class="token operator">-</span>n<span class="token punctuation">,</span> <span class="token operator">--</span>no_simplification
                        Do <span class="token operator">not</span> attempt to simplify the model automatically<span class="token punctuation">.</span> This may prevent some
                        models from properly converting
  <span class="token operator">-</span>b BATCH<span class="token punctuation">,</span> <span class="token operator">--</span>batch BATCH
                        The batch dimension <span class="token keyword">override</span><span class="token punctuation">.</span> This will take the first dimension of all
                        inputs <span class="token operator">and</span> treat it as a batch dim<span class="token punctuation">,</span> overriding it with the value provided
                        here<span class="token punctuation">.</span> For example<span class="token operator">:</span>
                        <span class="token operator">--</span>batch <span class="token number">6</span>
                        will result in a shape change from <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">224</span><span class="token punctuation">,</span><span class="token number">224</span><span class="token punctuation">]</span> to <span class="token punctuation">[</span><span class="token number">6</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">224</span><span class="token punctuation">,</span><span class="token number">224</span><span class="token punctuation">]</span><span class="token punctuation">.</span>
                        If there are inputs without batch dim <span class="token keyword">this</span> should <span class="token operator">not</span> be used <span class="token operator">and</span> each input
                        should be overridden independently <span class="token keyword">using</span> <span class="token operator">-</span>d option <span class="token keyword">for</span> input dimension
                        overrides<span class="token punctuation">.</span>
  <span class="token operator">-</span>s SYMBOL_NAME VALUE<span class="token punctuation">,</span> <span class="token operator">--</span>define_symbol SYMBOL_NAME VALUE
                        This option allows overriding specific input dimension symbols<span class="token punctuation">.</span> For instance
                        you might see input shapes specified with variables such as <span class="token operator">:</span>
                        data<span class="token operator">:</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span>height<span class="token punctuation">,</span>width<span class="token punctuation">]</span>
                        To <span class="token keyword">override</span> these simply pass the option as<span class="token operator">:</span>
                        <span class="token operator">--</span>define_symbol height <span class="token number">224</span> <span class="token operator">--</span>define_symbol width <span class="token number">448</span>
                        which results in dimensions that look like<span class="token operator">:</span>
                        data<span class="token operator">:</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">224</span><span class="token punctuation">,</span><span class="token number">448</span><span class="token punctuation">]</span>
  <span class="token operator">--</span>dump_custom_io_config_template
                        Dumps the yaml <span class="token keyword">template</span> <span class="token keyword">for</span> Custom I<span class="token operator">/</span>O configuration<span class="token punctuation">.</span> This file can be edited
                        as per the custom requirements <span class="token operator">and</span> passed <span class="token keyword">using</span> the option <span class="token operator">--</span>custom_ioUse
                        <span class="token keyword">this</span> option to specify a yaml file to which the custom IO config <span class="token keyword">template</span> is
                        dumped<span class="token punctuation">.</span>
  <span class="token operator">--</span>disable_batchnorm_folding
  <span class="token operator">--</span>keep_disconnected_nodes
                        Disable Optimization that removes Ops <span class="token operator">not</span> connected to the main graph<span class="token punctuation">.</span>
                        This optimization uses output names provided over commandline OR
                        inputs<span class="token operator">/</span>outputs extracted from the Source model to determine the main graph
  <span class="token operator">--</span>debug <span class="token punctuation">[</span>DEBUG<span class="token punctuation">]</span>       Run the converter in debug mode<span class="token punctuation">.</span>
  <span class="token operator">-</span>o OUTPUT_PATH<span class="token punctuation">,</span> <span class="token operator">--</span>output_path OUTPUT_PATH
                        Path where the converted Output model should be saved<span class="token punctuation">.</span>If <span class="token operator">not</span> specified<span class="token punctuation">,</span> the
                        converter model will be written to a file with same name as the input model
  <span class="token operator">--</span>copyright_file COPYRIGHT_FILE
                        Path to copyright file<span class="token punctuation">.</span> If provided<span class="token punctuation">,</span> the content of the file will be added
                        to the output model<span class="token punctuation">.</span>
  <span class="token operator">--</span>float_bw FLOAT_BW   Use the <span class="token operator">--</span>float_bw option to select the bitwidth to use when <span class="token keyword">using</span> <span class="token keyword">float</span> <span class="token keyword">for</span>
                        <span class="token function">parameters</span><span class="token punctuation">(</span>weights<span class="token operator">/</span>bias<span class="token punctuation">)</span> <span class="token operator">and</span> activations <span class="token keyword">for</span> all ops  <span class="token operator">or</span> specific <span class="token function">Op</span> <span class="token punctuation">(</span>via
                        encodings<span class="token punctuation">)</span> selected through encoding<span class="token punctuation">,</span> either <span class="token number">32</span> <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span> <span class="token operator">or</span> <span class="token number">16.</span>
  <span class="token operator">--</span>overwrite_model_prefix
                        If option passed<span class="token punctuation">,</span> model generator will use the output path name to use as
                        model prefix to name functions in <span class="token operator">&lt;</span>qnn_model_name<span class="token operator">&gt;</span><span class="token punctuation">.</span>cpp<span class="token punctuation">.</span> <span class="token punctuation">(</span>Useful <span class="token keyword">for</span> running
                        multiple models at once<span class="token punctuation">)</span> eg<span class="token operator">:</span> ModelName_composeGraphs<span class="token punctuation">.</span> Default is to use
                        generic <span class="token string">"QnnModel_"</span><span class="token punctuation">.</span>
  <span class="token operator">--</span>exclude_named_tensors
                        Remove <span class="token keyword">using</span> source framework tensorNames<span class="token punctuation">;</span> instead use a counter <span class="token keyword">for</span> naming
                        tensors<span class="token punctuation">.</span> Note<span class="token operator">:</span> This can potentially help to reduce  the <span class="token keyword">final</span> model library
                        that will be <span class="token function">generated</span><span class="token punctuation">(</span>Recommended <span class="token keyword">for</span> deploying model<span class="token punctuation">)</span><span class="token punctuation">.</span> Default is False<span class="token punctuation">.</span>
  <span class="token operator">-</span>h<span class="token punctuation">,</span> <span class="token operator">--</span>help            show <span class="token keyword">this</span> help message <span class="token operator">and</span> exit

Quantizer Options<span class="token operator">:</span>
  <span class="token operator">--</span>quantization_overrides QUANTIZATION_OVERRIDES
                        Use <span class="token keyword">this</span> option to specify a json file with parameters to use <span class="token keyword">for</span>
                        quantization<span class="token punctuation">.</span> These will <span class="token keyword">override</span> any quantization data carried from
                        <span class="token function">conversion</span> <span class="token punctuation">(</span>eg TF fake quantization<span class="token punctuation">)</span> <span class="token operator">or</span> calculated during the normal
                        quantization process<span class="token punctuation">.</span> Format defined as per AIMET specification<span class="token punctuation">.</span>

  <span class="token operator">--</span>keep_quant_nodes    Use <span class="token keyword">this</span> option to keep activation quantization nodes in the graph rather
                        than stripping them<span class="token punctuation">.</span>
  <span class="token operator">--</span>input_list INPUT_LIST
                        Path to a file specifying the input data<span class="token punctuation">.</span> This file should be a plain text
                        file<span class="token punctuation">,</span> containing one <span class="token operator">or</span> more absolute file paths per line<span class="token punctuation">.</span> Each path is
                        expected to point to a binary file containing one input in the <span class="token string">"raw"</span> format<span class="token punctuation">,</span>
                        ready to be consumed by the quantizer without any further preprocessing<span class="token punctuation">.</span>
                        Multiple files per line separated by spaces indicate multiple inputs to the
                        network<span class="token punctuation">.</span> See documentation <span class="token keyword">for</span> more details<span class="token punctuation">.</span> Must be specified <span class="token keyword">for</span>
                        quantization<span class="token punctuation">.</span> All subsequent quantization options are ignored when <span class="token keyword">this</span> is
                        <span class="token operator">not</span> provided<span class="token punctuation">.</span>
  <span class="token operator">--</span>param_quantizer PARAM_QUANTIZER
                        Optional parameter to indicate the weight<span class="token operator">/</span>bias quantizer to use<span class="token punctuation">.</span> Must be
                        followed by one of the following options<span class="token operator">:</span> <span class="token string">"tf"</span><span class="token operator">:</span> Uses the real min<span class="token operator">/</span>max of the
                        data <span class="token operator">and</span> specified <span class="token function">bitwidth</span> <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span> <span class="token string">"enhanced"</span><span class="token operator">:</span> Uses an algorithm useful
                        <span class="token keyword">for</span> quantizing models with <span class="token keyword">long</span> tails present in the weight distribution
                        <span class="token string">"adjusted"</span><span class="token operator">:</span> Uses an adjusted min<span class="token operator">/</span>max <span class="token keyword">for</span> computing the range<span class="token punctuation">,</span> particularly
                        good <span class="token keyword">for</span> denoise models <span class="token string">"symmetric"</span><span class="token operator">:</span> Ensures min <span class="token operator">and</span> max have the same
                        absolute values about zero<span class="token punctuation">.</span> Data will be stored as <span class="token keyword">int</span>#_t data such that the
                        offset is always <span class="token number">0.</span>
  <span class="token operator">--</span>act_quantizer ACT_QUANTIZER
                        Optional parameter to indicate the activation quantizer to use<span class="token punctuation">.</span> Must be
                        followed by one of the following options<span class="token operator">:</span> <span class="token string">"tf"</span><span class="token operator">:</span> Uses the real min<span class="token operator">/</span>max of the
                        data <span class="token operator">and</span> specified <span class="token function">bitwidth</span> <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span> <span class="token string">"enhanced"</span><span class="token operator">:</span> Uses an algorithm useful
                        <span class="token keyword">for</span> quantizing models with <span class="token keyword">long</span> tails present in the weight distribution
                        <span class="token string">"adjusted"</span><span class="token operator">:</span> Uses an adjusted min<span class="token operator">/</span>max <span class="token keyword">for</span> computing the range<span class="token punctuation">,</span> particularly
                        good <span class="token keyword">for</span> denoise models <span class="token string">"symmetric"</span><span class="token operator">:</span> Ensures min <span class="token operator">and</span> max have the same
                        absolute values about zero<span class="token punctuation">.</span> Data will be stored as <span class="token keyword">int</span>#_t data such that the
                        offset is always <span class="token number">0.</span>
  <span class="token operator">--</span>algorithms ALGORITHMS <span class="token punctuation">[</span>ALGORITHMS <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span>
                        Use <span class="token keyword">this</span> option to enable <span class="token keyword">new</span> optimization algorithms<span class="token punctuation">.</span> Usage is<span class="token operator">:</span>
                        <span class="token operator">--</span>algorithms <span class="token operator">&lt;</span>algo_name1<span class="token operator">&gt;</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> The available optimization algorithms are<span class="token operator">:</span>
                        <span class="token string">"cle"</span> <span class="token operator">-</span> Cross layer equalization includes a number of methods <span class="token keyword">for</span> equalizing
                        weights <span class="token operator">and</span> biases across layers in order to rectify imbalances that cause
                        quantization errors<span class="token punctuation">.</span>

  <span class="token operator">--</span>bias_bw BIAS_BW     Use the <span class="token operator">--</span>bias_bw option to select the bitwidth to use when quantizing the
                        biases<span class="token punctuation">,</span> either <span class="token number">8</span> <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span> <span class="token operator">or</span> <span class="token number">32.</span>
  <span class="token operator">--</span>act_bw ACT_BW       Use the <span class="token operator">--</span>act_bw option to select the bitwidth to use when quantizing the
                        activations<span class="token punctuation">,</span> either <span class="token number">8</span> <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span> <span class="token operator">or</span> <span class="token number">16.</span>
  <span class="token operator">--</span>weight_bw WEIGHT_BW
                        Use the <span class="token operator">--</span>weight_bw option to select the bitwidth to use when quantizing the
                        weights<span class="token punctuation">,</span> currently only <span class="token number">8</span> <span class="token function">bit</span> <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span> supported<span class="token punctuation">.</span>
  <span class="token operator">--</span>float_bias_bw FLOAT_BIAS_BW
                        Use the <span class="token operator">--</span>float_bias_bw option to select the bitwidth to use when biases are
                        in <span class="token keyword">float</span><span class="token punctuation">,</span> either <span class="token number">32</span> <span class="token operator">or</span> <span class="token number">16.</span>
  <span class="token operator">--</span>ignore_encodings    Use only quantizer generated encodings<span class="token punctuation">,</span> ignoring any user <span class="token operator">or</span> model provided
                        encodings<span class="token punctuation">.</span>
                        Note<span class="token operator">:</span> Cannot use <span class="token operator">--</span>ignore_encodings with <span class="token operator">--</span>quantization_overrides
  <span class="token operator">--</span>use_per_row_quantization
                        Use <span class="token keyword">this</span> option to enable rowwise quantization of Matmul <span class="token operator">and</span> FullyConnected
                        ops<span class="token punctuation">.</span>
  <span class="token operator">--</span>use_per_channel_quantization <span class="token punctuation">[</span>USE_PER_CHANNEL_QUANTIZATION <span class="token punctuation">[</span>USE_PER_CHANNEL_QUANTIZATION <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
                        Use per<span class="token operator">-</span>channel quantization <span class="token keyword">for</span> convolution<span class="token operator">-</span>based op weights<span class="token punctuation">.</span>
                        Note<span class="token operator">:</span> This will replace built<span class="token operator">-</span>in model QAT encodings when used <span class="token keyword">for</span> a given
                        weight<span class="token punctuation">.</span>Usage <span class="token string">"--use_per_channel_quantization"</span> to enable <span class="token operator">or</span> "<span class="token operator">--</span>
                        use_per_channel_quantization <span class="token boolean">false</span>" <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span> to disable
  <span class="token operator">--</span>use_native_input_files
                        Boolean flag to indicate how to read input files<span class="token operator">:</span>
                        <span class="token number">1.</span> <span class="token keyword">float</span> <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">:</span> reads inputs as floats <span class="token operator">and</span> quantizes <span class="token keyword">if</span> necessary based
                        on quantization parameters in the model<span class="token punctuation">.</span>
                        <span class="token number">2.</span> native<span class="token operator">:</span> reads inputs assuming the data type to be native to the
                        model<span class="token punctuation">.</span> For ex<span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token keyword">uint8_t</span><span class="token punctuation">.</span>
  <span class="token operator">--</span>use_native_dtype    Note<span class="token operator">:</span> This option is deprecated<span class="token punctuation">,</span> use <span class="token operator">--</span>use_native_input_files option in
                        future<span class="token punctuation">.</span>
                        Boolean flag to indicate how to read input files<span class="token operator">:</span>
                        <span class="token number">1.</span> <span class="token keyword">float</span> <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">:</span> reads inputs as floats <span class="token operator">and</span> quantizes <span class="token keyword">if</span> necessary based
                        on quantization parameters in the model<span class="token punctuation">.</span>
                        <span class="token number">2.</span> native<span class="token operator">:</span> reads inputs assuming the data type to be native to the
                        model<span class="token punctuation">.</span> For ex<span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token keyword">uint8_t</span><span class="token punctuation">.</span>
  <span class="token operator">--</span>use_native_output_files
                        Use <span class="token keyword">this</span> option to indicate the data type of the output files
                        <span class="token number">1.</span> <span class="token keyword">float</span> <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">:</span> output the file as floats<span class="token punctuation">.</span>
                        <span class="token number">2.</span> native<span class="token operator">:</span>          outputs the file that is native to the model<span class="token punctuation">.</span> For ex<span class="token punctuation">.</span><span class="token punctuation">,</span>
                        <span class="token keyword">uint8_t</span><span class="token punctuation">.</span>
  <span class="token operator">--</span>restrict_quantization_steps ENCODING_MIN<span class="token punctuation">,</span> ENCODING_MAX
                        Specifies the number of steps to use <span class="token keyword">for</span> computing quantization encodings
                        such that scale <span class="token operator">=</span> <span class="token punctuation">(</span>max <span class="token operator">-</span> min<span class="token punctuation">)</span> <span class="token operator">/</span> number of quantization steps<span class="token punctuation">.</span>
                        The option should be passed as a space separated pair of hexadecimal string
                        minimum <span class="token operator">and</span> maximum values<span class="token punctuation">.</span> i<span class="token punctuation">.</span>e<span class="token punctuation">.</span> <span class="token operator">--</span>restrict_quantization_steps <span class="token string">"MIN MAX"</span><span class="token punctuation">.</span>
                        Please note that <span class="token keyword">this</span> is a hexadecimal string literal <span class="token operator">and</span> <span class="token operator">not</span> a <span class="token keyword">signed</span>
                        integer<span class="token punctuation">,</span> to supply a negative value an <span class="token keyword">explicit</span> minus sign is required<span class="token punctuation">.</span>
                        E<span class="token punctuation">.</span>g<span class="token punctuation">.</span><span class="token operator">--</span>restrict_quantization_steps <span class="token string">"-0x80 0x7F"</span> indicates an example <span class="token number">8</span> bit range<span class="token punctuation">,</span>
                        <span class="token operator">--</span>restrict_quantization_steps <span class="token string">"-0x8000 0x7F7F"</span> indicates an example <span class="token number">16</span>
                        bit range<span class="token punctuation">.</span> This argument is required <span class="token keyword">for</span> <span class="token number">16</span><span class="token operator">-</span>bit Matmul operations<span class="token punctuation">.</span>

Custom Op Package Options<span class="token operator">:</span>
  <span class="token operator">--</span>op_package_lib OP_PACKAGE_LIB<span class="token punctuation">,</span> <span class="token operator">-</span>opl OP_PACKAGE_LIB
                        Use <span class="token keyword">this</span> argument to pass an op package library <span class="token keyword">for</span> quantization<span class="token punctuation">.</span> Must be in
                        the form <span class="token operator">&lt;</span>op_package_lib_path<span class="token operator">:</span>interfaceProviderName<span class="token operator">&gt;</span> <span class="token operator">and</span> be separated by a
                        comma <span class="token keyword">for</span> multiple package libs
  <span class="token operator">--</span>converter_op_package_lib CONVERTER_OP_PACKAGE_LIB<span class="token punctuation">,</span> <span class="token operator">-</span>cpl CONVERTER_OP_PACKAGE_LIB
                        Absolute path to converter op package library compiled by the OpPackage
                        generator<span class="token punctuation">.</span> Must be separated by a comma <span class="token keyword">for</span> multiple package libraries<span class="token punctuation">.</span>
                        Note<span class="token operator">:</span> Libraries must follow the same order as the xml files<span class="token punctuation">.</span>
                        E<span class="token punctuation">.</span>g<span class="token punctuation">.</span><span class="token number">1</span><span class="token operator">:</span> <span class="token operator">--</span>converter_op_package_lib absolute_path_to<span class="token operator">/</span>libExample<span class="token punctuation">.</span>so
                        E<span class="token punctuation">.</span>g<span class="token punctuation">.</span><span class="token number">2</span><span class="token operator">:</span> <span class="token operator">-</span>cpl absolute_path_to<span class="token operator">/</span>libExample1<span class="token punctuation">.</span>so<span class="token punctuation">,</span>absolute_path_to<span class="token operator">/</span>libExample2<span class="token punctuation">.</span>so
  <span class="token operator">-</span>p PACKAGE_NAME<span class="token punctuation">,</span> <span class="token operator">--</span>package_name PACKAGE_NAME
                        A global package name to be used <span class="token keyword">for</span> each node in the Model<span class="token punctuation">.</span>cpp file<span class="token punctuation">.</span>
                        Defaults to Qnn header defined package name
  <span class="token operator">--</span>op_package_config OP_PACKAGE_CONFIG <span class="token punctuation">[</span>OP_PACKAGE_CONFIG <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token operator">-</span>opc OP_PACKAGE_CONFIG <span class="token punctuation">[</span>OP_PACKAGE_CONFIG <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span>
                        Path to a Qnn Op Package XML configuration file that contains user defined
                        custom operations<span class="token punctuation">.</span>

Architecture Checker <span class="token function">Options</span><span class="token punctuation">(</span>Experimental<span class="token punctuation">)</span><span class="token operator">:</span>
  <span class="token operator">--</span>arch_checker        Note<span class="token operator">:</span> This option will be soon deprecated<span class="token punctuation">.</span> Use the qnn<span class="token operator">-</span>architecture<span class="token operator">-</span>checker tool to achieve the same result<span class="token punctuation">.</span>

Note<span class="token operator">:</span> Only one of<span class="token operator">:</span> <span class="token punctuation">{<!-- --></span><span class="token char">'package_name'</span><span class="token punctuation">,</span> <span class="token char">'op_package_config'</span><span class="token punctuation">}</span> can be specified
</code></pre> 
<h3><a id="62__1198"></a>6.2 模型准备</h3> 
<p>量化支持<br> 量化通过转换器接口支持并在转换时执行。启用量化和转换所需的唯一选项是 –input_list 选项，它为量化器提供给定模型所需的输入数据。上面列出的每个转换器都提供以下选项来启用和配置量化：</p> 
<pre><code class="prism language-cpp">Quantizer Options<span class="token operator">:</span>
<span class="token operator">--</span>quantization_overrides QUANTIZATION_OVERRIDES
                        Use <span class="token keyword">this</span> option to specify a json file with parameters
                        to use <span class="token keyword">for</span> quantization<span class="token punctuation">.</span> These will <span class="token keyword">override</span> any
                        quantization data carried from <span class="token function">conversion</span> <span class="token punctuation">(</span>eg TF fake
                        quantization<span class="token punctuation">)</span> <span class="token operator">or</span> calculated during the normal
                        quantization process<span class="token punctuation">.</span> Format defined as per AIMET
                        specification<span class="token punctuation">.</span>
<span class="token operator">--</span>input_list INPUT_LIST
                      Path to a file specifying the input data<span class="token punctuation">.</span> This file
                      should be a plain text file<span class="token punctuation">,</span> containing one <span class="token operator">or</span> more
                      absolute file paths per line<span class="token punctuation">.</span> Each path is expected to
                      point to a binary file containing one input in the
                      <span class="token string">"raw"</span> format<span class="token punctuation">,</span> ready to be consumed by the quantizer
                      without any further preprocessing<span class="token punctuation">.</span> Multiple files per
                      line separated by spaces indicate multiple inputs to
                      the network<span class="token punctuation">.</span> See documentation <span class="token keyword">for</span> more details<span class="token punctuation">.</span> Must
                      be specified <span class="token keyword">for</span> quantization<span class="token punctuation">.</span> All subsequent
                      quantization options are ignored when <span class="token keyword">this</span> is <span class="token operator">not</span>
                      provided<span class="token punctuation">.</span>
<span class="token operator">--</span>param_quantizer PARAM_QUANTIZER
                      Optional parameter to indicate the weight<span class="token operator">/</span>bias
                      quantizer to use<span class="token punctuation">.</span> Must be followed by one of the
                      following options<span class="token operator">:</span> <span class="token string">"tf"</span><span class="token operator">:</span> Uses the real min<span class="token operator">/</span>max of the
                      data <span class="token operator">and</span> specified <span class="token function">bitwidth</span> <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span> <span class="token string">"enhanced"</span><span class="token operator">:</span> Uses
                      an algorithm useful <span class="token keyword">for</span> quantizing models with <span class="token keyword">long</span>
                      tails present in the weight distribution <span class="token string">"adjusted"</span><span class="token operator">:</span>
                      Uses an adjusted min<span class="token operator">/</span>max <span class="token keyword">for</span> computing the range<span class="token punctuation">,</span>
                      particularly good <span class="token keyword">for</span> denoise models <span class="token string">"symmetric"</span><span class="token operator">:</span>
                      Ensures min <span class="token operator">and</span> max have the same absolute values
                      about zero<span class="token punctuation">.</span> Data will be stored as <span class="token keyword">int</span>#_t data such
                      that the offset is always <span class="token number">0.</span>
<span class="token operator">--</span>act_quantizer ACT_QUANTIZER
                      Optional parameter to indicate the activation
                      quantizer to use<span class="token punctuation">.</span> Must be followed by one of the
                      following options<span class="token operator">:</span> <span class="token string">"tf"</span><span class="token operator">:</span> Uses the real min<span class="token operator">/</span>max of the
                      data <span class="token operator">and</span> specified <span class="token function">bitwidth</span> <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span> <span class="token string">"enhanced"</span><span class="token operator">:</span> Uses
                      an algorithm useful <span class="token keyword">for</span> quantizing models with <span class="token keyword">long</span>
                      tails present in the weight distribution <span class="token string">"adjusted"</span><span class="token operator">:</span>
                      Uses an adjusted min<span class="token operator">/</span>max <span class="token keyword">for</span> computing the range<span class="token punctuation">,</span>
                      particularly good <span class="token keyword">for</span> denoise models <span class="token string">"symmetric"</span><span class="token operator">:</span>
                      Ensures min <span class="token operator">and</span> max have the same absolute values
                      about zero<span class="token punctuation">.</span> Data will be stored as <span class="token keyword">int</span>#_t data such
                      that the offset is always <span class="token number">0.</span>
<span class="token operator">--</span>algorithms ALGORITHMS <span class="token punctuation">[</span>ALGORITHMS <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span>
                      Use <span class="token keyword">this</span> option to enable <span class="token keyword">new</span> optimization algorithms<span class="token punctuation">.</span>
                      Usage is<span class="token operator">:</span> <span class="token operator">--</span>algorithms <span class="token operator">&lt;</span>algo_name1<span class="token operator">&gt;</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> The
                      available optimization algorithms are<span class="token operator">:</span> <span class="token string">"cle"</span> <span class="token operator">-</span> Cross
                      layer equalization includes a number of methods <span class="token keyword">for</span>
                      equalizing weights <span class="token operator">and</span> biases across layers in order
                      to rectify imbalances that cause quantization errors<span class="token punctuation">.</span>
<span class="token operator">--</span>bias_bw BIAS_BW     Use the <span class="token operator">--</span>bias_bw option to select the bitwidth to use
                      when quantizing the biases<span class="token punctuation">,</span> either <span class="token number">8</span> <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span> <span class="token operator">or</span> <span class="token number">32.</span>
<span class="token operator">--</span>act_bw ACT_BW       Use the <span class="token operator">--</span>act_bw option to select the bitwidth to use
                      when quantizing the activations<span class="token punctuation">,</span> either <span class="token number">8</span> <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span> <span class="token operator">or</span>
                      <span class="token number">16.</span>
<span class="token operator">--</span>weight_bw WEIGHT_BW
                      Use the <span class="token operator">--</span>weight_bw option to select the bitwidth to
                      use when quantizing the weights<span class="token punctuation">,</span> currently only <span class="token number">8</span> <span class="token function">bit</span>
                      <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span> supported<span class="token punctuation">.</span>
<span class="token operator">--</span>float_bias_bw FLOAT_BIAS_BW
                      Use the <span class="token operator">--</span>float_bias_bw option to select the bitwidth to
                      use when biases are in <span class="token keyword">float</span><span class="token punctuation">,</span> either <span class="token number">32</span> <span class="token operator">or</span> <span class="token number">16.</span>
<span class="token operator">--</span>ignore_encodings    Use only quantizer generated encodings<span class="token punctuation">,</span> ignoring any
                      user <span class="token operator">or</span> model provided encodings<span class="token punctuation">.</span> Note<span class="token operator">:</span> Cannot use
                      <span class="token operator">--</span>ignore_encodings with <span class="token operator">--</span>quantization_overrides
<span class="token operator">--</span>use_per_channel_quantization <span class="token punctuation">[</span>USE_PER_CHANNEL_QUANTIZATION <span class="token punctuation">[</span>USE_PER_CHANNEL_QUANTIZATION <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
                      Use per<span class="token operator">-</span>channel quantization <span class="token keyword">for</span>
                      convolution<span class="token operator">-</span>based op weights<span class="token punctuation">.</span> Note<span class="token operator">:</span> This will replace
                      built<span class="token operator">-</span>in model QAT encodings when used <span class="token keyword">for</span> a given
                      weight<span class="token punctuation">.</span>Usage <span class="token string">"--use_per_channel_quantization"</span> to
                      enable <span class="token operator">or</span> <span class="token string">"--use_per_channel_quantization false"</span>
                      <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span> to disable
<span class="token operator">--</span>use_per_row_quantization <span class="token punctuation">[</span>USE_PER_ROW_QUANTIZATION <span class="token punctuation">[</span>USE_PER_ROW_QUANTIZATION <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
                      Use <span class="token keyword">this</span> option to enable rowwise quantization of Matmul <span class="token operator">and</span>
                      FullyConnected op<span class="token punctuation">.</span> Usage <span class="token string">"--use_per_row_quantization"</span> to enable
                      <span class="token operator">or</span> <span class="token string">"--use_per_row_quantization false"</span> <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span> to
                      disable<span class="token punctuation">.</span> This option may <span class="token operator">not</span> be supported by all backends<span class="token punctuation">.</span>
</code></pre> 
<p>使用 TF 转换器转换和量化模型的基本命令行用法如下：</p> 
<pre><code class="prism language-cpp">$ qnn<span class="token operator">-</span>tensorflow<span class="token operator">-</span>converter <span class="token operator">-</span>i <span class="token operator">&lt;</span>path<span class="token operator">&gt;</span><span class="token operator">/</span>frozen_graph<span class="token punctuation">.</span>pb
                    <span class="token operator">-</span>d <span class="token operator">&lt;</span>network_input_name<span class="token operator">&gt;</span> <span class="token operator">&lt;</span>dims<span class="token operator">&gt;</span>
                    <span class="token operator">--</span>out_node <span class="token operator">&lt;</span>network_output_name<span class="token operator">&gt;</span>
                    <span class="token operator">-</span>o <span class="token operator">&lt;</span>optional_output_path<span class="token operator">&gt;</span>
                    <span class="token operator">--</span>allow_unconsumed_nodes  # optional<span class="token punctuation">,</span> but most likely will be need <span class="token keyword">for</span> larger models
                    <span class="token operator">-</span>p <span class="token operator">&lt;</span>optional_package_name<span class="token operator">&gt;</span> # Defaults to <span class="token string">"qti.aisw"</span>
                    <span class="token operator">--</span>input_list input_list<span class="token punctuation">.</span>txt

</code></pre> 
<p>这将使用默认量化器和位宽（8 位用于激活、权重和偏差）来量化网络。</p> 
<p>有关量化、选项和算法的更多详细信息，请参阅量化。</p> 
<p>qnn-模型库-生成器</p> 
<blockquote> 
 <p>笔记<br> 适合想要在 Windows-PC 下或具有 Windows 操作系统的 Qualcomm 设备上执行模型准备工具的开发人员。<br> qnn-model-lib-generator 位于 SDK 中的 /bin/x86_64-windows-msvc 下，供本机 Windows-PC 使用。<br> 对于想要在 Windows 操作系统设备上运行 qnn-model-lib-generator 的开发人员，它位于 /bin/aarch64-windows-msvc 下。<br> qnn-model-lib-generator 将尝试使用您平台上的 CMake 命令来生成库。<br> 请确保已安装编译工具（windows平台编译工具），以确保Windows操作系统中的CMake可行。</p> 
</blockquote> 
<p>qnn -model-lib-generator工具将 QNN 模型源代码编译为特定目标的工件。</p> 
<pre><code class="prism language-cpp">usage<span class="token operator">:</span> qnn<span class="token operator">-</span>model<span class="token operator">-</span>lib<span class="token operator">-</span>generator <span class="token punctuation">[</span><span class="token operator">-</span>h<span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token operator">-</span>c <span class="token operator">&lt;</span>QNN_MODEL<span class="token operator">&gt;</span><span class="token punctuation">.</span>cpp<span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token operator">-</span>b <span class="token operator">&lt;</span>QNN_MODEL<span class="token operator">&gt;</span><span class="token punctuation">.</span>bin<span class="token punctuation">]</span>
       <span class="token punctuation">[</span><span class="token operator">-</span>t LIB_TARGETS <span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token operator">-</span>l LIB_NAME<span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token operator">-</span>o OUTPUT_DIR<span class="token punctuation">]</span>
Script compiles provided Qnn Model artifacts <span class="token keyword">for</span> specified targets<span class="token punctuation">.</span>

Required <span class="token function">argument</span><span class="token punctuation">(</span>s<span class="token punctuation">)</span><span class="token operator">:</span>
 <span class="token operator">-</span>c <span class="token operator">&lt;</span>QNN_MODEL<span class="token operator">&gt;</span><span class="token punctuation">.</span>cpp                    Filepath <span class="token keyword">for</span> the qnn model <span class="token punctuation">.</span>cpp file

optional <span class="token function">argument</span><span class="token punctuation">(</span>s<span class="token punctuation">)</span><span class="token operator">:</span>
 <span class="token operator">-</span>b <span class="token operator">&lt;</span>QNN_MODEL<span class="token operator">&gt;</span><span class="token punctuation">.</span>bin                    Filepath <span class="token keyword">for</span> the qnn model <span class="token punctuation">.</span>bin <span class="token function">file</span>
                                       <span class="token punctuation">(</span>Note<span class="token operator">:</span> <span class="token keyword">if</span> <span class="token operator">not</span> passed<span class="token punctuation">,</span> runtime will fail <span class="token keyword">if</span> <span class="token punctuation">.</span>cpp needs any items from a <span class="token punctuation">.</span>bin file<span class="token punctuation">.</span><span class="token punctuation">)</span>

 <span class="token operator">-</span>t LIB_TARGETS                        Specifies the targets to build the models <span class="token keyword">for</span><span class="token punctuation">.</span> Default<span class="token operator">:</span> aarch64<span class="token operator">-</span>android x86_64<span class="token operator">-</span>linux<span class="token operator">-</span>clang
 <span class="token operator">-</span>l LIB_NAME                           Specifies the name to use <span class="token keyword">for</span> libraries<span class="token punctuation">.</span> Default<span class="token operator">:</span> uses name in <span class="token operator">&lt;</span>model<span class="token punctuation">.</span>bin<span class="token operator">&gt;</span> <span class="token keyword">if</span> provided<span class="token punctuation">,</span>
                                       <span class="token keyword">else</span> generic qnn_model<span class="token punctuation">.</span>so
  <span class="token operator">-</span>o OUTPUT_DIR                         Location <span class="token keyword">for</span> saving output libraries<span class="token punctuation">.</span>

</code></pre> 
<blockquote> 
 <p>笔记<br> 对于Windows用户，请使用python3执行该工具。</p> 
</blockquote> 
<p>qnn-op-包生成器<br> qnn-op-package-generator工具用于使用描述包属性的 XML 配置文件生成 QNN op 包的框架代码。该工具将包创建为包含框架源代码和 makefile 的目录，可以编译这些文件以创建共享库对象。</p> 
<pre><code class="prism language-cpp">usage<span class="token operator">:</span> qnn<span class="token operator">-</span>op<span class="token operator">-</span>package<span class="token operator">-</span>generator <span class="token punctuation">[</span><span class="token operator">-</span>h<span class="token punctuation">]</span> <span class="token operator">--</span>config_path CONFIG_PATH <span class="token punctuation">[</span><span class="token operator">--</span>debug<span class="token punctuation">]</span>
                                <span class="token punctuation">[</span><span class="token operator">--</span>output_path OUTPUT_PATH<span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token operator">-</span>f<span class="token punctuation">]</span>

optional arguments<span class="token operator">:</span>
  <span class="token operator">-</span>h<span class="token punctuation">,</span> <span class="token operator">--</span>help            show <span class="token keyword">this</span> help message <span class="token operator">and</span> exit

required arguments<span class="token operator">:</span>
  <span class="token operator">--</span>config_path CONFIG_PATH<span class="token punctuation">,</span> <span class="token operator">-</span>p CONFIG_PATH
                        The path to a config file that defines a QNN Op
                        <span class="token function">package</span><span class="token punctuation">(</span>s<span class="token punctuation">)</span><span class="token punctuation">.</span>

optional arguments<span class="token operator">:</span>
  <span class="token operator">--</span>debug               Returns debugging information from generating the
                        package
  <span class="token operator">--</span>output_path OUTPUT_PATH<span class="token punctuation">,</span> <span class="token operator">-</span>o OUTPUT_PATH
                        Path where the package should be saved
  <span class="token operator">-</span>f<span class="token punctuation">,</span> <span class="token operator">--</span>force<span class="token operator">-</span>generation
                        This option will <span class="token keyword">delete</span> the entire existing package
                        Note appropriate file permissions must be set to use
                        <span class="token keyword">this</span> option<span class="token punctuation">.</span>
  <span class="token operator">--</span>converter_op_package<span class="token punctuation">,</span> <span class="token operator">-</span>cop
                        Generates Converter Op Package skeleton code needed
                        by the output shape inference <span class="token keyword">for</span> converters

</code></pre> 
<p>qnn-上下文-二进制生成器<br> qnn -context-binary-generator工具用于通过使用特定后端并使用qnn-model-lib-generator创建的模型库来创建上下文二进制文件。</p> 
<pre><code class="prism language-cpp">usage<span class="token operator">:</span> qnn<span class="token operator">-</span>context<span class="token operator">-</span>binary<span class="token operator">-</span>generator <span class="token operator">--</span>model QNN_MODEL<span class="token punctuation">.</span>so <span class="token operator">--</span>backend QNN_BACKEND<span class="token punctuation">.</span>so
                                    <span class="token operator">--</span>binary_file BINARY_FILE_NAME
                                    <span class="token punctuation">[</span><span class="token operator">--</span>model_prefix MODEL_PREFIX<span class="token punctuation">]</span>
                                    <span class="token punctuation">[</span><span class="token operator">--</span>output_dir OUTPUT_DIRECTORY<span class="token punctuation">]</span>
                                    <span class="token punctuation">[</span><span class="token operator">--</span>op_packages ONE_OR_MORE_OP_PACKAGES<span class="token punctuation">]</span>
                                    <span class="token punctuation">[</span><span class="token operator">--</span>config_file CONFIG_FILE<span class="token punctuation">.</span>json<span class="token punctuation">]</span>
                                    <span class="token punctuation">[</span><span class="token operator">--</span>profiling_level PROFILING_LEVEL<span class="token punctuation">]</span>
                                    <span class="token punctuation">[</span><span class="token operator">--</span>verbose<span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token operator">--</span>version<span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token operator">--</span>help<span class="token punctuation">]</span>

REQUIRED ARGUMENTS<span class="token operator">:</span>
<span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span>
  <span class="token operator">--</span>model                         <span class="token operator">&lt;</span>FILE<span class="token operator">&gt;</span>      Path to the <span class="token operator">&lt;</span>qnn_model_name<span class="token punctuation">.</span>so<span class="token operator">&gt;</span> file containing a QNN network<span class="token punctuation">.</span>
                                              To create a context binary with multiple graphs<span class="token punctuation">,</span> use
                                              comma<span class="token operator">-</span>separated list of model<span class="token punctuation">.</span>so files<span class="token punctuation">.</span> The syntax is
                                              <span class="token operator">&lt;</span>qnn_model_name_1<span class="token punctuation">.</span>so<span class="token operator">&gt;</span><span class="token punctuation">,</span><span class="token operator">&lt;</span>qnn_model_name_2<span class="token punctuation">.</span>so<span class="token operator">&gt;</span><span class="token punctuation">.</span>

  <span class="token operator">--</span>backend                       <span class="token operator">&lt;</span>FILE<span class="token operator">&gt;</span>      Path to a QNN backend <span class="token punctuation">.</span>so library to create the context binary<span class="token punctuation">.</span>

  <span class="token operator">--</span>binary_file                   <span class="token operator">&lt;</span>VAL<span class="token operator">&gt;</span>       Name of the binary file to save the context binary to<span class="token punctuation">.</span>
                                              Saved in the same path as <span class="token operator">--</span>output_dir option with <span class="token punctuation">.</span>bin
                                              as the binary file extension<span class="token punctuation">.</span> If <span class="token operator">not</span> provided<span class="token punctuation">,</span> no backend binary
                                              is created<span class="token punctuation">.</span>


OPTIONAL ARGUMENTS<span class="token operator">:</span>
<span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span>
  <span class="token operator">--</span>model_prefix                              Function prefix to use when loading <span class="token operator">&lt;</span>qnn_model_name<span class="token punctuation">.</span>so<span class="token operator">&gt;</span> file
                                              containing a QNN network<span class="token punctuation">.</span> Default<span class="token operator">:</span> QnnModel<span class="token punctuation">.</span>

  <span class="token operator">--</span>output_dir                    <span class="token operator">&lt;</span>DIR<span class="token operator">&gt;</span>       The directory to save output to<span class="token punctuation">.</span> Defaults to <span class="token punctuation">.</span><span class="token operator">/</span>output<span class="token punctuation">.</span>

  <span class="token operator">--</span>op_packages                   <span class="token operator">&lt;</span>VAL<span class="token operator">&gt;</span>       Provide a comma separated list of op packages
                                              <span class="token operator">and</span> interface providers to <span class="token keyword">register</span><span class="token punctuation">.</span> The syntax is<span class="token operator">:</span>
                                              op_package_path<span class="token operator">:</span>interface_provider<span class="token punctuation">[</span><span class="token punctuation">,</span>op_package_path<span class="token operator">:</span>interface_provider<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span>

  <span class="token operator">--</span>profiling_level               <span class="token operator">&lt;</span>VAL<span class="token operator">&gt;</span>       Enable profiling<span class="token punctuation">.</span> Valid Values<span class="token operator">:</span>
                                              <span class="token number">1.</span> basic<span class="token operator">:</span>    captures execution <span class="token operator">and</span> init time<span class="token punctuation">.</span>
                                              <span class="token number">2.</span> detailed<span class="token operator">:</span> in addition to basic<span class="token punctuation">,</span> captures per Op timing
                                                  <span class="token keyword">for</span> execution<span class="token punctuation">.</span>
                                              <span class="token number">3.</span> backend<span class="token operator">:</span>  backend<span class="token operator">-</span>specific profiling level specified
                                                  in the backend extension related JSON config file<span class="token punctuation">.</span>

  <span class="token operator">--</span>profiling_option              <span class="token operator">&lt;</span>VAL<span class="token operator">&gt;</span>       Set profiling options<span class="token operator">:</span>
                                              <span class="token number">1.</span> optrace<span class="token operator">:</span>    Generates an optrace of the run<span class="token punctuation">.</span>

  <span class="token operator">--</span>config_file                   <span class="token operator">&lt;</span>FILE<span class="token operator">&gt;</span>      Path to a JSON config file<span class="token punctuation">.</span> The config file currently
                                              supports options related to backend extensions <span class="token operator">and</span>
                                              context priority<span class="token punctuation">.</span> Please refer to SDK documentation
                                              <span class="token keyword">for</span> more details<span class="token punctuation">.</span>

  <span class="token operator">--</span>enable_intermediate_outputs               Enable all intermediate nodes to be output along with
                                              <span class="token keyword">default</span> outputs in the saved context<span class="token punctuation">.</span>
                                              Note that options <span class="token operator">--</span>enable_intermediate_outputs <span class="token operator">and</span> <span class="token operator">--</span>set_output_tensors
                                              are mutually exclusive<span class="token punctuation">.</span> Only one of the options can be specified at a time<span class="token punctuation">.</span>

  <span class="token operator">--</span>set_output_tensors            <span class="token operator">&lt;</span>VAL<span class="token operator">&gt;</span>       Provide a comma<span class="token operator">-</span>separated list of intermediate output tensor names<span class="token punctuation">,</span> <span class="token keyword">for</span> which the outputs
                                              will be written in addition to <span class="token keyword">final</span> graph output tensors<span class="token punctuation">.</span>
                                              Note that options <span class="token operator">--</span>enable_intermediate_outputs <span class="token operator">and</span> <span class="token operator">--</span>set_output_tensors
                                              are mutually exclusive<span class="token punctuation">.</span> Only one of the options can be specified at a time<span class="token punctuation">.</span>
                                              The syntax is<span class="token operator">:</span> graphName0<span class="token operator">:</span>tensorName0<span class="token punctuation">,</span>tensorName1<span class="token punctuation">;</span>graphName1<span class="token operator">:</span>tensorName0<span class="token punctuation">,</span>tensorName1

  <span class="token operator">--</span>backend_binary                <span class="token operator">&lt;</span>VAL<span class="token operator">&gt;</span>       Name of the file to save a backend<span class="token operator">-</span>specific context
                                              binary to<span class="token punctuation">.</span>
                                              Saved in the same path as <span class="token operator">--</span>output_dir option with <span class="token punctuation">.</span>bin
                                              as the binary file extension<span class="token punctuation">.</span>

  <span class="token operator">--</span>log_level                                 Specifies max logging level to be set<span class="token punctuation">.</span> Valid settings<span class="token operator">:</span>
                                              <span class="token string">"error"</span><span class="token punctuation">,</span> <span class="token string">"warn"</span><span class="token punctuation">,</span> <span class="token string">"info"</span> <span class="token operator">and</span> <span class="token string">"verbose"</span>

  <span class="token operator">--</span>input_output_tensor_mem_type  <span class="token operator">&lt;</span>VAL<span class="token operator">&gt;</span>       Specifies mem type to be used <span class="token keyword">for</span> input <span class="token operator">and</span> output tensors during graph creation<span class="token punctuation">.</span>
                                              Valid settings<span class="token operator">:</span><span class="token string">"raw"</span> <span class="token operator">and</span> <span class="token string">"memhandle"</span>

  <span class="token operator">--</span>version                                   Print the QNN SDK version<span class="token punctuation">.</span>

  <span class="token operator">--</span>help                                      Show <span class="token keyword">this</span> help message<span class="token punctuation">.</span>

</code></pre> 
<p>有关更多详细信息和选项，请参阅qnn-net-run部分。–op_packages–config_file</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/982cc344b994937413064abeecf34021/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Android13关于获取外部存储文件的相关问题及解决方案记录</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/3a28b281d65fffc87f2b19a81f15fe80/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">python如何做图形化界面,python的图形界面gui编程</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程学习者.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>