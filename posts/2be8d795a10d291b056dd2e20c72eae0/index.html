<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>AIå¤§æ¨¡å‹æ¢ç´¢ä¹‹è·¯-è®­ç»ƒç¯‡22ï¼š ChatGLM3å¾®è°ƒå®æˆ˜-ä»åŸç†åˆ°åº”ç”¨çš„LoRAæŠ€æœ¯å…¨è§£ - ç¼–ç¨‹å­¦ä¹ è€…</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcxuexizhe.github.io/posts/2be8d795a10d291b056dd2e20c72eae0/">
  <meta property="og:site_name" content="ç¼–ç¨‹å­¦ä¹ è€…">
  <meta property="og:title" content="AIå¤§æ¨¡å‹æ¢ç´¢ä¹‹è·¯-è®­ç»ƒç¯‡22ï¼š ChatGLM3å¾®è°ƒå®æˆ˜-ä»åŸç†åˆ°åº”ç”¨çš„LoRAæŠ€æœ¯å…¨è§£">
  <meta property="og:description" content="ç³»åˆ—ç¯‡ç« ğŸ’¥ AIå¤§æ¨¡å‹æ¢ç´¢ä¹‹è·¯-è®­ç»ƒç¯‡1ï¼šå¤§è¯­è¨€æ¨¡å‹å¾®è°ƒåŸºç¡€è®¤çŸ¥
AIå¤§æ¨¡å‹æ¢ç´¢ä¹‹è·¯-è®­ç»ƒç¯‡2ï¼šå¤§è¯­è¨€æ¨¡å‹é¢„è®­ç»ƒåŸºç¡€è®¤çŸ¥
AIå¤§æ¨¡å‹æ¢ç´¢ä¹‹è·¯-è®­ç»ƒç¯‡3ï¼šå¤§è¯­è¨€æ¨¡å‹å…¨æ™¯è§£è¯»
AIå¤§æ¨¡å‹æ¢ç´¢ä¹‹è·¯-è®­ç»ƒç¯‡4ï¼šå¤§è¯­è¨€æ¨¡å‹è®­ç»ƒæ•°æ®é›†æ¦‚è§ˆ
AIå¤§æ¨¡å‹æ¢ç´¢ä¹‹è·¯-è®­ç»ƒç¯‡5ï¼šå¤§è¯­è¨€æ¨¡å‹é¢„è®­ç»ƒæ•°æ®å‡†å¤‡-è¯å…ƒåŒ–
AIå¤§æ¨¡å‹æ¢ç´¢ä¹‹è·¯-è®­ç»ƒç¯‡6ï¼šå¤§è¯­è¨€æ¨¡å‹é¢„è®­ç»ƒæ•°æ®å‡†å¤‡-é¢„å¤„ç†
AIå¤§æ¨¡å‹æ¢ç´¢ä¹‹è·¯-è®­ç»ƒç¯‡7ï¼šå¤§è¯­è¨€æ¨¡å‹Transformeråº“ä¹‹HuggingFaceä»‹ç»
AIå¤§æ¨¡å‹æ¢ç´¢ä¹‹è·¯-è®­ç»ƒç¯‡8ï¼šå¤§è¯­è¨€æ¨¡å‹Transformeråº“-é¢„è®­ç»ƒæµç¨‹ç¼–ç ä½“éªŒ
AIå¤§æ¨¡å‹æ¢ç´¢ä¹‹è·¯-è®­ç»ƒç¯‡9ï¼šå¤§è¯­è¨€æ¨¡å‹Transformeråº“-Pipelineç»„ä»¶å®è·µ
AIå¤§æ¨¡å‹æ¢ç´¢ä¹‹è·¯-è®­ç»ƒç¯‡10ï¼šå¤§è¯­è¨€æ¨¡å‹Transformeråº“-Tokenizerç»„ä»¶å®è·µ
AIå¤§æ¨¡å‹æ¢ç´¢ä¹‹è·¯-è®­ç»ƒç¯‡11ï¼šå¤§è¯­è¨€æ¨¡å‹Transformeråº“-Modelç»„ä»¶å®è·µ
AIå¤§æ¨¡å‹æ¢ç´¢ä¹‹è·¯-è®­ç»ƒç¯‡12ï¼šè¯­è¨€æ¨¡å‹Transformeråº“-Datasetsç»„ä»¶å®è·µ
AIå¤§æ¨¡å‹æ¢ç´¢ä¹‹è·¯-è®­ç»ƒç¯‡13ï¼šå¤§è¯­è¨€æ¨¡å‹Transformeråº“-Evaluateç»„ä»¶å®è·µ
AIå¤§æ¨¡å‹æ¢ç´¢ä¹‹è·¯-è®­ç»ƒç¯‡14ï¼šå¤§è¯­è¨€æ¨¡å‹Transformeråº“-Trainerç»„ä»¶å®è·µ
AIå¤§æ¨¡å‹æ¢ç´¢ä¹‹è·¯-è®­ç»ƒç¯‡15ï¼šå¤§è¯­è¨€æ¨¡å‹é¢„è®­ç»ƒä¹‹å…¨é‡å‚æ•°å¾®è°ƒ
AIå¤§æ¨¡å‹æ¢ç´¢ä¹‹è·¯-è®­ç»ƒç¯‡16ï¼šå¤§è¯­è¨€æ¨¡å‹é¢„è®­ç»ƒ-å¾®è°ƒæŠ€æœ¯ä¹‹LoRA
AIå¤§æ¨¡å‹æ¢ç´¢ä¹‹è·¯-è®­ç»ƒç¯‡17ï¼šå¤§è¯­è¨€æ¨¡å‹é¢„è®­ç»ƒ-å¾®è°ƒæŠ€æœ¯ä¹‹QLoRA
AIå¤§æ¨¡å‹æ¢ç´¢ä¹‹è·¯-è®­ç»ƒç¯‡18ï¼šå¤§è¯­è¨€æ¨¡å‹é¢„è®­ç»ƒ-å¾®è°ƒæŠ€æœ¯ä¹‹Prompt Tuning
AIå¤§æ¨¡å‹æ¢ç´¢ä¹‹è·¯-è®­ç»ƒç¯‡19ï¼šå¤§è¯­è¨€æ¨¡å‹é¢„è®­ç»ƒ-å¾®è°ƒæŠ€æœ¯ä¹‹Prefix Tuning
AIå¤§æ¨¡å‹æ¢ç´¢ä¹‹è·¯-è®­ç»ƒç¯‡20ï¼šå¤§è¯­è¨€æ¨¡å‹é¢„è®­ç»ƒ-å¸¸è§å¾®è°ƒæŠ€æœ¯å¯¹æ¯”
AIå¤§æ¨¡å‹æ¢ç´¢ä¹‹è·¯-è®­ç»ƒç¯‡21ï¼šLlama2å¾®è°ƒå®æˆ˜-LoRAæŠ€æœ¯å¾®è°ƒæ­¥éª¤è¯¦è§£
ç›®å½• ç³»åˆ—ç¯‡ç« ğŸ’¥å‰è¨€ä¸€ã€ç»å…¸çš„Transformeræ¶æ„äºŒã€ChatGLM3æ¶æ„è®¾è®¡1ã€GLM åŠ¨æœº2ã€GLMçš„æ ¸å¿ƒæœºåˆ¶3ã€é¢„è®­ç»ƒä»»åŠ¡ç±»å‹1ï¼‰æ©ç è¯­è¨€æ¨¡å‹ï¼Œè‡ªç¼–ç æ¨¡å‹2ï¼‰å› æœæ¨¡å‹ï¼Œè‡ªå›å½’æ¨¡å‹3ï¼‰åºåˆ—åˆ°åºåˆ—æ¨¡å‹ 4ã€promptæ ¼å¼ ä¸‰ã€ChatGLM3å¾®è°ƒå‡†å¤‡1ã€æ•°æ®å‡†å¤‡2ã€æ¨¡å‹é€‰æ‹© å››ã€åŸºäºLoRAå¾®è°ƒChatGLM3æ­¥éª¤1 å¯¼å…¥ç›¸å…³åŒ…æ­¥éª¤2 åŠ è½½æ•°æ®é›†æ­¥éª¤3 æ•°æ®é›†é¢„å¤„ç†1ï¼‰è·å–åˆ†è¯å™¨2ï¼‰å®šä¹‰æ•°æ®å¤„ç†å‡½æ•°3ï¼‰å¯¹æ•°æ®è¿›è¡Œé¢„å¤„ç†4ï¼‰è§£ç æ£€æŸ¥input_idsçš„æ ¼å¼5ï¼‰æ£€æŸ¥labelsæ•°æ®æ ¼å¼ æ­¥éª¤4 åˆ›å»ºæ¨¡å‹1ã€åˆ›å»ºæ¨¡å‹å®ä¾‹1ï¼‰åˆ›å»ºæ¨¡å‹2ï¼‰ç²¾åº¦æŸ¥çœ‹ç¡®è®¤3ï¼‰æŸ¥çœ‹æ¨¡å‹å‚æ•° 2ã€PEFT æ­¥éª¤1 é…ç½®æ–‡ä»¶3ã€PEFT æ­¥éª¤2 åˆ›å»ºæ¨¡å‹1ï¼‰åˆ›å»ºå¾®è°ƒæ¨¡å‹2ï¼‰æŸ¥çœ‹LoRAå±‚æ·»åŠ æƒ…å†µ3ï¼‰æŸ¥çœ‹æ¨¡å‹ä¸­å¯è®­ç»ƒå‚æ•°çš„æ•°é‡ æ­¥éª¤5 é…ç½®è®­ç»ƒå‚æ•°æ­¥éª¤6 åˆ›å»ºè®­ç»ƒå™¨æ­¥éª¤7 æ¨¡å‹è®­ç»ƒæ­¥éª¤8 æ¨¡å‹æ¨ç† æ€»ç»“ å‰è¨€ åœ¨è‡ªç„¶è¯­è¨€å¤„ç†çš„æµªæ½®ä¸­ï¼ŒTransformeræ¶æ„ä»¥å…¶ç‹¬ç‰¹çš„è®¾è®¡å’Œå“è¶Šæ€§èƒ½ï¼Œæˆä¸ºäº†å¤§è¯­è¨€æ¨¡å‹çš„åŸºçŸ³ã€‚ChatGLM3ï¼Œä½œä¸ºå…¶ä¸­çš„ä¸€å‘˜ï¼Œé€šè¿‡å¾®è°ƒåœ¨ç‰¹å®šä»»åŠ¡ä¸Šå±•ç°äº†å…¶å¼ºå¤§çš„é€‚åº”æ€§å’Œçµæ´»æ€§ã€‚æœ¬æ–‡å°†æ·±å…¥æ¢è®¨ChatGLM3çš„æ¶æ„è®¾è®¡ï¼Œå¾®è°ƒç­–ç•¥ï¼Œå¹¶æä¾›å®æˆ˜æ¡ˆä¾‹ï¼Œä»¥æœŸä¸ºå¼€å‘è€…æä¾›å®è´µçš„å‚è€ƒã€‚
ä¸€ã€ç»å…¸çš„Transformeræ¶æ„ Transformeræ¶æ„è‡ªé—®ä¸–ä»¥æ¥ï¼Œå·²æˆä¸ºNLPé¢†åŸŸçš„ä¸€ä¸ªé‡Œç¨‹ç¢‘ã€‚å…¶æ ¸å¿ƒæ€æƒ³æ˜¯åˆ©ç”¨è‡ªæ³¨æ„åŠ›æœºåˆ¶ï¼ˆSelf-Attentionï¼‰æ¥æ•æ‰æ–‡æœ¬ä¸­çš„é•¿è·ç¦»ä¾èµ–å…³ç³»ï¼Œæ— éœ€åƒå¾ªç¯ç¥ç»ç½‘ç»œï¼ˆRNNï¼‰é‚£æ ·é€æ­¥å¤„ç†åºåˆ—ã€‚å„å¤§è¯­è¨€æ¨¡å‹è™½åŸºäºTransformeræ¼”å˜ï¼›ä½†åœ¨ç»“æ„ã€ç¼–ç æ–¹å¼ã€æ¿€æ´»å‡½æ•°ã€layer Normæ–¹æ³•ä¸Šå„æœ‰ä¸åŒï¼›å¦å¤–æ©ç çš„è®¾è®¡ä¸åŒï¼Œè®­ç»ƒæ•°æ®å’Œç›®æ ‡çš„å¤šæ ·æ€§ç­‰ï¼Œéƒ½èµ‹äºˆäº†æ¨¡å‹ä¸åŒçš„ç‰¹æ€§å’Œåº”ç”¨åœºæ™¯ã€‚
äºŒã€ChatGLM3æ¶æ„è®¾è®¡ 1ã€GLM åŠ¨æœº å¤§å‹é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹çš„å‘å±•å¯å½’çº³ä¸ºä¸‰ä¸ªä¸»è¦æ–¹å‘ï¼š
1ï¼‰è‡ªç¼–ç æ¨¡å‹ (Auto Encoding)ï¼š BERTï¼ŒROBERTaï¼ŒDeBERTaï¼ŒALBERTç­‰ï¼›é‡‡ç”¨åŒå‘æ³¨æ„åŠ›æœºåˆ¶ï¼Œæ“…é•¿å¤„ç†è‡ªç„¶è¯­è¨€ç†è§£ä»»åŠ¡ï¼Œå¦‚æƒ…æ„Ÿåˆ†ç±»ã€æŠ½å–å¼é—®ç­”å’Œè‡ªç„¶è¯­è¨€æ¨ç†ç­‰ã€‚
2ï¼‰è‡ªå›å½’æ¨¡å‹ (Auto Regressive) ï¼šGPTç³»åˆ—ï¼ŒLlamaï¼Œç™¾å·ï¼Œç­‰ï¼›é€šè¿‡å•å‘æ³¨æ„åŠ›æœºåˆ¶ï¼Œä¸“æ³¨äºç”Ÿæˆä»»åŠ¡ï¼ŒåŒ…æ‹¬è¯­è¨€å»ºæ¨¡å’Œæ–‡æœ¬ç”Ÿæˆã€‚
3ï¼‰ç¼–ç å™¨-è§£ç å™¨æ¨¡å‹ (Encoder-Decoder) : T5ï¼ŒBARTï¼ŒMASSï¼ŒPALMç­‰ï¼›ç»“åˆäº†åŒå‘å’Œå•å‘æ³¨æ„åŠ›ï¼ˆencoderçš„attentionæ˜¯åŒå‘çš„ï¼Œdecoderçš„attentionæ˜¯å•å‘çš„ï¼‰ã€‚é€‚ç”¨äºæ¡ä»¶ç”Ÿæˆ(seq2seq)ä»»åŠ¡ï¼Œæ¯”å¦‚ï¼šæ–‡æœ¬æ‘˜è¦ï¼Œæœºå™¨ç¿»è¯‘ç­‰ã€‚
ç„¶è€Œï¼Œç°æœ‰æ¨¡å‹åœ¨å¤šä»»åŠ¡æ€§èƒ½ä¸Šå­˜åœ¨å±€é™ã€‚GLMï¼ˆGeneral Language Modelï¼‰æ—¨åœ¨èåˆä¸‰è€…ä¼˜åŠ¿ï¼Œå®ç°åœ¨è‡ªç„¶è¯­è¨€ç†è§£ã€ç”Ÿæˆå’Œæ¡ä»¶ç”Ÿæˆä»»åŠ¡ä¸Šçš„å…¨é¢ä¼˜åŒ–">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-05-13T11:17:13+08:00">
    <meta property="article:modified_time" content="2024-05-13T11:17:13+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="ç¼–ç¨‹å­¦ä¹ è€…" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">ç¼–ç¨‹å­¦ä¹ è€…</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">AIå¤§æ¨¡å‹æ¢ç´¢ä¹‹è·¯-è®­ç»ƒç¯‡22ï¼š ChatGLM3å¾®è°ƒå®æˆ˜-ä»åŸç†åˆ°åº”ç”¨çš„LoRAæŠ€æœ¯å…¨è§£</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-tomorrow-night">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="_2"></a>ç³»åˆ—ç¯‡ç« ğŸ’¥</h2> 
<p><a href="https://xundaomalu.blog.csdn.net/article/details/138107946" rel="nofollow">AIå¤§æ¨¡å‹æ¢ç´¢ä¹‹è·¯-è®­ç»ƒç¯‡1ï¼šå¤§è¯­è¨€æ¨¡å‹å¾®è°ƒåŸºç¡€è®¤çŸ¥</a><br> <a href="https://xundaomalu.blog.csdn.net/article/details/138143923" rel="nofollow">AIå¤§æ¨¡å‹æ¢ç´¢ä¹‹è·¯-è®­ç»ƒç¯‡2ï¼šå¤§è¯­è¨€æ¨¡å‹é¢„è®­ç»ƒåŸºç¡€è®¤çŸ¥</a><br> <a href="https://xundaomalu.blog.csdn.net/article/details/138161057" rel="nofollow">AIå¤§æ¨¡å‹æ¢ç´¢ä¹‹è·¯-è®­ç»ƒç¯‡3ï¼šå¤§è¯­è¨€æ¨¡å‹å…¨æ™¯è§£è¯»</a><br> <a href="https://xundaomalu.blog.csdn.net/article/details/138205204" rel="nofollow">AIå¤§æ¨¡å‹æ¢ç´¢ä¹‹è·¯-è®­ç»ƒç¯‡4ï¼šå¤§è¯­è¨€æ¨¡å‹è®­ç»ƒæ•°æ®é›†æ¦‚è§ˆ</a><br> <a href="https://xundaomalu.blog.csdn.net/article/details/138225299" rel="nofollow">AIå¤§æ¨¡å‹æ¢ç´¢ä¹‹è·¯-è®­ç»ƒç¯‡5ï¼šå¤§è¯­è¨€æ¨¡å‹é¢„è®­ç»ƒæ•°æ®å‡†å¤‡-è¯å…ƒåŒ–</a><br> <a href="https://xundaomalu.blog.csdn.net/article/details/138267915" rel="nofollow">AIå¤§æ¨¡å‹æ¢ç´¢ä¹‹è·¯-è®­ç»ƒç¯‡6ï¼šå¤§è¯­è¨€æ¨¡å‹é¢„è®­ç»ƒæ•°æ®å‡†å¤‡-é¢„å¤„ç†</a><br> <a href="https://xundaomalu.blog.csdn.net/article/details/138294519" rel="nofollow">AIå¤§æ¨¡å‹æ¢ç´¢ä¹‹è·¯-è®­ç»ƒç¯‡7ï¼šå¤§è¯­è¨€æ¨¡å‹Transformeråº“ä¹‹HuggingFaceä»‹ç»</a><br> <a href="https://xundaomalu.blog.csdn.net/article/details/138348834" rel="nofollow">AIå¤§æ¨¡å‹æ¢ç´¢ä¹‹è·¯-è®­ç»ƒç¯‡8ï¼šå¤§è¯­è¨€æ¨¡å‹Transformeråº“-é¢„è®­ç»ƒæµç¨‹ç¼–ç ä½“éªŒ</a><br> <a href="https://blog.csdn.net/xiaobing259/article/details/138373677">AIå¤§æ¨¡å‹æ¢ç´¢ä¹‹è·¯-è®­ç»ƒç¯‡9ï¼šå¤§è¯­è¨€æ¨¡å‹Transformeråº“-Pipelineç»„ä»¶å®è·µ</a><br> <a href="https://xundaomalu.blog.csdn.net/article/details/138391592" rel="nofollow">AIå¤§æ¨¡å‹æ¢ç´¢ä¹‹è·¯-è®­ç»ƒç¯‡10ï¼šå¤§è¯­è¨€æ¨¡å‹Transformeråº“-Tokenizerç»„ä»¶å®è·µ</a><br> <a href="https://blog.csdn.net/xiaobing259/article/details/138424867">AIå¤§æ¨¡å‹æ¢ç´¢ä¹‹è·¯-è®­ç»ƒç¯‡11ï¼šå¤§è¯­è¨€æ¨¡å‹Transformeråº“-Modelç»„ä»¶å®è·µ</a><br> <a href="https://xundaomalu.blog.csdn.net/article/details/138426216" rel="nofollow">AIå¤§æ¨¡å‹æ¢ç´¢ä¹‹è·¯-è®­ç»ƒç¯‡12ï¼šè¯­è¨€æ¨¡å‹Transformeråº“-Datasetsç»„ä»¶å®è·µ</a><br> <a href="https://xundaomalu.blog.csdn.net/article/details/138448172" rel="nofollow">AIå¤§æ¨¡å‹æ¢ç´¢ä¹‹è·¯-è®­ç»ƒç¯‡13ï¼šå¤§è¯­è¨€æ¨¡å‹Transformeråº“-Evaluateç»„ä»¶å®è·µ</a><br> <a href="https://xundaomalu.blog.csdn.net/article/details/138448511" rel="nofollow">AIå¤§æ¨¡å‹æ¢ç´¢ä¹‹è·¯-è®­ç»ƒç¯‡14ï¼šå¤§è¯­è¨€æ¨¡å‹Transformeråº“-Trainerç»„ä»¶å®è·µ</a><br> <a href="https://xundaomalu.blog.csdn.net/article/details/138472105" rel="nofollow">AIå¤§æ¨¡å‹æ¢ç´¢ä¹‹è·¯-è®­ç»ƒç¯‡15ï¼šå¤§è¯­è¨€æ¨¡å‹é¢„è®­ç»ƒä¹‹å…¨é‡å‚æ•°å¾®è°ƒ</a><br> <a href="https://xundaomalu.blog.csdn.net/article/details/138518728" rel="nofollow">AIå¤§æ¨¡å‹æ¢ç´¢ä¹‹è·¯-è®­ç»ƒç¯‡16ï¼šå¤§è¯­è¨€æ¨¡å‹é¢„è®­ç»ƒ-å¾®è°ƒæŠ€æœ¯ä¹‹LoRA</a><br> <a href="https://xundaomalu.blog.csdn.net/article/details/138555530" rel="nofollow">AIå¤§æ¨¡å‹æ¢ç´¢ä¹‹è·¯-è®­ç»ƒç¯‡17ï¼šå¤§è¯­è¨€æ¨¡å‹é¢„è®­ç»ƒ-å¾®è°ƒæŠ€æœ¯ä¹‹QLoRA</a><br> <a href="https://xundaomalu.blog.csdn.net/article/details/138595171" rel="nofollow">AIå¤§æ¨¡å‹æ¢ç´¢ä¹‹è·¯-è®­ç»ƒç¯‡18ï¼šå¤§è¯­è¨€æ¨¡å‹é¢„è®­ç»ƒ-å¾®è°ƒæŠ€æœ¯ä¹‹Prompt Tuning</a><br> <a href="https://xundaomalu.blog.csdn.net/article/details/138631718" rel="nofollow">AIå¤§æ¨¡å‹æ¢ç´¢ä¹‹è·¯-è®­ç»ƒç¯‡19ï¼šå¤§è¯­è¨€æ¨¡å‹é¢„è®­ç»ƒ-å¾®è°ƒæŠ€æœ¯ä¹‹Prefix Tuning</a><br> <a href="https://xundaomalu.blog.csdn.net/article/details/138604711" rel="nofollow">AIå¤§æ¨¡å‹æ¢ç´¢ä¹‹è·¯-è®­ç»ƒç¯‡20ï¼šå¤§è¯­è¨€æ¨¡å‹é¢„è®­ç»ƒ-å¸¸è§å¾®è°ƒæŠ€æœ¯å¯¹æ¯”</a><br> <a href="https://xundaomalu.blog.csdn.net/article/details/138763708" rel="nofollow">AIå¤§æ¨¡å‹æ¢ç´¢ä¹‹è·¯-è®­ç»ƒç¯‡21ï¼šLlama2å¾®è°ƒå®æˆ˜-LoRAæŠ€æœ¯å¾®è°ƒæ­¥éª¤è¯¦è§£</a></p> 
<hr> 
<p></p> 
<div class="toc"> 
 <h4>ç›®å½•</h4> 
 <ul><li><a href="#_2" rel="nofollow">ç³»åˆ—ç¯‡ç« ğŸ’¥</a></li><li><a href="#_30" rel="nofollow">å‰è¨€</a></li><li><a href="#Transformer_32" rel="nofollow">ä¸€ã€ç»å…¸çš„Transformeræ¶æ„</a></li><li><a href="#ChatGLM3_38" rel="nofollow">äºŒã€ChatGLM3æ¶æ„è®¾è®¡</a></li><li><ul><li><a href="#1GLM__39" rel="nofollow">1ã€GLM åŠ¨æœº</a></li><li><a href="#2GLM_47" rel="nofollow">2ã€GLMçš„æ ¸å¿ƒæœºåˆ¶</a></li><li><a href="#3_54" rel="nofollow">3ã€é¢„è®­ç»ƒä»»åŠ¡ç±»å‹</a></li><li><ul><li><a href="#1_55" rel="nofollow">1ï¼‰æ©ç è¯­è¨€æ¨¡å‹ï¼Œè‡ªç¼–ç æ¨¡å‹</a></li><li><a href="#2_59" rel="nofollow">2ï¼‰å› æœæ¨¡å‹ï¼Œè‡ªå›å½’æ¨¡å‹</a></li><li><a href="#3_64" rel="nofollow">3ï¼‰åºåˆ—åˆ°åºåˆ—æ¨¡å‹</a></li></ul> 
   </li><li><a href="#4prompt_72" rel="nofollow">4ã€promptæ ¼å¼</a></li></ul> 
  </li><li><a href="#ChatGLM3_82" rel="nofollow">ä¸‰ã€ChatGLM3å¾®è°ƒå‡†å¤‡</a></li><li><ul><li><a href="#1_83" rel="nofollow">1ã€æ•°æ®å‡†å¤‡</a></li><li><a href="#2_86" rel="nofollow">2ã€æ¨¡å‹é€‰æ‹©</a></li></ul> 
  </li><li><a href="#LoRAChatGLM3_92" rel="nofollow">å››ã€åŸºäºLoRAå¾®è°ƒChatGLM3</a></li><li><ul><li><a href="#1__93" rel="nofollow">æ­¥éª¤1 å¯¼å…¥ç›¸å…³åŒ…</a></li><li><a href="#2__101" rel="nofollow">æ­¥éª¤2 åŠ è½½æ•°æ®é›†</a></li><li><a href="#3__129" rel="nofollow">æ­¥éª¤3 æ•°æ®é›†é¢„å¤„ç†</a></li><li><ul><li><a href="#1_145" rel="nofollow">1ï¼‰è·å–åˆ†è¯å™¨</a></li><li><a href="#2_159" rel="nofollow">2ï¼‰å®šä¹‰æ•°æ®å¤„ç†å‡½æ•°</a></li><li><a href="#3_183" rel="nofollow">3ï¼‰å¯¹æ•°æ®è¿›è¡Œé¢„å¤„ç†</a></li><li><a href="#4input_ids_200" rel="nofollow">4ï¼‰è§£ç æ£€æŸ¥input_idsçš„æ ¼å¼</a></li><li><a href="#5labels_212" rel="nofollow">5ï¼‰æ£€æŸ¥labelsæ•°æ®æ ¼å¼</a></li></ul> 
   </li><li><a href="#4__224" rel="nofollow">æ­¥éª¤4 åˆ›å»ºæ¨¡å‹</a></li><li><ul><li><a href="#1_226" rel="nofollow">1ã€åˆ›å»ºæ¨¡å‹å®ä¾‹</a></li><li><ul><li><a href="#1_227" rel="nofollow">1ï¼‰åˆ›å»ºæ¨¡å‹</a></li><li><a href="#2_236" rel="nofollow">2ï¼‰ç²¾åº¦æŸ¥çœ‹ç¡®è®¤</a></li><li><a href="#3_248" rel="nofollow">3ï¼‰æŸ¥çœ‹æ¨¡å‹å‚æ•°</a></li></ul> 
    </li><li><a href="#2PEFT_1__462" rel="nofollow">2ã€PEFT æ­¥éª¤1 é…ç½®æ–‡ä»¶</a></li><li><a href="#3PEFT_2__479" rel="nofollow">3ã€PEFT æ­¥éª¤2 åˆ›å»ºæ¨¡å‹</a></li><li><ul><li><a href="#1_481" rel="nofollow">1ï¼‰åˆ›å»ºå¾®è°ƒæ¨¡å‹</a></li><li><a href="#2LoRA_494" rel="nofollow">2ï¼‰æŸ¥çœ‹LoRAå±‚æ·»åŠ æƒ…å†µ</a></li><li><a href="#3_503" rel="nofollow">3ï¼‰æŸ¥çœ‹æ¨¡å‹ä¸­å¯è®­ç»ƒå‚æ•°çš„æ•°é‡</a></li></ul> 
   </li></ul> 
   </li><li><a href="#5__513" rel="nofollow">æ­¥éª¤5 é…ç½®è®­ç»ƒå‚æ•°</a></li><li><a href="#6__530" rel="nofollow">æ­¥éª¤6 åˆ›å»ºè®­ç»ƒå™¨</a></li><li><a href="#7__543" rel="nofollow">æ­¥éª¤7 æ¨¡å‹è®­ç»ƒ</a></li><li><a href="#8__550" rel="nofollow">æ­¥éª¤8 æ¨¡å‹æ¨ç†</a></li></ul> 
  </li><li><a href="#_577" rel="nofollow">æ€»ç»“</a></li></ul> 
</div> 
<p></p> 
<hr> 
<h2><a id="_30"></a>å‰è¨€</h2> 
<p>åœ¨è‡ªç„¶è¯­è¨€å¤„ç†çš„æµªæ½®ä¸­ï¼ŒTransformeræ¶æ„ä»¥å…¶ç‹¬ç‰¹çš„è®¾è®¡å’Œå“è¶Šæ€§èƒ½ï¼Œæˆä¸ºäº†å¤§è¯­è¨€æ¨¡å‹çš„åŸºçŸ³ã€‚ChatGLM3ï¼Œä½œä¸ºå…¶ä¸­çš„ä¸€å‘˜ï¼Œé€šè¿‡å¾®è°ƒåœ¨ç‰¹å®šä»»åŠ¡ä¸Šå±•ç°äº†å…¶å¼ºå¤§çš„é€‚åº”æ€§å’Œçµæ´»æ€§ã€‚æœ¬æ–‡å°†æ·±å…¥æ¢è®¨ChatGLM3çš„æ¶æ„è®¾è®¡ï¼Œå¾®è°ƒç­–ç•¥ï¼Œå¹¶æä¾›å®æˆ˜æ¡ˆä¾‹ï¼Œä»¥æœŸä¸ºå¼€å‘è€…æä¾›å®è´µçš„å‚è€ƒã€‚</p> 
<h2><a id="Transformer_32"></a>ä¸€ã€ç»å…¸çš„Transformeræ¶æ„</h2> 
<p><img src="https://images2.imgbox.com/98/f5/U4sGOHJX_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<p>Transformeræ¶æ„è‡ªé—®ä¸–ä»¥æ¥ï¼Œå·²æˆä¸ºNLPé¢†åŸŸçš„ä¸€ä¸ªé‡Œç¨‹ç¢‘ã€‚å…¶æ ¸å¿ƒæ€æƒ³æ˜¯åˆ©ç”¨è‡ªæ³¨æ„åŠ›æœºåˆ¶ï¼ˆSelf-Attentionï¼‰æ¥æ•æ‰æ–‡æœ¬ä¸­çš„é•¿è·ç¦»ä¾èµ–å…³ç³»ï¼Œæ— éœ€åƒå¾ªç¯ç¥ç»ç½‘ç»œï¼ˆRNNï¼‰é‚£æ ·é€æ­¥å¤„ç†åºåˆ—ã€‚å„å¤§è¯­è¨€æ¨¡å‹è™½åŸºäºTransformeræ¼”å˜ï¼›<strong>ä½†åœ¨ç»“æ„ã€ç¼–ç æ–¹å¼ã€æ¿€æ´»å‡½æ•°ã€layer Normæ–¹æ³•ä¸Šå„æœ‰ä¸åŒï¼›å¦å¤–æ©ç çš„è®¾è®¡ä¸åŒï¼Œè®­ç»ƒæ•°æ®å’Œç›®æ ‡çš„å¤šæ ·æ€§ç­‰</strong>ï¼Œéƒ½èµ‹äºˆäº†æ¨¡å‹ä¸åŒçš„ç‰¹æ€§å’Œåº”ç”¨åœºæ™¯ã€‚<br> <img src="https://images2.imgbox.com/7c/65/GYJBXrYO_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<h2><a id="ChatGLM3_38"></a>äºŒã€ChatGLM3æ¶æ„è®¾è®¡</h2> 
<h3><a id="1GLM__39"></a>1ã€GLM åŠ¨æœº</h3> 
<p>å¤§å‹é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹çš„å‘å±•å¯å½’çº³ä¸ºä¸‰ä¸ªä¸»è¦æ–¹å‘ï¼š<br> 1ï¼‰è‡ªç¼–ç æ¨¡å‹ (Auto Encoding)ï¼š BERTï¼ŒROBERTaï¼ŒDeBERTaï¼ŒALBERTç­‰ï¼›<strong>é‡‡ç”¨åŒå‘æ³¨æ„åŠ›æœºåˆ¶</strong>ï¼Œæ“…é•¿å¤„ç†è‡ªç„¶è¯­è¨€ç†è§£ä»»åŠ¡ï¼Œå¦‚æƒ…æ„Ÿåˆ†ç±»ã€æŠ½å–å¼é—®ç­”å’Œè‡ªç„¶è¯­è¨€æ¨ç†ç­‰ã€‚<br> 2ï¼‰è‡ªå›å½’æ¨¡å‹ (Auto Regressive) ï¼šGPTç³»åˆ—ï¼ŒLlamaï¼Œç™¾å·ï¼Œç­‰ï¼›<strong>é€šè¿‡å•å‘æ³¨æ„åŠ›æœºåˆ¶</strong>ï¼Œä¸“æ³¨äºç”Ÿæˆä»»åŠ¡ï¼ŒåŒ…æ‹¬è¯­è¨€å»ºæ¨¡å’Œæ–‡æœ¬ç”Ÿæˆã€‚<br> 3ï¼‰ç¼–ç å™¨-è§£ç å™¨æ¨¡å‹ (Encoder-Decoder) : T5ï¼ŒBARTï¼ŒMASSï¼ŒPALMç­‰ï¼›<strong>ç»“åˆäº†åŒå‘å’Œå•å‘æ³¨æ„åŠ›ï¼ˆencoderçš„attentionæ˜¯åŒå‘çš„ï¼Œdecoderçš„attentionæ˜¯å•å‘çš„ï¼‰</strong>ã€‚é€‚ç”¨äºæ¡ä»¶ç”Ÿæˆ(seq2seq)ä»»åŠ¡ï¼Œæ¯”å¦‚ï¼šæ–‡æœ¬æ‘˜è¦ï¼Œæœºå™¨ç¿»è¯‘ç­‰ã€‚</p> 
<blockquote> 
 <p>ç„¶è€Œï¼Œç°æœ‰æ¨¡å‹åœ¨å¤šä»»åŠ¡æ€§èƒ½ä¸Šå­˜åœ¨å±€é™ã€‚GLMï¼ˆGeneral Language Modelï¼‰æ—¨åœ¨èåˆä¸‰è€…ä¼˜åŠ¿ï¼Œå®ç°åœ¨è‡ªç„¶è¯­è¨€ç†è§£ã€ç”Ÿæˆå’Œæ¡ä»¶ç”Ÿæˆä»»åŠ¡ä¸Šçš„å…¨é¢ä¼˜åŒ–</p> 
</blockquote> 
<h3><a id="2GLM_47"></a>2ã€GLMçš„æ ¸å¿ƒæœºåˆ¶</h3> 
<p><img src="https://images2.imgbox.com/0c/fa/lgVTrEka_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<p>GLMçš„è®¾è®¡æ ¸å¿ƒåœ¨äºå‡ ä¸ªåˆ›æ–°æœºåˆ¶çš„å¼•å…¥ï¼š</p> 
<ul><li><strong>è‡ªå›å½’å¡«ç©º</strong> ï¼šé€šè¿‡é¢„æµ‹é®è”½ï¼ˆMaskedï¼‰çš„è¯æ¥è®­ç»ƒæ¨¡å‹ï¼Œç±»ä¼¼äºBERTçš„Masked Language Modelä»»åŠ¡ï¼Œå¢å¼ºæ¨¡å‹å¯¹è¯­è¨€çš„ç†è§£å’Œç”Ÿæˆèƒ½åŠ›ã€‚</li><li><strong>2Dä½ç½®ç¼–ç </strong>ï¼šé‡‡ç”¨äºŒç»´ä½ç½®ç¼–ç ï¼Œæ›´ç²¾ç»†åœ°æ•æ‰è¯ä¸è¯ä¹‹é—´çš„ç›¸å¯¹ä½ç½®å…³ç³»ï¼Œæå‡æ¨¡å‹å¯¹åºåˆ—é¡ºåºçš„æ•æ„Ÿåº¦ã€‚</li><li><strong>å¡«ç©ºåºåˆ—ä¹±åº</strong>ï¼šåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¯¹å¡«ç©ºä»»åŠ¡çš„åºåˆ—è¿›è¡Œä¹±åºå¤„ç†ï¼Œè¿«ä½¿æ¨¡å‹å­¦ä¹ æ›´æ·±å±‚æ¬¡çš„è¯­è¨€ç»“æ„å’Œè½¬æ¢è§„åˆ™ã€‚</li></ul> 
<h3><a id="3_54"></a>3ã€é¢„è®­ç»ƒä»»åŠ¡ç±»å‹</h3> 
<h4><a id="1_55"></a>1ï¼‰æ©ç è¯­è¨€æ¨¡å‹ï¼Œè‡ªç¼–ç æ¨¡å‹</h4> 
<p>å°†ä¸€äº›ä½ç½®çš„tokenæ›¿æ¢æˆç‰¹æ®Š[MASK]å­—ç¬¦ï¼Œé¢„æµ‹è¢«æ›¿æ¢çš„å­—ç¬¦<br> <img src="https://images2.imgbox.com/31/f6/RcIKwhRJ_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<h4><a id="2_59"></a>2ï¼‰å› æœæ¨¡å‹ï¼Œè‡ªå›å½’æ¨¡å‹</h4> 
<p>å°†å®Œæ•´åºåˆ—è¾“å…¥ï¼ŒåŸºäºä¸Šæ–‡çš„tokené¢„æµ‹ä¸‹æ–‡çš„token<br> <img src="https://images2.imgbox.com/6c/5d/I6lbB1yC_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<h4><a id="3_64"></a>3ï¼‰åºåˆ—åˆ°åºåˆ—æ¨¡å‹</h4> 
<p>é‡‡ç”¨ç¼–ç å™¨è§£ç å™¨çš„æ–¹å¼ï¼Œé¢„æµ‹æ”¾åœ¨è§£ç å™¨éƒ¨åˆ†<br> <img src="https://images2.imgbox.com/95/d5/oywV3KCO_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<p>åœ¨hugginfaceçš„PEFTåº“ä¸­ï¼ŒGLMå½’ç±»ä¸ºå› æœæ¨¡å‹<br> <img src="https://images2.imgbox.com/33/2a/MM9gJXB3_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<h3><a id="4prompt_72"></a>4ã€promptæ ¼å¼</h3> 
<p>ChatGLM3çš„promptæ ¼å¼å¦‚ä¸‹ï¼š<br> [gMASK]sop&lt;|user|&gt; \n Prompt&lt;|assistant|&gt;\n response eos_token<br> ä½¿ç”¨å‚è€ƒï¼š<br> tokenizer.build_chat_input(â€œpromptâ€, history=[], role=â€œuserâ€)<br> tokenizer.decode([xxx])<br> <img src="https://images2.imgbox.com/ab/1d/dW7qTSFr_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"><br> <img src="https://images2.imgbox.com/f4/1e/FOLiS6xI_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<h2><a id="ChatGLM3_82"></a>ä¸‰ã€ChatGLM3å¾®è°ƒå‡†å¤‡</h2> 
<h3><a id="1_83"></a>1ã€æ•°æ®å‡†å¤‡</h3> 
<p>æ•°æ®é›†ï¼šhttps://huggingface.co/datasets/c-s-ale/alpaca-gpt4-data-zh<br> <img src="https://images2.imgbox.com/cd/d2/0lGblC9a_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<h3><a id="2_86"></a>2ã€æ¨¡å‹é€‰æ‹©</h3> 
<p>æœ¬æ¬¡ä»»åŠ¡é€‰æ‹©GLM3çš„åŸºç¡€æ¨¡å‹ã€‚<br> æ¨¡å‹åœ°å€ï¼šhttps://www.modelscope.cn/models/ZhipuAI/chatglm3-6b-base/files</p> 
<p><img src="https://images2.imgbox.com/cc/82/sc8XWbsC_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<h2><a id="LoRAChatGLM3_92"></a>å››ã€åŸºäºLoRAå¾®è°ƒChatGLM3</h2> 
<h3><a id="1__93"></a>æ­¥éª¤1 å¯¼å…¥ç›¸å…³åŒ…</h3> 
<p>å¼€å§‹ä¹‹å‰ï¼Œæˆ‘ä»¬éœ€è¦å¯¼å…¥é€‚ç”¨äºæ¨¡å‹è®­ç»ƒå’Œæ¨ç†çš„å¿…è¦åº“ï¼Œå¦‚transformersã€‚</p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> datasets <span class="token keyword">import</span> Dataset
<span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoTokenizer<span class="token punctuation">,</span> AutoModelForCausalLM<span class="token punctuation">,</span> DataCollatorForSeq2Seq<span class="token punctuation">,</span> TrainingArguments<span class="token punctuation">,</span> Trainer
</code></pre> 
<h3><a id="2__101"></a>æ­¥éª¤2 åŠ è½½æ•°æ®é›†</h3> 
<p>ä½¿ç”¨é€‚å½“çš„æ•°æ®åŠ è½½å™¨ï¼Œä¾‹å¦‚datasetsåº“ï¼Œæ¥åŠ è½½é¢„å¤„ç†è¿‡çš„æŒ‡ä»¤éµå¾ªæ€§ä»»åŠ¡æ•°æ®é›†ã€‚</p> 
<pre><code class="prism language-python">ds <span class="token operator">=</span> Dataset<span class="token punctuation">.</span>load_from_disk<span class="token punctuation">(</span><span class="token string">"/root/PEFTä»£ç /tuning/lesson01/data/alpaca_data_zh"</span><span class="token punctuation">)</span>
ds
</code></pre> 
<p>è¾“å‡ºï¼š</p> 
<pre><code class="prism language-python">Dataset<span class="token punctuation">(</span><span class="token punctuation">{<!-- --></span>
    features<span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'output'</span><span class="token punctuation">,</span> <span class="token string">'input'</span><span class="token punctuation">,</span> <span class="token string">'instruction'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    num_rows<span class="token punctuation">:</span> <span class="token number">26858</span>
<span class="token punctuation">}</span><span class="token punctuation">)</span>
</code></pre> 
<p>æŸ¥çœ‹æ•°æ®</p> 
<pre><code class="prism language-python">ds<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">1</span><span class="token punctuation">]</span>
</code></pre> 
<p>è¾“å‡ºï¼š</p> 
<pre><code class="prism language-python"><span class="token punctuation">{<!-- --></span><span class="token string">'output'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'ä»¥ä¸‹æ˜¯ä¿æŒå¥åº·çš„ä¸‰ä¸ªæç¤ºï¼š\n\n1. ä¿æŒèº«ä½“æ´»åŠ¨ã€‚æ¯å¤©åšé€‚å½“çš„èº«ä½“è¿åŠ¨ï¼Œå¦‚æ•£æ­¥ã€è·‘æ­¥æˆ–æ¸¸æ³³ï¼Œèƒ½ä¿ƒè¿›å¿ƒè¡€ç®¡å¥åº·ï¼Œå¢å¼ºè‚Œè‚‰åŠ›é‡ï¼Œå¹¶æœ‰åŠ©äºå‡å°‘ä½“é‡ã€‚\n\n2. å‡è¡¡é¥®é£Ÿã€‚æ¯å¤©é£Ÿç”¨æ–°é²œçš„è”¬èœã€æ°´æœã€å…¨è°·ç‰©å’Œè„‚è‚ªå«é‡ä½çš„è›‹ç™½è´¨é£Ÿç‰©ï¼Œé¿å…é«˜ç³–ã€é«˜è„‚è‚ªå’ŒåŠ å·¥é£Ÿå“ï¼Œä»¥ä¿æŒå¥åº·çš„é¥®é£Ÿä¹ æƒ¯ã€‚\n\n3. ç¡çœ å……è¶³ã€‚ç¡çœ å¯¹äººä½“å¥åº·è‡³å…³é‡è¦ï¼Œæˆå¹´äººæ¯å¤©åº”ä¿è¯ 7-8 å°æ—¶çš„ç¡çœ ã€‚è‰¯å¥½çš„ç¡çœ æœ‰åŠ©äºå‡è½»å‹åŠ›ï¼Œä¿ƒè¿›èº«ä½“æ¢å¤ï¼Œå¹¶æé«˜æ³¨æ„åŠ›å’Œè®°å¿†åŠ›ã€‚'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
 <span class="token string">'input'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">''</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
 <span class="token string">'instruction'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'ä¿æŒå¥åº·çš„ä¸‰ä¸ªæç¤ºã€‚'</span><span class="token punctuation">]</span><span class="token punctuation">}</span>
</code></pre> 
<h3><a id="3__129"></a>æ­¥éª¤3 æ•°æ®é›†é¢„å¤„ç†</h3> 
<p>åˆ©ç”¨é¢„è®­ç»ƒæ¨¡å‹çš„åˆ†è¯å™¨ï¼ˆTokenizerï¼‰å¯¹åŸå§‹æ–‡æœ¬è¿›è¡Œç¼–ç ï¼Œå¹¶ç”Ÿæˆç›¸åº”çš„è¾“å…¥IDã€æ³¨æ„åŠ›æ©ç å’Œæ ‡ç­¾ã€‚</p> 
<p><strong>è‡ªå›å½’ç¼–ç æŒ‡ä»¤å¾®è°ƒæ•°æ®å¤„ç†è¿‡ç¨‹å›é¡¾ï¼š</strong><br> â‘ ã€€inputè¾“å…¥æ„å»ºï¼š</p> 
<ul><li>åœ¨æ­¤æ­¥éª¤ä¸­ï¼Œæˆ‘ä»¬å°†æ•°æ®é›†ä¸­çš„ä¸‰ä¸ªä¸»è¦ç»„æˆéƒ¨åˆ†ï¼ˆæŒ‡ä»¤ã€ç”¨æˆ·è¾“å…¥å’Œé¢„æœŸè¾“å‡ºï¼‰è¿æ¥åœ¨ä¸€èµ·ï¼Œå½¢æˆä¸€ä¸ªå•ä¸€çš„å­—ç¬¦ä¸²ã€‚</li><li>è¿™ä¸ªå­—ç¬¦ä¸²æŒ‰ç…§ä»¥ä¸‹æ ¼å¼ç»„ç»‡ï¼šé¦–å…ˆæ˜¯æŒ‡ä»¤ï¼ˆinstructionï¼‰ï¼Œç„¶åæ˜¯ç”¨æˆ·è¾“å…¥ï¼ˆinputï¼‰ï¼Œæœ€åæ˜¯é¢„æœŸè¾“å‡ºï¼ˆoutputï¼‰ã€‚</li><li>è¿™ç§ç»„ç»‡æ–¹å¼æœ‰åŠ©äºæ¨¡å‹ç†è§£è¾“å…¥å’Œè¾“å‡ºä¹‹é—´çš„å…³ç³»ï¼Œå¹¶å­¦ä¹ å¦‚ä½•æ ¹æ®æŒ‡ä»¤å’Œç”¨æˆ·è¾“å…¥ç”Ÿæˆæ­£ç¡®çš„è¾“å‡ºã€‚</li></ul> 
<p>â‘¡ã€€labelæ ‡ç­¾åˆ›å»ºï¼š</p> 
<ul><li>æ­¤æ­¥éª¤æ¶‰åŠæ„å»ºç”¨äºè®­ç»ƒæ¨¡å‹çš„æ ‡ç­¾ï¼ˆlabelsï¼‰ã€‚</li><li>ç”¨æˆ·è¾“å…¥éƒ¨åˆ†åœ¨æ ‡ç­¾ä¸­ä¿æŒä¸å˜ï¼Œè¿™æ„å‘³ç€æ¨¡å‹å°†å°è¯•å­¦ä¹ é¢„æµ‹ä¸ç”¨æˆ·è¾“å…¥ç›¸å¯¹åº”çš„è¾“å‡ºã€‚</li><li>å¯¹äºè¾“å‡ºéƒ¨åˆ†ï¼Œæˆ‘ä»¬å°†å…¶è½¬åŒ–ä¸ºç›®æ ‡æ ‡ç­¾ï¼Œä»¥ä¾¿æ¨¡å‹å¯ä»¥å­¦ä¹ ç”Ÿæˆä¸é¢„æœŸè¾“å‡ºç›¸åŒ¹é…çš„æ–‡æœ¬ã€‚</li><li>åœ¨è‡ªå›å½’æ¨¡å‹ä¸­ï¼Œé™¤äº†è¾“å‡ºéƒ¨åˆ†å¤–ï¼Œå…¶ä»–éƒ¨åˆ†ï¼ˆåŒ…æ‹¬æŒ‡ä»¤å’Œè¾“å…¥ï¼‰çš„æ ‡ç­¾è¢«æ›¿æ¢ä¸ºç‰¹æ®Šçš„åˆ†éš”ç¬¦ï¼ˆä¾‹å¦‚ï¼š[SEP]ï¼‰åŠ ä¸Š-100ã€‚è¿™æ ·åšçš„ç›®çš„æ˜¯å‘Šè¯‰æ¨¡å‹ä¸éœ€è¦é¢„æµ‹è¿™äº›éƒ¨åˆ†ï¼Œè€Œæ˜¯å°†æ³¨æ„åŠ›é›†ä¸­åœ¨è¾“å‡ºéƒ¨åˆ†ä¸Šã€‚</li><li>é€šè¿‡è¿™ç§æ–¹å¼ï¼Œæ¨¡å‹å°†å­¦ä¼šæ ¹æ®ç»™å®šçš„æŒ‡ä»¤å’Œç”¨æˆ·è¾“å…¥æ¥ç”Ÿæˆæ­£ç¡®çš„è¾“å‡ºï¼ŒåŒæ—¶å¿½ç•¥å…¶ä»–ä¸ç›¸å…³çš„ä¿¡æ¯ã€‚</li></ul> 
<h4><a id="1_145"></a>1ï¼‰è·å–åˆ†è¯å™¨</h4> 
<pre><code class="prism language-python"><span class="token comment">#åŠ è½½æœ¬åœ°æ¨¡å‹ï¼Œæå‰ä¸‹è½½åˆ°æœ¬åœ°</span>
tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"/root/autodl-tmp/chatglm3-6b-base"</span><span class="token punctuation">,</span> trust_remote_code<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
tokenizer
</code></pre> 
<p>è¾“å‡ºï¼š</p> 
<pre><code class="prism language-python">ChatGLMTokenizer<span class="token punctuation">(</span>name_or_path<span class="token operator">=</span><span class="token string">'/root/autodl-tmp/chatglm3-6b-base'</span><span class="token punctuation">,</span> vocab_size<span class="token operator">=</span><span class="token number">64798</span><span class="token punctuation">,</span> model_max_length<span class="token operator">=</span><span class="token number">1000000000000000019884624838656</span><span class="token punctuation">,</span> is_fast<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> padding_side<span class="token operator">=</span><span class="token string">'left'</span><span class="token punctuation">,</span> truncation_side<span class="token operator">=</span><span class="token string">'right'</span><span class="token punctuation">,</span> special_tokens<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token punctuation">}</span><span class="token punctuation">,</span> clean_up_tokenization_spaces<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
</code></pre> 
<h4><a id="2_159"></a>2ï¼‰å®šä¹‰æ•°æ®å¤„ç†å‡½æ•°</h4> 
<p>æ ¼å¼å¤„ç†ï¼š[gMASK]sop&lt;|user|&gt; \n Prompt&lt;|assistant|&gt;\n response eos_token</p> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">process_func</span><span class="token punctuation">(</span>example<span class="token punctuation">)</span><span class="token punctuation">:</span>
    MAX_LENGTH <span class="token operator">=</span> <span class="token number">256</span> <span class="token comment"># è®¾ç½®æœ€å¤§é•¿åº¦ä¸º256</span>
    input_ids<span class="token punctuation">,</span> attention_mask<span class="token punctuation">,</span> labels <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span> <span class="token comment"># åˆå§‹åŒ–è¾“å…¥IDã€æ³¨æ„åŠ›æ©ç å’Œæ ‡ç­¾åˆ—è¡¨</span>
    instruction <span class="token operator">=</span> <span class="token string">"\n"</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token punctuation">[</span>example<span class="token punctuation">[</span><span class="token string">"instruction"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> example<span class="token punctuation">[</span><span class="token string">"input"</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span>     <span class="token comment"># prompt</span>
    instruction <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>build_chat_input<span class="token punctuation">(</span>instruction<span class="token punctuation">,</span> history<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> role<span class="token operator">=</span><span class="token string">"user"</span><span class="token punctuation">)</span>  <span class="token comment"># [gMASK]sop&lt;|user|&gt; \n prompt &lt;|assistant|&gt;</span>
    response <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span><span class="token string">"\n"</span> <span class="token operator">+</span> example<span class="token punctuation">[</span><span class="token string">"output"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> add_special_tokens<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>        <span class="token comment"># \n response</span>
    input_ids <span class="token operator">=</span> instruction<span class="token punctuation">[</span><span class="token string">"input_ids"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>tolist<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> response<span class="token punctuation">[</span><span class="token string">"input_ids"</span><span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token punctuation">[</span>tokenizer<span class="token punctuation">.</span>eos_token_id<span class="token punctuation">]</span> <span class="token comment">#eos token</span>
    attention_mask <span class="token operator">=</span> instruction<span class="token punctuation">[</span><span class="token string">"attention_mask"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>tolist<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> response<span class="token punctuation">[</span><span class="token string">"attention_mask"</span><span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
    labels <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">100</span><span class="token punctuation">]</span> <span class="token operator">*</span> <span class="token builtin">len</span><span class="token punctuation">(</span>instruction<span class="token punctuation">[</span><span class="token string">"input_ids"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>tolist<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">+</span> response<span class="token punctuation">[</span><span class="token string">"input_ids"</span><span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token punctuation">[</span>tokenizer<span class="token punctuation">.</span>eos_token_id<span class="token punctuation">]</span>
    <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>input_ids<span class="token punctuation">)</span> <span class="token operator">&gt;</span> MAX_LENGTH<span class="token punctuation">:</span>
        input_ids <span class="token operator">=</span> input_ids<span class="token punctuation">[</span><span class="token punctuation">:</span>MAX_LENGTH<span class="token punctuation">]</span>
        attention_mask <span class="token operator">=</span> attention_mask<span class="token punctuation">[</span><span class="token punctuation">:</span>MAX_LENGTH<span class="token punctuation">]</span>
        labels <span class="token operator">=</span> labels<span class="token punctuation">[</span><span class="token punctuation">:</span>MAX_LENGTH<span class="token punctuation">]</span>
    <span class="token keyword">return</span> <span class="token punctuation">{<!-- --></span>
        <span class="token string">"input_ids"</span><span class="token punctuation">:</span> input_ids<span class="token punctuation">,</span>
        <span class="token string">"attention_mask"</span><span class="token punctuation">:</span> attention_mask<span class="token punctuation">,</span>
        <span class="token string">"labels"</span><span class="token punctuation">:</span> labels
    <span class="token punctuation">}</span> 
</code></pre> 
<h4><a id="3_183"></a>3ï¼‰å¯¹æ•°æ®è¿›è¡Œé¢„å¤„ç†</h4> 
<pre><code class="prism language-python">tokenized_ds <span class="token operator">=</span> ds<span class="token punctuation">.</span><span class="token builtin">map</span><span class="token punctuation">(</span>process_func<span class="token punctuation">,</span> remove_columns<span class="token operator">=</span>ds<span class="token punctuation">.</span>column_names<span class="token punctuation">)</span>
tokenized_ds
</code></pre> 
<p>è¾“å‡ºï¼š</p> 
<pre><code class="prism language-python">Dataset<span class="token punctuation">(</span><span class="token punctuation">{<!-- --></span>
    features<span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'input_ids'</span><span class="token punctuation">,</span> <span class="token string">'attention_mask'</span><span class="token punctuation">,</span> <span class="token string">'labels'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    num_rows<span class="token punctuation">:</span> <span class="token number">26858</span>
<span class="token punctuation">}</span><span class="token punctuation">)</span>

</code></pre> 
<h4><a id="4input_ids_200"></a>4ï¼‰è§£ç æ£€æŸ¥input_idsçš„æ ¼å¼</h4> 
<pre><code class="prism language-python">tokenizer<span class="token punctuation">.</span>decode<span class="token punctuation">(</span>tokenized_ds<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"input_ids"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre> 
<p>è¾“å‡ºï¼š</p> 
<pre><code class="prism language-python"><span class="token string">'[gMASK]sop&lt;|user|&gt; \n è§£é‡Šä¸ºä»€ä¹ˆä»¥ä¸‹åˆ†æ•°ç­‰åŒäº1/4\nè¾“å…¥ï¼š4/16&lt;|assistant|&gt; \n4/16ç­‰äº1/4æ˜¯å› ä¸ºæˆ‘ä»¬å¯ä»¥çº¦åˆ†åˆ†å­åˆ†æ¯éƒ½é™¤ä»¥ä»–ä»¬çš„æœ€å¤§å…¬çº¦æ•°4ï¼Œå¾—åˆ°ï¼ˆ4Ã·4ï¼‰/ (16Ã·4ï¼‰=1/4ã€‚åˆ†æ•°çš„çº¦åˆ†æ˜¯ç”¨åˆ†å­å’Œåˆ†æ¯é™¤ä»¥ç›¸åŒçš„éé›¶æ•´æ•°ï¼Œæ¥è¡¨ç¤ºåˆ†æ•°çš„ä¸€ä¸ªç›¸åŒçš„å€¼ï¼Œè¿™å› ä¸ºåˆ†æ•°å®é™…ä¸Šè¡¨ç¤ºäº†åˆ†å­é™¤ä»¥åˆ†æ¯ï¼Œæ‰€ä»¥å³ä½¿ä¸¤ä¸ªæ•°åŒæ—¶é™¤ä»¥åŒä¸€ä¸ªéé›¶æ•´æ•°ï¼Œåˆ†æ•°çš„å€¼ä¹Ÿä¸ä¼šæ”¹å˜ã€‚æ‰€ä»¥4/16 å’Œ1/4æ˜¯ä¸¤ç§ä¸åŒçš„ä¹¦å†™å½¢å¼ï¼Œä½†å®ƒä»¬çš„å€¼ç›¸ç­‰ã€‚'</span>
</code></pre> 
<h4><a id="5labels_212"></a>5ï¼‰æ£€æŸ¥labelsæ•°æ®æ ¼å¼</h4> 
<pre><code class="prism language-python">tokenizer<span class="token punctuation">.</span>decode<span class="token punctuation">(</span><span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">filter</span><span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> x <span class="token operator">!=</span> <span class="token operator">-</span><span class="token number">100</span><span class="token punctuation">,</span> tokenized_ds<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"labels"</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<p>è¾“å‡ºï¼š</p> 
<pre><code class="prism language-python"><span class="token string">'\n4/16ç­‰äº1/4æ˜¯å› ä¸ºæˆ‘ä»¬å¯ä»¥çº¦åˆ†åˆ†å­åˆ†æ¯éƒ½é™¤ä»¥ä»–ä»¬çš„æœ€å¤§å…¬çº¦æ•°4ï¼Œå¾—åˆ°ï¼ˆ4Ã·4ï¼‰/ (16Ã·4ï¼‰=1/4ã€‚åˆ†æ•°çš„çº¦åˆ†æ˜¯ç”¨åˆ†å­å’Œåˆ†æ¯é™¤ä»¥ç›¸åŒçš„éé›¶æ•´æ•°ï¼Œæ¥è¡¨ç¤ºåˆ†æ•°çš„ä¸€ä¸ªç›¸åŒçš„å€¼ï¼Œè¿™å› ä¸ºåˆ†æ•°å®é™…ä¸Šè¡¨ç¤ºäº†åˆ†å­é™¤ä»¥åˆ†æ¯ï¼Œæ‰€ä»¥å³ä½¿ä¸¤ä¸ªæ•°åŒæ—¶é™¤ä»¥åŒä¸€ä¸ªéé›¶æ•´æ•°ï¼Œåˆ†æ•°çš„å€¼ä¹Ÿä¸ä¼šæ”¹å˜ã€‚æ‰€ä»¥4/16 å’Œ1/4æ˜¯ä¸¤ç§ä¸åŒçš„ä¹¦å†™å½¢å¼ï¼Œä½†å®ƒä»¬çš„å€¼ç›¸ç­‰ã€‚'</span>
</code></pre> 
<h3><a id="4__224"></a>æ­¥éª¤4 åˆ›å»ºæ¨¡å‹</h3> 
<p>ç„¶åï¼Œæˆ‘ä»¬å®ä¾‹åŒ–ä¸€ä¸ªé¢„è®­ç»ƒæ¨¡å‹ï¼Œè¿™ä¸ªæ¨¡å‹å°†ä½œä¸ºå¾®è°ƒçš„åŸºç¡€ã€‚å¯¹äºå¤§å‹æ¨¡å‹ï¼Œæˆ‘ä»¬å¯èƒ½è¿˜éœ€è¦è¿›è¡Œä¸€äº›ç‰¹å®šçš„é…ç½®ï¼Œä»¥é€‚åº”å¯ç”¨çš„è®¡ç®—èµ„æºã€‚ï¼ˆ<code>ä¸ºäº†èŠ‚çœèµ„æºï¼Œè¿™é‡Œè®¾ç½®ä¸ºåŠç²¾åº¦torch_dtype=torch.half</code>ï¼‰</p> 
<h4><a id="1_226"></a>1ã€åˆ›å»ºæ¨¡å‹å®ä¾‹</h4> 
<h5><a id="1_227"></a>1ï¼‰åˆ›å»ºæ¨¡å‹</h5> 
<pre><code class="prism language-python"><span class="token keyword">import</span> torch
model <span class="token operator">=</span> AutoModelForCausalLM<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"/root/autodl-tmp/modelscope/Llama-2-7b-ms"</span><span class="token punctuation">,</span> 
                                             low_cpu_mem_usage<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
                                             torch_dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>half<span class="token punctuation">,</span>
                                             device_map<span class="token operator">=</span><span class="token string">"auto"</span><span class="token punctuation">)</span>
</code></pre> 
<h5><a id="2_236"></a>2ï¼‰ç²¾åº¦æŸ¥çœ‹ç¡®è®¤</h5> 
<pre><code class="prism language-python">model<span class="token punctuation">.</span>dtype
</code></pre> 
<p>è¾“å‡ºï¼š</p> 
<pre><code class="prism language-python">torch<span class="token punctuation">.</span>float16
</code></pre> 
<h5><a id="3_248"></a>3ï¼‰æŸ¥çœ‹æ¨¡å‹å‚æ•°</h5> 
<p>æ£€æŸ¥æ¨¡å‹æœ‰å“ªäº›å‚æ•°ï¼Œç¡®è®¤åœ¨å“ªä¸€å±‚æ·»åŠ LoRAå¾®è°ƒ</p> 
<pre><code class="prism language-python"><span class="token keyword">for</span> name<span class="token punctuation">,</span> param <span class="token keyword">in</span> model<span class="token punctuation">.</span>named_parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>name<span class="token punctuation">)</span>
</code></pre> 
<p>è¾“å‡ºï¼š</p> 
<pre><code class="prism language-python">transformer<span class="token punctuation">.</span>embedding<span class="token punctuation">.</span>word_embeddings<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">0</span><span class="token punctuation">.</span>input_layernorm<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">0</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">0</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>bias
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">0</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>dense<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">0</span><span class="token punctuation">.</span>post_attention_layernorm<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">0</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_h_to_4h<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">0</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_4h_to_h<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">1</span><span class="token punctuation">.</span>input_layernorm<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">1</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">1</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>bias
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">1</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>dense<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">1</span><span class="token punctuation">.</span>post_attention_layernorm<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">1</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_h_to_4h<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">1</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_4h_to_h<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">2</span><span class="token punctuation">.</span>input_layernorm<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">2</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">2</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>bias
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">2</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>dense<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">2</span><span class="token punctuation">.</span>post_attention_layernorm<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">2</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_h_to_4h<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">2</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_4h_to_h<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">3</span><span class="token punctuation">.</span>input_layernorm<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">3</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">3</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>bias
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">3</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>dense<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">3</span><span class="token punctuation">.</span>post_attention_layernorm<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">3</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_h_to_4h<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">3</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_4h_to_h<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">4</span><span class="token punctuation">.</span>input_layernorm<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">4</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">4</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>bias
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">4</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>dense<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">4</span><span class="token punctuation">.</span>post_attention_layernorm<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">4</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_h_to_4h<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">4</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_4h_to_h<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">5</span><span class="token punctuation">.</span>input_layernorm<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">5</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">5</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>bias
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">5</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>dense<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">5</span><span class="token punctuation">.</span>post_attention_layernorm<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">5</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_h_to_4h<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">5</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_4h_to_h<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">6</span><span class="token punctuation">.</span>input_layernorm<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">6</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">6</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>bias
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">6</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>dense<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">6</span><span class="token punctuation">.</span>post_attention_layernorm<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">6</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_h_to_4h<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">6</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_4h_to_h<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">7</span><span class="token punctuation">.</span>input_layernorm<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">7</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">7</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>bias
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">7</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>dense<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">7</span><span class="token punctuation">.</span>post_attention_layernorm<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">7</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_h_to_4h<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">7</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_4h_to_h<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">8</span><span class="token punctuation">.</span>input_layernorm<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">8</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">8</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>bias
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">8</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>dense<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">8</span><span class="token punctuation">.</span>post_attention_layernorm<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">8</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_h_to_4h<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">8</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_4h_to_h<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">9</span><span class="token punctuation">.</span>input_layernorm<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">9</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">9</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>bias
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">9</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>dense<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">9</span><span class="token punctuation">.</span>post_attention_layernorm<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">9</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_h_to_4h<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">9</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_4h_to_h<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">10</span><span class="token punctuation">.</span>input_layernorm<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">10</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">10</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>bias
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">10</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>dense<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">10</span><span class="token punctuation">.</span>post_attention_layernorm<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">10</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_h_to_4h<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">10</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_4h_to_h<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">11</span><span class="token punctuation">.</span>input_layernorm<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">11</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">11</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>bias
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">11</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>dense<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">11</span><span class="token punctuation">.</span>post_attention_layernorm<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">11</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_h_to_4h<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">11</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_4h_to_h<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">12</span><span class="token punctuation">.</span>input_layernorm<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">12</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">12</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>bias
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">12</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>dense<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">12</span><span class="token punctuation">.</span>post_attention_layernorm<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">12</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_h_to_4h<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">12</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_4h_to_h<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">13</span><span class="token punctuation">.</span>input_layernorm<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">13</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">13</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>bias
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">13</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>dense<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">13</span><span class="token punctuation">.</span>post_attention_layernorm<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">13</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_h_to_4h<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">13</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_4h_to_h<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">14</span><span class="token punctuation">.</span>input_layernorm<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">14</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">14</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>bias
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">14</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>dense<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">14</span><span class="token punctuation">.</span>post_attention_layernorm<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">14</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_h_to_4h<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">14</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_4h_to_h<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">15</span><span class="token punctuation">.</span>input_layernorm<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">15</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">15</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>bias
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">15</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>dense<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">15</span><span class="token punctuation">.</span>post_attention_layernorm<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">15</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_h_to_4h<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">15</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_4h_to_h<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">16</span><span class="token punctuation">.</span>input_layernorm<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">16</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">16</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>bias
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">16</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>dense<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">16</span><span class="token punctuation">.</span>post_attention_layernorm<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">16</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_h_to_4h<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">16</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_4h_to_h<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">17</span><span class="token punctuation">.</span>input_layernorm<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">17</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">17</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>bias
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">17</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>dense<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">17</span><span class="token punctuation">.</span>post_attention_layernorm<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">17</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_h_to_4h<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">17</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_4h_to_h<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">18</span><span class="token punctuation">.</span>input_layernorm<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">18</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">18</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>bias
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">18</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>dense<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">18</span><span class="token punctuation">.</span>post_attention_layernorm<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">18</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_h_to_4h<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">18</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_4h_to_h<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">19</span><span class="token punctuation">.</span>input_layernorm<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">19</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">19</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>bias
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">19</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>dense<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">19</span><span class="token punctuation">.</span>post_attention_layernorm<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">19</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_h_to_4h<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">19</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_4h_to_h<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">20</span><span class="token punctuation">.</span>input_layernorm<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">20</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">20</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>bias
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">20</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>dense<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">20</span><span class="token punctuation">.</span>post_attention_layernorm<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">20</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_h_to_4h<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">20</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_4h_to_h<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">21</span><span class="token punctuation">.</span>input_layernorm<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">21</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">21</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>bias
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">21</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>dense<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">21</span><span class="token punctuation">.</span>post_attention_layernorm<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">21</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_h_to_4h<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">21</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_4h_to_h<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">22</span><span class="token punctuation">.</span>input_layernorm<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">22</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">22</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>bias
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">22</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>dense<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">22</span><span class="token punctuation">.</span>post_attention_layernorm<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">22</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_h_to_4h<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">22</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_4h_to_h<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">23</span><span class="token punctuation">.</span>input_layernorm<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">23</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">23</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>bias
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">23</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>dense<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">23</span><span class="token punctuation">.</span>post_attention_layernorm<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">23</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_h_to_4h<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">23</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_4h_to_h<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">24</span><span class="token punctuation">.</span>input_layernorm<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">24</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">24</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>bias
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">24</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>dense<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">24</span><span class="token punctuation">.</span>post_attention_layernorm<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">24</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_h_to_4h<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">24</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_4h_to_h<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">25</span><span class="token punctuation">.</span>input_layernorm<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">25</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">25</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>bias
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">25</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>dense<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">25</span><span class="token punctuation">.</span>post_attention_layernorm<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">25</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_h_to_4h<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">25</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_4h_to_h<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">26</span><span class="token punctuation">.</span>input_layernorm<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">26</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">26</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>bias
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">26</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>dense<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">26</span><span class="token punctuation">.</span>post_attention_layernorm<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">26</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_h_to_4h<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">26</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_4h_to_h<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">27</span><span class="token punctuation">.</span>input_layernorm<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">27</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">27</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>bias
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">27</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>dense<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">27</span><span class="token punctuation">.</span>post_attention_layernorm<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">27</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_h_to_4h<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>layers<span class="token punctuation">.</span><span class="token number">27</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_4h_to_h<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>final_layernorm<span class="token punctuation">.</span>weight
transformer<span class="token punctuation">.</span>output_layer<span class="token punctuation">.</span>weight
</code></pre> 
<p><code>ä¸‹é¢2ä¸ªéƒ¨åˆ†æ˜¯LoRAç›¸å…³çš„é…ç½®ã€‚</code></p> 
<h4><a id="2PEFT_1__462"></a>2ã€PEFT æ­¥éª¤1 é…ç½®æ–‡ä»¶</h4> 
<p>åœ¨ä½¿ç”¨PEFTè¿›è¡Œå¾®è°ƒæ—¶ï¼Œæˆ‘ä»¬é¦–å…ˆéœ€è¦åˆ›å»ºä¸€ä¸ªé…ç½®æ–‡ä»¶ï¼Œè¯¥æ–‡ä»¶å®šä¹‰äº†å¾®è°ƒè¿‡ç¨‹ä¸­çš„å„ç§è®¾ç½®ï¼Œå¦‚å­¦ä¹ ç‡è°ƒåº¦ã€ä¼˜åŒ–å™¨é€‰æ‹©ç­‰ã€‚<br> <code>æå‰å®‰è£…peftï¼špip install peft</code></p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> peft <span class="token keyword">import</span> LoraConfig<span class="token punctuation">,</span> TaskType<span class="token punctuation">,</span> get_peft_model<span class="token punctuation">,</span> PeftModel

config <span class="token operator">=</span> LoraConfig<span class="token punctuation">(</span>target_modules<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"query_key_value"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
config
</code></pre> 
<p>è¾“å‡º</p> 
<pre><code class="prism language-python">LoraConfig<span class="token punctuation">(</span>peft_type<span class="token operator">=</span><span class="token operator">&lt;</span>PeftType<span class="token punctuation">.</span>LORA<span class="token punctuation">:</span> <span class="token string">'LORA'</span><span class="token operator">&gt;</span><span class="token punctuation">,</span> auto_mapping<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> base_model_name_or_path<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> revision<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> task_type<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> inference_mode<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> r<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">,</span> target_modules<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token string">'query_key_value'</span><span class="token punctuation">}</span><span class="token punctuation">,</span> lora_alpha<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">,</span> lora_dropout<span class="token operator">=</span><span class="token number">0.0</span><span class="token punctuation">,</span> fan_in_fan_out<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token string">'none'</span><span class="token punctuation">,</span> modules_to_save<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> init_lora_weights<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> layers_to_transform<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> layers_pattern<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> rank_pattern<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token punctuation">}</span><span class="token punctuation">,</span> alpha_pattern<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token punctuation">}</span><span class="token punctuation">,</span> megatron_config<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> megatron_core<span class="token operator">=</span><span class="token string">'megatron.core'</span><span class="token punctuation">,</span> loftq_config<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token punctuation">}</span><span class="token punctuation">)</span>
</code></pre> 
<h4><a id="3PEFT_2__479"></a>3ã€PEFT æ­¥éª¤2 åˆ›å»ºæ¨¡å‹</h4> 
<p>æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬ä½¿ç”¨PEFTå’Œé¢„è®­ç»ƒæ¨¡å‹æ¥åˆ›å»ºä¸€ä¸ªå¾®è°ƒæ¨¡å‹ã€‚è¿™ä¸ªæ¨¡å‹å°†åŒ…å«åŸå§‹çš„é¢„è®­ç»ƒæ¨¡å‹ä»¥åŠç”±PEFTå¼•å…¥çš„ä½ç§©å‚æ•°ã€‚</p> 
<h5><a id="1_481"></a>1ï¼‰åˆ›å»ºå¾®è°ƒæ¨¡å‹</h5> 
<pre><code class="prism language-python">model <span class="token operator">=</span> get_peft_model<span class="token punctuation">(</span>model<span class="token punctuation">,</span> config<span class="token punctuation">)</span>
config
</code></pre> 
<p>è¾“å‡º</p> 
<pre><code class="prism language-python">LoraConfig<span class="token punctuation">(</span>peft_type<span class="token operator">=</span><span class="token operator">&lt;</span>PeftType<span class="token punctuation">.</span>LORA<span class="token punctuation">:</span> <span class="token string">'LORA'</span><span class="token operator">&gt;</span><span class="token punctuation">,</span> auto_mapping<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> base_model_name_or_path<span class="token operator">=</span><span class="token string">'/root/autodl-tmp/modelscope/Llama-2-7b-ms'</span><span class="token punctuation">,</span> revision<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> task_type<span class="token operator">=</span><span class="token operator">&lt;</span>TaskType<span class="token punctuation">.</span>CAUSAL_LM<span class="token punctuation">:</span> <span class="token string">'CAUSAL_LM'</span><span class="token operator">&gt;</span><span class="token punctuation">,</span> inference_mode<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> r<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">,</span> target_modules<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token string">'q_proj'</span><span class="token punctuation">,</span> <span class="token string">'v_proj'</span><span class="token punctuation">}</span><span class="token punctuation">,</span> lora_alpha<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">,</span> lora_dropout<span class="token operator">=</span><span class="token number">0.0</span><span class="token punctuation">,</span> fan_in_fan_out<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token string">'none'</span><span class="token punctuation">,</span> modules_to_save<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> init_lora_weights<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> layers_to_transform<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> layers_pattern<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> rank_pattern<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token punctuation">}</span><span class="token punctuation">,</span> alpha_pattern<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token punctuation">}</span><span class="token punctuation">,</span> megatron_config<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> megatron_core<span class="token operator">=</span><span class="token string">'megatron.core'</span><span class="token punctuation">,</span> loftq_config<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token punctuation">}</span><span class="token punctuation">)</span>
</code></pre> 
<h5><a id="2LoRA_494"></a>2ï¼‰æŸ¥çœ‹LoRAå±‚æ·»åŠ æƒ…å†µ</h5> 
<p>æ‰“å°æ‰€æœ‰çš„æ¨¡å‹å‚æ•°ï¼ŒæŸ¥çœ‹LoRAæ·»åŠ åˆ°äº†å“ªä¸€å±‚</p> 
<pre><code class="prism language-python"><span class="token keyword">for</span> name<span class="token punctuation">,</span> parameter <span class="token keyword">in</span> model<span class="token punctuation">.</span>named_parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>name<span class="token punctuation">)</span>
</code></pre> 
<h5><a id="3_503"></a>3ï¼‰æŸ¥çœ‹æ¨¡å‹ä¸­å¯è®­ç»ƒå‚æ•°çš„æ•°é‡</h5> 
<pre><code class="prism language-python">model<span class="token punctuation">.</span>print_trainable_parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment">#æ‰“å°å‡ºæ¨¡å‹ä¸­å¯è®­ç»ƒå‚æ•°çš„æ•°é‡</span>
</code></pre> 
<p>è¾“å‡ºï¼š</p> 
<pre><code class="prism language-python">trainable params<span class="token punctuation">:</span> <span class="token number">1</span><span class="token punctuation">,</span><span class="token number">949</span><span class="token punctuation">,</span><span class="token number">696</span> <span class="token operator">|</span><span class="token operator">|</span> <span class="token builtin">all</span> params<span class="token punctuation">:</span> <span class="token number">6</span><span class="token punctuation">,</span><span class="token number">245</span><span class="token punctuation">,</span><span class="token number">533</span><span class="token punctuation">,</span><span class="token number">696</span> <span class="token operator">|</span><span class="token operator">|</span> trainable<span class="token operator">%</span><span class="token punctuation">:</span> <span class="token number">0.031217444255383614</span>
</code></pre> 
<h3><a id="5__513"></a>æ­¥éª¤5 é…ç½®è®­ç»ƒå‚æ•°</h3> 
<p>åœ¨è¿™ä¸€æ­¥ï¼Œæˆ‘ä»¬å®šä¹‰è®­ç»ƒå‚æ•°ï¼Œè¿™äº›å‚æ•°åŒ…æ‹¬è¾“å‡ºç›®å½•ã€å­¦ä¹ ç‡ã€æƒé‡è¡°å‡ã€æ¢¯åº¦ç´¯ç§¯æ­¥æ•°ã€è®­ç»ƒå‘¨æœŸæ•°ç­‰ã€‚è¿™äº›å‚æ•°å°†è¢«ç”¨æ¥é…ç½®è®­ç»ƒè¿‡ç¨‹ã€‚(<code>è®¾ç½®adam_epsilon=1e-4é¿å…ç²¾åº¦æº¢å‡ºï¼ŒåŠç²¾åº¦çš„æƒ…å†µä¸‹æ‰éœ€è¦è®¾ç½®</code>ï¼‰</p> 
<pre><code class="prism language-python">args <span class="token operator">=</span> TrainingArguments<span class="token punctuation">(</span>
    output_dir<span class="token operator">=</span><span class="token string">"/root/autodl-tmp/chatglm2output"</span><span class="token punctuation">,</span> <span class="token comment">#è¾“å‡ºç›®å½•ï¼Œç”¨äºå­˜å‚¨æ¨¡å‹å’Œæ—¥å¿—æ–‡ä»¶ã€‚</span>
    per_device_train_batch_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token comment"># æ¯ä¸ªè®¾å¤‡çš„è®­ç»ƒæ‰¹æ¬¡å¤§å°ï¼Œå³æ¯ä¸ªè®¾å¤‡æ¯æ¬¡å¤„ç†çš„æ•°æ®é‡ï¼Œæ‰¹æ¬¡è¶Šå¤§ï¼Œè®­ç»ƒæ—¶éœ€è¦èµ„æºè¶Šå¤š</span>
    gradient_accumulation_steps<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">,</span> <span class="token comment"># æŒ‡å®šæ¢¯åº¦ç´¯ç§¯æ­¥æ•°ã€‚ç”¨äºæ§åˆ¶æ¢¯åº¦æ›´æ–°çš„é¢‘ç‡ã€‚åœ¨æ¯ä¸ªç´¯ç§¯æ­¥ä¸­ï¼Œæ¨¡å‹ä¼šè®¡ç®—å¤šä¸ªæ‰¹æ¬¡çš„æ¢¯åº¦ï¼Œç„¶åä¸€æ¬¡æ€§æ›´æ–°æƒé‡ã€‚è¿™å¯ä»¥å‡å°‘å†…å­˜å ç”¨å¹¶æé«˜è®­ç»ƒé€Ÿåº¦ã€‚åœ¨æœ¬ä¾‹å­ä¸­ï¼Œæ¯16ä¸ªæ­¥éª¤è¿›è¡Œä¸€æ¬¡æ¢¯åº¦æ›´æ–°ã€‚</span>
    logging_steps<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token comment">#æ—¥å¿—è®°å½•æ­¥æ•°ï¼Œç”¨äºæ§åˆ¶æ¯éš”å¤šå°‘æ­¥è®°å½•ä¸€æ¬¡è®­ç»ƒæ—¥å¿—ã€‚</span>
    num_train_epochs<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token comment">#è®­ç»ƒè½®æ•°ï¼Œå³æ¨¡å‹åœ¨æ•´ä¸ªè®­ç»ƒé›†ä¸Šè¿›è¡Œè¿­ä»£çš„æ¬¡æ•°ã€‚æ­£å¸¸æƒ…å†µä¼šè®­ç»ƒå¾ˆå¤šè½®</span>
    learning_rate<span class="token operator">=</span><span class="token number">1e-4</span><span class="token punctuation">,</span> <span class="token comment">#å­¦ä¹ ç‡ï¼Œæ§åˆ¶æ¨¡å‹å‚æ•°æ›´æ–°çš„é€Ÿåº¦ã€‚è¾ƒå°çš„å­¦ä¹ ç‡ä¼šä½¿æ¨¡å‹æ”¶æ•›å¾—æ›´å¿«ï¼Œä½†å¯èƒ½éœ€è¦æ›´å¤šçš„è®­ç»ƒè½®æ•°</span>
    adam_epsilon<span class="token operator">=</span><span class="token number">1e-4</span><span class="token punctuation">,</span> <span class="token comment">#Adamä¼˜åŒ–å™¨çš„epsilonå€¼ï¼Œç”¨äºé˜²æ­¢é™¤ä»¥é›¶çš„æƒ…å†µã€‚</span>
    remove_unused_columns<span class="token operator">=</span><span class="token boolean">False</span> <span class="token comment">#æ˜¯å¦ç§»é™¤æœªä½¿ç”¨çš„åˆ—ï¼Œå¦‚æœè®¾ç½®ä¸ºFalseï¼Œåˆ™ä¿ç•™æ‰€æœ‰åˆ—ï¼Œå¦åˆ™åªä¿ç•™æ¨¡å‹æ‰€éœ€çš„åˆ—ã€‚</span>
<span class="token punctuation">)</span>
</code></pre> 
<h3><a id="6__530"></a>æ­¥éª¤6 åˆ›å»ºè®­ç»ƒå™¨</h3> 
<p>æœ€åï¼Œæˆ‘ä»¬åˆ›å»ºä¸€ä¸ªè®­ç»ƒå™¨å®ä¾‹ï¼Œå®ƒå°è£…äº†è®­ç»ƒå¾ªç¯ã€‚è®­ç»ƒå™¨å°†è´Ÿè´£è¿è¡Œè®­ç»ƒè¿‡ç¨‹ï¼Œå¹¶æ ¹æ®æˆ‘ä»¬ä¹‹å‰å®šä¹‰çš„å‚æ•°è¿›è¡Œä¼˜åŒ–ã€‚</p> 
<pre><code class="prism language-python">trainer <span class="token operator">=</span> Trainer<span class="token punctuation">(</span>
    model<span class="token operator">=</span>model<span class="token punctuation">,</span>
    args<span class="token operator">=</span>args<span class="token punctuation">,</span>
    train_dataset<span class="token operator">=</span>tokenized_ds<span class="token punctuation">,</span>
    data_collator<span class="token operator">=</span>DataCollatorForSeq2Seq<span class="token punctuation">(</span>tokenizer<span class="token operator">=</span>tokenizer<span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>

</code></pre> 
<h3><a id="7__543"></a>æ­¥éª¤7 æ¨¡å‹è®­ç»ƒ</h3> 
<p>é€šè¿‡è°ƒç”¨è®­ç»ƒå™¨çš„<code>train()</code>æ–¹æ³•ï¼Œæˆ‘ä»¬å¯åŠ¨æ¨¡å‹çš„è®­ç»ƒè¿‡ç¨‹ã€‚è¿™å°†æ ¹æ®ä¹‹å‰å®šä¹‰çš„å‚æ•°æ‰§è¡Œæ¨¡å‹çš„è®­ç»ƒã€‚</p> 
<pre><code class="prism language-python">trainer<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<h3><a id="8__550"></a>æ­¥éª¤8 æ¨¡å‹æ¨ç†</h3> 
<p>è®­ç»ƒå®Œæˆåï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹è¿›è¡Œæ¨ç†ã€‚</p> 
<pre><code class="prism language-python">model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>model<span class="token punctuation">.</span>chat<span class="token punctuation">(</span>tokenizer<span class="token punctuation">,</span> <span class="token string">"å¦‚ä½•å†™ç®€å†ï¼Ÿ"</span><span class="token punctuation">,</span> history<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre> 
<p>è¾“å‡ºï¼š</p> 
<pre><code class="prism language-python">å†™ç®€å†æ—¶ï¼Œæ‚¨å¯ä»¥æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤è¿›è¡Œï¼š

<span class="token number">1.</span> ä¸ªäººä¿¡æ¯ï¼šåœ¨å¼€å¤´éƒ¨åˆ†ï¼Œå†™ä¸Šæ‚¨çš„å§“åã€è”ç³»æ–¹å¼å’Œåœ°å€ã€‚

<span class="token number">2.</span> æ•™è‚²èƒŒæ™¯ï¼šåˆ—å‡ºæ‚¨æ‰€è·å¾—çš„æ‰€æœ‰å­¦å†ï¼ŒåŒ…æ‹¬å­¦æ ¡åç§°ã€å­¦ä½å’Œæ¯•ä¸šæ—¥æœŸã€‚

<span class="token number">3.</span> å·¥ä½œç»å†ï¼šåœ¨ç®€å†ä¸­ï¼ŒæŒ‰ç…§æ—¶é—´é¡ºåºåˆ—å‡ºæ‚¨è¿‡å»çš„å·¥ä½œç»å†ï¼ŒåŒ…æ‹¬å…¬å¸åç§°ã€èŒä½ã€èŒè´£å’Œæ—¶é—´ã€‚

<span class="token number">4.</span> æŠ€èƒ½å’Œè¯ä¹¦ï¼šåœ¨æ‚¨çš„ç®€å†ä¸­ï¼Œåˆ—å‡ºæ‚¨æŒæ¡çš„æŠ€èƒ½å’Œè¯ä¹¦ï¼Œä¾‹å¦‚ç¼–ç¨‹è¯­è¨€ã€è½¯ä»¶ã€è¯ä¹¦å’Œè¯ä¹¦ç­‰çº§ã€‚

<span class="token number">5.</span> ä¸ªäººäº®ç‚¹ï¼šåœ¨æ‚¨çš„ç®€å†ä¸­ï¼Œåˆ—å‡ºæ‚¨çš„ä¸ªäººäº®ç‚¹ï¼Œä¾‹å¦‚æ‚¨åœ¨å›¢é˜Ÿåˆä½œã€åˆ›æ–°ã€è§£å†³é—®é¢˜å’Œæ²Ÿé€šæ–¹é¢çš„ä¼˜åŠ¿ã€‚

<span class="token number">6.</span> æ€»ç»“ï¼šåœ¨ç»“å°¾éƒ¨åˆ†ï¼Œç®€è¦æ€»ç»“æ‚¨åœ¨å„ä¸ªé¢†åŸŸçš„å·¥ä½œç»éªŒå’ŒæŠ€èƒ½ï¼Œå¹¶è¡¨è¾¾æ‚¨å¯¹æœªæ¥çš„èŒä¸šå‘å±•çš„æœŸæœ›ã€‚

è¯·æ³¨æ„ï¼Œç®€å†åº”è¯¥ç®€æ´æ˜äº†ï¼Œçªå‡ºæ‚¨çš„ä¼˜åŠ¿å’ŒæŠ€èƒ½ï¼ŒåŒæ—¶é¿å…ä½¿ç”¨è¿‡äºå¤æ‚çš„è¯­è¨€å’Œè¯æ±‡ã€‚æ‚¨å¯ä»¥å‚è€ƒæ¨¡æ¿æˆ–åœ¨çº¿ç®€å†ç”Ÿæˆå™¨æ¥å¸®åŠ©æ‚¨åˆ›å»ºä¸€ä»½ç®€å†ã€‚
</code></pre> 
<h2><a id="_577"></a>æ€»ç»“</h2> 
<p>æœ¬æ–‡æ·±å…¥æ¢è®¨äº†å¤§è¯­è¨€æ¨¡å‹ChatGLM3çš„å¾®è°ƒå®è·µï¼Œä»æ¶æ„è®¾è®¡åˆ°é¢„è®­ç»ƒä»»åŠ¡ï¼Œå†åˆ°å®é™…çš„å¾®è°ƒæ“ä½œæ­¥éª¤ã€‚æ–‡ç« é¦–å…ˆå›é¡¾äº†Transformeræ¶æ„çš„é‡è¦æ€§ï¼Œæ¥ç€åˆ†æäº†ChatGLM3èåˆä¸åŒé¢„è®­ç»ƒæ¨¡å‹ä¼˜åŠ¿çš„ç‹¬ç‰¹åŠ¨æœºå’Œæ ¸å¿ƒæœºåˆ¶ï¼Œå¦‚è‡ªå›å½’å¡«ç©ºå’Œ2Dä½ç½®ç¼–ç ã€‚æ­¤å¤–ï¼Œæ–‡ä¸­è¯¦ç»†æè¿°äº†åŸºäºLoRAæŠ€æœ¯çš„å¾®è°ƒè¿‡ç¨‹ï¼ŒåŒ…æ‹¬æ•°æ®å‡†å¤‡ã€æ¨¡å‹æ„å»ºã€è®­ç»ƒä»¥åŠæ¨ç†ç­‰å…³é”®æ­¥éª¤ã€‚è¿™äº›å†…å®¹æ—¨åœ¨ä¸ºå¤§å®¶æä¾›å®è´µçš„å‚è€ƒï¼Œå¸®åŠ©å¤§å®¶åœ¨è‡ªç„¶è¯­è¨€å¤„ç†é¡¹ç›®ä¸­æœ‰æ•ˆåº”ç”¨å¤§å‹é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ã€‚</p> 
<p><img src="https://images2.imgbox.com/b8/cf/rf8R2Guh_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<p>ğŸ¯ğŸ”–æ›´å¤šä¸“æ ç³»åˆ—æ–‡ç« ï¼š<a href="https://blog.csdn.net/xiaobing259/category_12628007.html?spm=1001.2014.3001.5482"><strong>AIGC-AIå¤§æ¨¡å‹æ¢ç´¢ä¹‹è·¯</strong></a></p> 
<blockquote> 
 <p>å¦‚æœæ–‡ç« å†…å®¹å¯¹æ‚¨æœ‰æ‰€è§¦åŠ¨ï¼Œåˆ«å¿˜äº†<font color="red"><strong>ç‚¹èµã€â­å…³æ³¨ï¼Œæ”¶è—</strong></font>ï¼åŠ å…¥æˆ‘ï¼Œè®©æˆ‘ä»¬æºæ‰‹åŒè¡ŒAIçš„æ¢ç´¢ä¹‹æ—…ï¼Œä¸€èµ·å¼€å¯æ™ºèƒ½æ—¶ä»£çš„å¤§é—¨ï¼</p> 
</blockquote>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/5089fd683ac3fe1866cf760627f75b31/" rel="prev">
			<span class="pager__subtitle">Â«&thinsp;Previous</span>
			<p class="pager__title">é™æµç®—æ³•(ä»¤ç‰Œæ¡¶&amp;æ¼æ¡¶&amp;è®¡æ•°å™¨)</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/e62856c9b3aab7bbd1f20b0fef6323b8/" rel="next">
			<span class="pager__subtitle">Next&thinsp;Â»</span>
			<p class="pager__title">ã€C#ã€‘.net core 6.0 ApiControllerï¼ŒAPIæ§åˆ¶å™¨æ–¹æ³•ï¼ŒAPIæ¥å£ä»¥å®ä½“ç±»ä½œä¸ºæ¥æ”¶å‚æ•°åº”è¯¥æ³¨æ„çš„ç‚¹</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 ç¼–ç¨‹å­¦ä¹ è€….
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>