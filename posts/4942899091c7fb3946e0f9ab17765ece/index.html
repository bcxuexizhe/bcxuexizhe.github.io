<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>AIå¤§æ¨¡å‹æ¢ç´¢ä¹‹è·¯-è®­ç»ƒç¯‡16ï¼šå¤§è¯­è¨€æ¨¡å‹é¢„è®­ç»ƒ-å¾®è°ƒæŠ€æœ¯ä¹‹LoRA - ç¼–ç¨‹å­¦ä¹ è€…</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcxuexizhe.github.io/posts/4942899091c7fb3946e0f9ab17765ece/">
  <meta property="og:site_name" content="ç¼–ç¨‹å­¦ä¹ è€…">
  <meta property="og:title" content="AIå¤§æ¨¡å‹æ¢ç´¢ä¹‹è·¯-è®­ç»ƒç¯‡16ï¼šå¤§è¯­è¨€æ¨¡å‹é¢„è®­ç»ƒ-å¾®è°ƒæŠ€æœ¯ä¹‹LoRA">
  <meta property="og:description" content="ç³»åˆ—ç¯‡ç« ğŸ’¥ AIå¤§æ¨¡å‹æ¢ç´¢ä¹‹è·¯-è®­ç»ƒç¯‡1ï¼šå¤§è¯­è¨€æ¨¡å‹å¾®è°ƒåŸºç¡€è®¤çŸ¥
AIå¤§æ¨¡å‹æ¢ç´¢ä¹‹è·¯-è®­ç»ƒç¯‡2ï¼šå¤§è¯­è¨€æ¨¡å‹é¢„è®­ç»ƒåŸºç¡€è®¤çŸ¥
AIå¤§æ¨¡å‹æ¢ç´¢ä¹‹è·¯-è®­ç»ƒç¯‡3ï¼šå¤§è¯­è¨€æ¨¡å‹å…¨æ™¯è§£è¯»
AIå¤§æ¨¡å‹æ¢ç´¢ä¹‹è·¯-è®­ç»ƒç¯‡4ï¼šå¤§è¯­è¨€æ¨¡å‹è®­ç»ƒæ•°æ®é›†æ¦‚è§ˆ
AIå¤§æ¨¡å‹æ¢ç´¢ä¹‹è·¯-è®­ç»ƒç¯‡5ï¼šå¤§è¯­è¨€æ¨¡å‹é¢„è®­ç»ƒæ•°æ®å‡†å¤‡-è¯å…ƒåŒ–
AIå¤§æ¨¡å‹æ¢ç´¢ä¹‹è·¯-è®­ç»ƒç¯‡6ï¼šå¤§è¯­è¨€æ¨¡å‹é¢„è®­ç»ƒæ•°æ®å‡†å¤‡-é¢„å¤„ç†
AIå¤§æ¨¡å‹æ¢ç´¢ä¹‹è·¯-è®­ç»ƒç¯‡7ï¼šå¤§è¯­è¨€æ¨¡å‹Transformeråº“ä¹‹HuggingFaceä»‹ç»
AIå¤§æ¨¡å‹æ¢ç´¢ä¹‹è·¯-è®­ç»ƒç¯‡8ï¼šå¤§è¯­è¨€æ¨¡å‹Transformeråº“-é¢„è®­ç»ƒæµç¨‹ç¼–ç ä½“éªŒ
AIå¤§æ¨¡å‹æ¢ç´¢ä¹‹è·¯-è®­ç»ƒç¯‡9ï¼šå¤§è¯­è¨€æ¨¡å‹Transformeråº“-Pipelineç»„ä»¶å®è·µ
AIå¤§æ¨¡å‹æ¢ç´¢ä¹‹è·¯-è®­ç»ƒç¯‡10ï¼šå¤§è¯­è¨€æ¨¡å‹Transformeråº“-Tokenizerç»„ä»¶å®è·µ
AIå¤§æ¨¡å‹æ¢ç´¢ä¹‹è·¯-è®­ç»ƒç¯‡11ï¼šå¤§è¯­è¨€æ¨¡å‹Transformeråº“-Modelç»„ä»¶å®è·µ
AIå¤§æ¨¡å‹æ¢ç´¢ä¹‹è·¯-è®­ç»ƒç¯‡12ï¼šè¯­è¨€æ¨¡å‹Transformeråº“-Datasetsç»„ä»¶å®è·µ
AIå¤§æ¨¡å‹æ¢ç´¢ä¹‹è·¯-è®­ç»ƒç¯‡13ï¼šå¤§è¯­è¨€æ¨¡å‹Transformeråº“-Evaluateç»„ä»¶å®è·µ
AIå¤§æ¨¡å‹æ¢ç´¢ä¹‹è·¯-è®­ç»ƒç¯‡14ï¼šå¤§è¯­è¨€æ¨¡å‹Transformeråº“-Trainerç»„ä»¶å®è·µ
AIå¤§æ¨¡å‹æ¢ç´¢ä¹‹è·¯-è®­ç»ƒç¯‡15ï¼šå¤§è¯­è¨€æ¨¡å‹é¢„è®­ç»ƒä¹‹å…¨é‡å‚æ•°å¾®è°ƒ
ç›®å½• ç³»åˆ—ç¯‡ç« ğŸ’¥å‰è¨€ä¸€ã€å¾®è°ƒæŠ€æœ¯åˆ†ç±»äºŒã€LoRAåŸç†ä¸‰ã€åœ¨å“ªå„¿å¢åŠ æ—è·¯å››ã€ä¸ºä»€ä¹ˆå¾®è°ƒå°‘é‡å‚æ•°å°±å¯ä»¥äº”ã€å¦‚ä½•å¯¹Aå’ŒBè¿›è¡Œåˆå§‹åŒ–å…­ã€å¢åŠ æ—è·¯ä¼šå¢åŠ æ¨ç†æ—¶é—´å—ï¼Ÿä¸ƒã€Rå€¼ä¸ºå¤šå°‘åˆé€‚å…«ã€å¦‚ä½•æ³¨å…¥LoRAä¹ã€LoRAä»£ç å®è·µå­¦æœ¯èµ„æºåŠ é€Ÿæ­¥éª¤1 å¯¼å…¥ç›¸å…³åŒ…æ­¥éª¤2 åŠ è½½æ•°æ®é›†æ­¥éª¤3 æ•°æ®é›†é¢„å¤„ç†æ­¥éª¤4 åˆ›å»ºæ¨¡å‹1ã€PEFT æ­¥éª¤1 é…ç½®æ–‡ä»¶2ã€PEFT æ­¥éª¤2 åˆ›å»ºæ¨¡å‹ æ­¥éª¤5 é…ç½®è®­ç»ƒå‚æ•°æ­¥éª¤6 åˆ›å»ºè®­ç»ƒå™¨æ­¥éª¤7 æ¨¡å‹è®­ç»ƒæ­¥éª¤8 æ¨¡å‹æ¨ç† åã€ä¸»è·¯åˆå¹¶æ—è·¯1ã€åŠ è½½åŸºç¡€æ¨¡å‹2ã€åŠ è½½LoRAæ¨¡å‹3ã€æ¨¡å‹æ¨ç†4ã€æ¨¡å‹åˆå¹¶5ã€æ¨¡å‹æ¨ç†6ã€å®Œæ•´æ¨¡å‹ä¿å­˜ æ€»ç»“ å‰è¨€ åœ¨è‡ªç„¶è¯­è¨€å¤„ç†é¢†åŸŸï¼Œå¤§è¯­è¨€æ¨¡å‹çš„é¢„è®­ç»ƒ-å¾®è°ƒæŠ€æœ¯å·²ç»æˆä¸ºä¸€ç§å¸¸è§çš„æ–¹æ³•ã€‚å…¶ä¸­ï¼ŒLoRAï¼ˆLow-Rank Adaptationï¼‰æ˜¯ä¸€ç§æ–°é¢–çš„å¾®è°ƒæŠ€æœ¯ï¼Œé€šè¿‡å¼•å…¥ä½ç§©çŸ©é˜µæ¥è°ƒæ•´æ¨¡å‹çš„è¡Œä¸ºï¼Œä»¥æé«˜æ¨¡å‹åœ¨æ–°ä»»åŠ¡ä¸Šçš„è¡¨ç°ã€‚æœ¬æ–‡å°†å¯¹LoRAçš„åŸç†ã€ä¼˜åŠ¿ä»¥åŠåº”ç”¨è¿›è¡Œè¯¦ç»†ä»‹ç»ã€‚
ä¸€ã€å¾®è°ƒæŠ€æœ¯åˆ†ç±» å¾®è°ƒæŠ€æœ¯ä¸»è¦åˆ†ä¸ºä»¥ä¸‹å‡ ç±»ï¼š
1ï¼‰å¢åŠ é¢å¤–å‚æ•°ï¼ˆAï¼‰ï¼šè¿™ç§æ–¹æ³•æ˜¯åœ¨åŸæœ‰çš„é¢„è®­ç»ƒæ¨¡å‹çš„åŸºç¡€ä¸Šå¢åŠ ä¸€äº›é¢å¤–çš„å‚æ•°ï¼Œä»¥æ”¹å˜æ¨¡å‹çš„è¡Œä¸ºã€‚
2ï¼‰é€‰å–ä¸€éƒ¨åˆ†å‚æ•°æ›´æ–°ï¼ˆSï¼‰ï¼šè¿™ç§æ–¹æ³•æ˜¯åœ¨å¾®è°ƒè¿‡ç¨‹ä¸­åªæ›´æ–°æ¨¡å‹çš„ä¸€éƒ¨åˆ†å‚æ•°ï¼Œè€Œä¸æ˜¯æ‰€æœ‰å‚æ•°ã€‚è¿™å¯ä»¥å‡å°‘è®¡ç®—é‡ï¼Œæé«˜å¾®è°ƒæ•ˆç‡ã€‚
3ï¼‰å¼•å…¥é‡å‚æ•°åŒ–ï¼ˆRï¼‰ï¼šè¿™ç§æ–¹æ³•æ˜¯åœ¨æ¨¡å‹çš„å‚æ•°ç©ºé—´ä¸­å¼•å…¥ä¸€äº›æ–°çš„å˜åŒ–ï¼Œé€šå¸¸æ˜¯ä¸€äº›çº¿æ€§å˜æ¢æˆ–éçº¿æ€§å˜æ¢ï¼Œä»¥æ”¹å˜æ¨¡å‹çš„è¡Œä¸ºã€‚è¿™ç§æ–¹æ³•å¯ä»¥ä½¿æ¨¡å‹åœ¨æ–°ä»»åŠ¡ä¸Šæœ‰æ›´å¥½çš„è¡¨ç°ã€‚
å¸¸è§çš„å‚æ•°é«˜æ•ˆå¾®è°ƒæŠ€æœ¯æœ‰Prefix Tuningã€Prompt Tuningã€P-Tuningã€Adapter Tuningã€LoRAç­‰
äºŒã€LoRAåŸç† LoRAï¼ˆLow-Rank Adaptation:ä½ç§©çš„é€‚é…å™¨ï¼‰æ˜¯ä¸€ç§æ–°é¢–çš„å¾®è°ƒæŠ€æœ¯ï¼Œå®ƒé€šè¿‡å¼•å…¥ä½ç§©çŸ©é˜µæ¥è°ƒæ•´æ¨¡å‹çš„è¡Œä¸ºï¼Œä»¥æé«˜æ¨¡å‹åœ¨æ–°ä»»åŠ¡ä¸Šçš„è¡¨ç°ã€‚å…·ä½“æ¥è¯´ï¼ŒLoRAåœ¨åŸæœ‰çš„é¢„è®­ç»ƒæ¨¡å‹ä¸­å¢åŠ äº†ä¸¤ä¸ªæ—è·¯çŸ©é˜µAå’ŒBï¼Œè¿™ä¸¤ä¸ªçŸ©é˜µçš„ç»´åº¦è¿œå°äºåŸå§‹æ¨¡å‹çš„è¾“å…¥è¾“å‡ºç»´åº¦ï¼Œä»è€Œå®ç°äº†å‚æ•°çš„é«˜æ•ˆå¾®è°ƒã€‚
ä¸‰ã€åœ¨å“ªå„¿å¢åŠ æ—è·¯ åœ¨åŸæœ‰çš„é¢„è®­ç»ƒæ¨¡å‹ä¸­ï¼Œå¯ä»¥é€‰æ‹©åœ¨ä»»æ„ä¸¤ä¸ªç›¸é‚»å±‚ä¹‹é—´å¢åŠ æ—è·¯çŸ©é˜µAå’ŒBã€‚è¿™æ ·ï¼Œæ¨¡å‹åœ¨å‰å‘ä¼ æ’­è¿‡ç¨‹ä¸­ï¼Œå¯ä»¥é€šè¿‡è¿™ä¸¤ä¸ªæ—è·¯çŸ©é˜µæ¥å¼•å…¥æ–°çš„ä¿¡æ¯ï¼Œä»è€Œæ”¹å˜æ¨¡å‹çš„è¡Œä¸ºã€‚
å››ã€ä¸ºä»€ä¹ˆå¾®è°ƒå°‘é‡å‚æ•°å°±å¯ä»¥ Açš„è¾“å…¥ç»´åº¦å’ŒBçš„è¾“å‡ºç»´åº¦åˆ†åˆ«ä¸åŸå§‹æ¨¡å‹çš„è¾“å…¥è¾“å‡ºç»´åº¦ç›¸åŒï¼Œè€ŒAçš„è¾“å‡ºç»´åº¦å’ŒBçš„è¾“å…¥ç»´åº¦æ˜¯ä¸€ä¸ªè¿œå°äºåŸå§‹æ¨¡å‹è¾“å…¥è¾“å‡ºç»´åº¦çš„å€¼ï¼Œè¿™å°±æ˜¯low-rankçš„ä½“ç°ï¼Œå¯ä»¥æå¤§åœ°å‡å°‘å¾…è®­ç»ƒçš„å‚æ•°
ç§©è¡¨ç¤ºçš„æ˜¯çŸ©é˜µçš„ä¿¡æ¯é‡ï¼Œè¿™é‡Œçš„â€œç§©â€ç‰¹æŒ‡å¼•å…¥çš„æ—è·¯çŸ©é˜µçš„è§„æ¨¡ï¼Œå³å®ƒä»¬çš„è¡Œæ•°å’Œåˆ—æ•°ã€‚
åœ¨LoRAæŠ€æœ¯ä¸­ï¼Œæˆ‘ä»¬é€šè¿‡å¼•å…¥ä½ç§©çŸ©é˜µæ¥è°ƒæ•´é¢„è®­ç»ƒæ¨¡å‹çš„è¡Œä¸ºï¼ŒåŒæ—¶ä¿ç•™å¤§éƒ¨åˆ†åŸæœ‰çš„å‚æ•°ä¸å˜ã€‚è¿™æ ·åšå¯ä»¥åœ¨ä¸ç‰ºç‰²å¤ªå¤šæ€§èƒ½çš„å‰æä¸‹ï¼Œæ˜¾è‘—é™ä½æ¨¡å‹å¾®è°ƒæ—¶çš„è®¡ç®—æˆæœ¬å’Œå†…å­˜éœ€æ±‚ã€‚
é€šä¿—åŒ–è§£é‡Šï¼šâ€œç§©â€:
æƒ³è±¡ä¸€ä¸‹ä½ æœ‰ä¸€ä¸ªå¾ˆå¤§çš„åŒ…è£¹ï¼Œä½ éœ€è¦é€šè¿‡ä¸€ä¸ªå°é—¨æŠŠå®ƒé€å‡ºå»ã€‚ä½†æ˜¯é—¨å¤ªå°äº†ï¼Œä½ å¿…é¡»æŠŠåŒ…è£¹æ‹†æˆå‡ ä¸ªå°åŒ…è£¹æ‰èƒ½é€šè¿‡ã€‚åœ¨è¿™ä¸ªæ¯”å–»ä¸­ï¼Œå¤§åŒ…è£¹å°±åƒæ¨¡å‹çš„æƒé‡çŸ©é˜µï¼Œå°é—¨å°±åƒæˆ‘ä»¬æ–°å¢çš„ä½ç§©çŸ©é˜µï¼Œè€Œâ€œç§©â€å°±æ˜¯è¿™äº›å°åŒ…è£¹çš„æ•°é‡ã€‚åœ¨LoRAä¸­ï¼Œæˆ‘ä»¬é€šè¿‡åˆ›å»ºä¸€äº›å°çš„ï¼ˆä½ç§©ï¼‰çŸ©é˜µæ¥ä¼ é€’ä¿¡æ¯ï¼Œè€Œä¸æ˜¯ä½¿ç”¨åŸå§‹çš„å¤§çŸ©é˜µã€‚è¿™æ ·åšçš„å¥½å¤„æ˜¯æˆ‘ä»¬å¯ä»¥åªå…³æ³¨é‚£äº›æœ€é‡è¦çš„ä¿¡æ¯ï¼Œå¿½ç•¥æ‰ä¸é‡è¦çš„ä¿¡æ¯ï¼Œä»è€Œå‡å°‘è®¡ç®—é‡å’Œå†…å­˜éœ€æ±‚ã€‚
äº”ã€å¦‚ä½•å¯¹Aå’ŒBè¿›è¡Œåˆå§‹åŒ– Aå’ŒBå¦‚ä½•åˆå§‹åŒ–ï¼Ÿ
å¯¹Aé‡‡ç”¨é«˜æ–¯åˆå§‹åŒ–ï¼Œå¯¹Bé‡‡ç”¨é›¶åˆå§‹åŒ–çš„ç›®çš„æ˜¯ï¼Œè®©è®­ç»ƒåˆšå¼€å§‹æ—¶çš„å€¼ä¸º0ï¼Œè¿™æ ·ä¸ä¼šç»™æ¨¡å‹å¸¦æ¥é¢å¤–çš„å™ªå£°ã€‚
å…­ã€å¢åŠ æ—è·¯ä¼šå¢åŠ æ¨ç†æ—¶é—´å—ï¼Ÿ è™½ç„¶å¢åŠ äº†æ—è·¯çŸ©é˜µAå’ŒBï¼Œä½†æ˜¯ç”±äºå®ƒä»¬çš„ç»´åº¦è¿œå°äºåŸå§‹æ¨¡å‹çš„è¾“å…¥è¾“å‡ºç»´åº¦ï¼Œå› æ­¤åœ¨æ¨ç†è¿‡ç¨‹ä¸­ï¼Œè®¡ç®—é‡çš„å¢åŠ æ˜¯éå¸¸æœ‰é™çš„ã€‚
ä¸ƒã€Rå€¼ä¸ºå¤šå°‘åˆé€‚ Rå€¼è¡¨ç¤ºçš„æ˜¯æ—è·¯çŸ©é˜µAå’ŒBçš„ç§©ã€‚ä¸€èˆ¬æ¥è¯´ï¼ŒRå€¼çš„é€‰æ‹©éœ€è¦æ ¹æ®å…·ä½“ä»»åŠ¡å’Œæ¨¡å‹ç»“æ„æ¥ç¡®å®šã€‚åœ¨å®é™…åº”ç”¨ä¸­ï¼Œå¯ä»¥å°è¯•ä¸åŒçš„Rå€¼ï¼Œä»¥æ‰¾åˆ°æœ€ä½³çš„è®¾ç½®ã€‚
å…«ã€å¦‚ä½•æ³¨å…¥LoRA è¦å°†LoRAåº”ç”¨äºç°æœ‰çš„é¢„è®­ç»ƒæ¨¡å‹ä¸­ï¼Œé¦–å…ˆéœ€è¦åœ¨ç›¸é‚»å±‚ä¹‹é—´æ’å…¥æ—è·¯çŸ©é˜µAå’ŒBã€‚ç„¶åï¼Œåœ¨å¾®è°ƒè¿‡ç¨‹ä¸­ï¼Œåªéœ€è¦è°ƒæ•´è¿™ä¸¤ä¸ªæ—è·¯çŸ©é˜µçš„å‚æ•°å³å¯ã€‚è¿™æ ·ï¼Œå°±å¯ä»¥å®ç°æ¨¡å‹è¡Œä¸ºçš„é«˜æ•ˆè°ƒæ•´ã€‚
å¦‚ä¸Šå›¾ä¸­å®šä¹‰ä¸€ä¸ªç®€å•çš„3å±‚çš„ç¥ç»ç½‘ç»œï¼Œåœ¨ç¬¬1å±‚å¢åŠ æ—è·¯åæ•ˆæœå¦‚ä¸‹ï¼š
ä¹ã€LoRAä»£ç å®è·µ PEFTæ–‡æ¡£èµ„æ–™åœ°å€
1ï¼‰æ–‡æ¡£åœ°å€ï¼šhttps://huggingface.co/docs/peft/index">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-05-07T09:17:52+08:00">
    <meta property="article:modified_time" content="2024-05-07T09:17:52+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="ç¼–ç¨‹å­¦ä¹ è€…" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">ç¼–ç¨‹å­¦ä¹ è€…</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">AIå¤§æ¨¡å‹æ¢ç´¢ä¹‹è·¯-è®­ç»ƒç¯‡16ï¼šå¤§è¯­è¨€æ¨¡å‹é¢„è®­ç»ƒ-å¾®è°ƒæŠ€æœ¯ä¹‹LoRA</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-tomorrow-night">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="_2"></a>ç³»åˆ—ç¯‡ç« ğŸ’¥</h2> 
<p><a href="https://xundaomalu.blog.csdn.net/article/details/138107946" rel="nofollow">AIå¤§æ¨¡å‹æ¢ç´¢ä¹‹è·¯-è®­ç»ƒç¯‡1ï¼šå¤§è¯­è¨€æ¨¡å‹å¾®è°ƒåŸºç¡€è®¤çŸ¥</a><br> <a href="https://xundaomalu.blog.csdn.net/article/details/138143923" rel="nofollow">AIå¤§æ¨¡å‹æ¢ç´¢ä¹‹è·¯-è®­ç»ƒç¯‡2ï¼šå¤§è¯­è¨€æ¨¡å‹é¢„è®­ç»ƒåŸºç¡€è®¤çŸ¥</a><br> <a href="https://xundaomalu.blog.csdn.net/article/details/138161057" rel="nofollow">AIå¤§æ¨¡å‹æ¢ç´¢ä¹‹è·¯-è®­ç»ƒç¯‡3ï¼šå¤§è¯­è¨€æ¨¡å‹å…¨æ™¯è§£è¯»</a><br> <a href="https://xundaomalu.blog.csdn.net/article/details/138205204" rel="nofollow">AIå¤§æ¨¡å‹æ¢ç´¢ä¹‹è·¯-è®­ç»ƒç¯‡4ï¼šå¤§è¯­è¨€æ¨¡å‹è®­ç»ƒæ•°æ®é›†æ¦‚è§ˆ</a><br> <a href="https://xundaomalu.blog.csdn.net/article/details/138225299" rel="nofollow">AIå¤§æ¨¡å‹æ¢ç´¢ä¹‹è·¯-è®­ç»ƒç¯‡5ï¼šå¤§è¯­è¨€æ¨¡å‹é¢„è®­ç»ƒæ•°æ®å‡†å¤‡-è¯å…ƒåŒ–</a><br> <a href="https://xundaomalu.blog.csdn.net/article/details/138267915" rel="nofollow">AIå¤§æ¨¡å‹æ¢ç´¢ä¹‹è·¯-è®­ç»ƒç¯‡6ï¼šå¤§è¯­è¨€æ¨¡å‹é¢„è®­ç»ƒæ•°æ®å‡†å¤‡-é¢„å¤„ç†</a><br> <a href="https://xundaomalu.blog.csdn.net/article/details/138294519" rel="nofollow">AIå¤§æ¨¡å‹æ¢ç´¢ä¹‹è·¯-è®­ç»ƒç¯‡7ï¼šå¤§è¯­è¨€æ¨¡å‹Transformeråº“ä¹‹HuggingFaceä»‹ç»</a><br> <a href="https://xundaomalu.blog.csdn.net/article/details/138348834" rel="nofollow">AIå¤§æ¨¡å‹æ¢ç´¢ä¹‹è·¯-è®­ç»ƒç¯‡8ï¼šå¤§è¯­è¨€æ¨¡å‹Transformeråº“-é¢„è®­ç»ƒæµç¨‹ç¼–ç ä½“éªŒ</a><br> <a href="https://blog.csdn.net/xiaobing259/article/details/138373677">AIå¤§æ¨¡å‹æ¢ç´¢ä¹‹è·¯-è®­ç»ƒç¯‡9ï¼šå¤§è¯­è¨€æ¨¡å‹Transformeråº“-Pipelineç»„ä»¶å®è·µ</a><br> <a href="https://xundaomalu.blog.csdn.net/article/details/138391592" rel="nofollow">AIå¤§æ¨¡å‹æ¢ç´¢ä¹‹è·¯-è®­ç»ƒç¯‡10ï¼šå¤§è¯­è¨€æ¨¡å‹Transformeråº“-Tokenizerç»„ä»¶å®è·µ</a><br> <a href="https://blog.csdn.net/xiaobing259/article/details/138424867">AIå¤§æ¨¡å‹æ¢ç´¢ä¹‹è·¯-è®­ç»ƒç¯‡11ï¼šå¤§è¯­è¨€æ¨¡å‹Transformeråº“-Modelç»„ä»¶å®è·µ</a><br> <a href="https://xundaomalu.blog.csdn.net/article/details/138426216" rel="nofollow">AIå¤§æ¨¡å‹æ¢ç´¢ä¹‹è·¯-è®­ç»ƒç¯‡12ï¼šè¯­è¨€æ¨¡å‹Transformeråº“-Datasetsç»„ä»¶å®è·µ</a><br> <a href="https://xundaomalu.blog.csdn.net/article/details/138448172" rel="nofollow">AIå¤§æ¨¡å‹æ¢ç´¢ä¹‹è·¯-è®­ç»ƒç¯‡13ï¼šå¤§è¯­è¨€æ¨¡å‹Transformeråº“-Evaluateç»„ä»¶å®è·µ</a><br> <a href="https://xundaomalu.blog.csdn.net/article/details/138448511" rel="nofollow">AIå¤§æ¨¡å‹æ¢ç´¢ä¹‹è·¯-è®­ç»ƒç¯‡14ï¼šå¤§è¯­è¨€æ¨¡å‹Transformeråº“-Trainerç»„ä»¶å®è·µ</a><br> <a href="https://xundaomalu.blog.csdn.net/article/details/138472105" rel="nofollow">AIå¤§æ¨¡å‹æ¢ç´¢ä¹‹è·¯-è®­ç»ƒç¯‡15ï¼šå¤§è¯­è¨€æ¨¡å‹é¢„è®­ç»ƒä¹‹å…¨é‡å‚æ•°å¾®è°ƒ</a></p> 
<hr> 
<p></p> 
<div class="toc"> 
 <h4>ç›®å½•</h4> 
 <ul><li><a href="#_2" rel="nofollow">ç³»åˆ—ç¯‡ç« ğŸ’¥</a></li><li><a href="#_23" rel="nofollow">å‰è¨€</a></li><li><a href="#_25" rel="nofollow">ä¸€ã€å¾®è°ƒæŠ€æœ¯åˆ†ç±»</a></li><li><a href="#LoRA_35" rel="nofollow">äºŒã€LoRAåŸç†</a></li><li><a href="#_39" rel="nofollow">ä¸‰ã€åœ¨å“ªå„¿å¢åŠ æ—è·¯</a></li><li><a href="#_44" rel="nofollow">å››ã€ä¸ºä»€ä¹ˆå¾®è°ƒå°‘é‡å‚æ•°å°±å¯ä»¥</a></li><li><a href="#AB_58" rel="nofollow">äº”ã€å¦‚ä½•å¯¹Aå’ŒBè¿›è¡Œåˆå§‹åŒ–</a></li><li><a href="#_64" rel="nofollow">å…­ã€å¢åŠ æ—è·¯ä¼šå¢åŠ æ¨ç†æ—¶é—´å—ï¼Ÿ</a></li><li><a href="#R_69" rel="nofollow">ä¸ƒã€Rå€¼ä¸ºå¤šå°‘åˆé€‚</a></li><li><a href="#LoRA_73" rel="nofollow">å…«ã€å¦‚ä½•æ³¨å…¥LoRA</a></li><li><a href="#LoRA_80" rel="nofollow">ä¹ã€LoRAä»£ç å®è·µ</a></li><li><ul><li><a href="#_93" rel="nofollow">å­¦æœ¯èµ„æºåŠ é€Ÿ</a></li><li><a href="#1__108" rel="nofollow">æ­¥éª¤1 å¯¼å…¥ç›¸å…³åŒ…</a></li><li><a href="#2__117" rel="nofollow">æ­¥éª¤2 åŠ è½½æ•°æ®é›†</a></li><li><a href="#3__147" rel="nofollow">æ­¥éª¤3 æ•°æ®é›†é¢„å¤„ç†</a></li><li><a href="#4__215" rel="nofollow">æ­¥éª¤4 åˆ›å»ºæ¨¡å‹</a></li><li><ul><li><a href="#1PEFT_1__575" rel="nofollow">1ã€PEFT æ­¥éª¤1 é…ç½®æ–‡ä»¶</a></li><li><a href="#2PEFT_2__586" rel="nofollow">2ã€PEFT æ­¥éª¤2 åˆ›å»ºæ¨¡å‹</a></li></ul> 
   </li><li><a href="#5__665" rel="nofollow">æ­¥éª¤5 é…ç½®è®­ç»ƒå‚æ•°</a></li><li><a href="#6__679" rel="nofollow">æ­¥éª¤6 åˆ›å»ºè®­ç»ƒå™¨</a></li><li><a href="#7__691" rel="nofollow">æ­¥éª¤7 æ¨¡å‹è®­ç»ƒ</a></li><li><a href="#8__699" rel="nofollow">æ­¥éª¤8 æ¨¡å‹æ¨ç†</a></li></ul> 
  </li><li><a href="#_717" rel="nofollow">åã€ä¸»è·¯åˆå¹¶æ—è·¯</a></li><li><ul><li><a href="#1_718" rel="nofollow">1ã€åŠ è½½åŸºç¡€æ¨¡å‹</a></li><li><a href="#2LoRA_729" rel="nofollow">2ã€åŠ è½½LoRAæ¨¡å‹</a></li><li><a href="#3_794" rel="nofollow">3ã€æ¨¡å‹æ¨ç†</a></li><li><a href="#4_806" rel="nofollow">4ã€æ¨¡å‹åˆå¹¶</a></li><li><a href="#5_841" rel="nofollow">5ã€æ¨¡å‹æ¨ç†</a></li><li><a href="#6_851" rel="nofollow">6ã€å®Œæ•´æ¨¡å‹ä¿å­˜</a></li></ul> 
  </li><li><a href="#_858" rel="nofollow">æ€»ç»“</a></li></ul> 
</div> 
<p></p> 
<hr> 
<h2><a id="_23"></a>å‰è¨€</h2> 
<p>åœ¨è‡ªç„¶è¯­è¨€å¤„ç†é¢†åŸŸï¼Œå¤§è¯­è¨€æ¨¡å‹çš„é¢„è®­ç»ƒ-å¾®è°ƒæŠ€æœ¯å·²ç»æˆä¸ºä¸€ç§å¸¸è§çš„æ–¹æ³•ã€‚å…¶ä¸­ï¼ŒLoRAï¼ˆLow-Rank Adaptationï¼‰æ˜¯ä¸€ç§æ–°é¢–çš„å¾®è°ƒæŠ€æœ¯ï¼Œé€šè¿‡å¼•å…¥ä½ç§©çŸ©é˜µæ¥è°ƒæ•´æ¨¡å‹çš„è¡Œä¸ºï¼Œä»¥æé«˜æ¨¡å‹åœ¨æ–°ä»»åŠ¡ä¸Šçš„è¡¨ç°ã€‚æœ¬æ–‡å°†å¯¹LoRAçš„åŸç†ã€ä¼˜åŠ¿ä»¥åŠåº”ç”¨è¿›è¡Œè¯¦ç»†ä»‹ç»ã€‚</p> 
<h2><a id="_25"></a>ä¸€ã€å¾®è°ƒæŠ€æœ¯åˆ†ç±»</h2> 
<p>å¾®è°ƒæŠ€æœ¯ä¸»è¦åˆ†ä¸ºä»¥ä¸‹å‡ ç±»ï¼š<br> <strong>1ï¼‰å¢åŠ é¢å¤–å‚æ•°ï¼ˆA</strong>ï¼‰ï¼šè¿™ç§æ–¹æ³•æ˜¯åœ¨åŸæœ‰çš„é¢„è®­ç»ƒæ¨¡å‹çš„åŸºç¡€ä¸Šå¢åŠ ä¸€äº›é¢å¤–çš„å‚æ•°ï¼Œä»¥æ”¹å˜æ¨¡å‹çš„è¡Œä¸ºã€‚<br> <strong>2ï¼‰é€‰å–ä¸€éƒ¨åˆ†å‚æ•°æ›´æ–°ï¼ˆSï¼‰</strong>ï¼šè¿™ç§æ–¹æ³•æ˜¯åœ¨å¾®è°ƒè¿‡ç¨‹ä¸­åªæ›´æ–°æ¨¡å‹çš„ä¸€éƒ¨åˆ†å‚æ•°ï¼Œè€Œä¸æ˜¯æ‰€æœ‰å‚æ•°ã€‚è¿™å¯ä»¥å‡å°‘è®¡ç®—é‡ï¼Œæé«˜å¾®è°ƒæ•ˆç‡ã€‚<br> <strong>3ï¼‰å¼•å…¥é‡å‚æ•°åŒ–ï¼ˆRï¼‰</strong>ï¼šè¿™ç§æ–¹æ³•æ˜¯åœ¨æ¨¡å‹çš„å‚æ•°ç©ºé—´ä¸­å¼•å…¥ä¸€äº›æ–°çš„å˜åŒ–ï¼Œé€šå¸¸æ˜¯ä¸€äº›çº¿æ€§å˜æ¢æˆ–éçº¿æ€§å˜æ¢ï¼Œä»¥æ”¹å˜æ¨¡å‹çš„è¡Œä¸ºã€‚è¿™ç§æ–¹æ³•å¯ä»¥ä½¿æ¨¡å‹åœ¨æ–°ä»»åŠ¡ä¸Šæœ‰æ›´å¥½çš„è¡¨ç°ã€‚</p> 
<blockquote> 
 <p>å¸¸è§çš„å‚æ•°é«˜æ•ˆå¾®è°ƒæŠ€æœ¯æœ‰Prefix Tuningã€Prompt Tuningã€P-Tuningã€Adapter Tuningã€LoRAç­‰<br> <img src="https://images2.imgbox.com/a3/51/6XTc00l0_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
</blockquote> 
<h2><a id="LoRA_35"></a>äºŒã€LoRAåŸç†</h2> 
<p>LoRAï¼ˆLow-Rank Adaptation:ä½ç§©çš„é€‚é…å™¨ï¼‰æ˜¯ä¸€ç§æ–°é¢–çš„å¾®è°ƒæŠ€æœ¯ï¼Œå®ƒé€šè¿‡å¼•å…¥ä½ç§©çŸ©é˜µæ¥è°ƒæ•´æ¨¡å‹çš„è¡Œä¸ºï¼Œä»¥æé«˜æ¨¡å‹åœ¨æ–°ä»»åŠ¡ä¸Šçš„è¡¨ç°ã€‚å…·ä½“æ¥è¯´ï¼ŒLoRAåœ¨åŸæœ‰çš„é¢„è®­ç»ƒæ¨¡å‹ä¸­å¢åŠ äº†ä¸¤ä¸ªæ—è·¯çŸ©é˜µAå’ŒBï¼Œè¿™ä¸¤ä¸ªçŸ©é˜µçš„ç»´åº¦è¿œå°äºåŸå§‹æ¨¡å‹çš„è¾“å…¥è¾“å‡ºç»´åº¦ï¼Œä»è€Œå®ç°äº†å‚æ•°çš„é«˜æ•ˆå¾®è°ƒã€‚<br> <img src="https://images2.imgbox.com/70/79/1OWOrCDO_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<h2><a id="_39"></a>ä¸‰ã€åœ¨å“ªå„¿å¢åŠ æ—è·¯</h2> 
<p>åœ¨åŸæœ‰çš„é¢„è®­ç»ƒæ¨¡å‹ä¸­ï¼Œå¯ä»¥é€‰æ‹©åœ¨ä»»æ„ä¸¤ä¸ªç›¸é‚»å±‚ä¹‹é—´å¢åŠ æ—è·¯çŸ©é˜µAå’ŒBã€‚è¿™æ ·ï¼Œæ¨¡å‹åœ¨å‰å‘ä¼ æ’­è¿‡ç¨‹ä¸­ï¼Œå¯ä»¥é€šè¿‡è¿™ä¸¤ä¸ªæ—è·¯çŸ©é˜µæ¥å¼•å…¥æ–°çš„ä¿¡æ¯ï¼Œä»è€Œæ”¹å˜æ¨¡å‹çš„è¡Œä¸ºã€‚<br> <img src="https://images2.imgbox.com/8b/d5/twoiMw7I_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<h2><a id="_44"></a>å››ã€ä¸ºä»€ä¹ˆå¾®è°ƒå°‘é‡å‚æ•°å°±å¯ä»¥</h2> 
<p><img src="https://images2.imgbox.com/6b/47/jETLyFDa_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"><br> Açš„è¾“å…¥ç»´åº¦å’ŒBçš„è¾“å‡ºç»´åº¦åˆ†åˆ«ä¸åŸå§‹æ¨¡å‹çš„è¾“å…¥è¾“å‡ºç»´åº¦ç›¸åŒï¼Œè€ŒAçš„è¾“å‡ºç»´åº¦å’ŒBçš„è¾“å…¥ç»´åº¦æ˜¯ä¸€ä¸ªè¿œå°äºåŸå§‹æ¨¡å‹è¾“å…¥è¾“å‡ºç»´åº¦çš„å€¼ï¼Œè¿™å°±æ˜¯low-rankçš„ä½“ç°ï¼Œå¯ä»¥æå¤§åœ°å‡å°‘å¾…è®­ç»ƒçš„å‚æ•°<br> <img src="https://images2.imgbox.com/4d/25/8bT2Tz9T_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<p><strong>ç§©</strong>è¡¨ç¤ºçš„æ˜¯çŸ©é˜µçš„ä¿¡æ¯é‡ï¼Œè¿™é‡Œçš„â€œ<strong>ç§©</strong>â€ç‰¹æŒ‡å¼•å…¥çš„æ—è·¯çŸ©é˜µçš„è§„æ¨¡ï¼Œå³å®ƒä»¬çš„è¡Œæ•°å’Œåˆ—æ•°ã€‚<br> <img src="https://images2.imgbox.com/dc/0c/TfXHy883_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<p>åœ¨LoRAæŠ€æœ¯ä¸­ï¼Œæˆ‘ä»¬é€šè¿‡å¼•å…¥ä½ç§©çŸ©é˜µæ¥è°ƒæ•´é¢„è®­ç»ƒæ¨¡å‹çš„è¡Œä¸ºï¼ŒåŒæ—¶ä¿ç•™å¤§éƒ¨åˆ†åŸæœ‰çš„å‚æ•°ä¸å˜ã€‚è¿™æ ·åšå¯ä»¥åœ¨ä¸ç‰ºç‰²å¤ªå¤šæ€§èƒ½çš„å‰æä¸‹ï¼Œæ˜¾è‘—é™ä½æ¨¡å‹å¾®è°ƒæ—¶çš„è®¡ç®—æˆæœ¬å’Œå†…å­˜éœ€æ±‚ã€‚</p> 
<blockquote> 
 <p><strong>é€šä¿—åŒ–è§£é‡Šï¼šâ€œç§©â€</strong>:<br> æƒ³è±¡ä¸€ä¸‹ä½ æœ‰ä¸€ä¸ªå¾ˆå¤§çš„åŒ…è£¹ï¼Œä½ éœ€è¦é€šè¿‡ä¸€ä¸ªå°é—¨æŠŠå®ƒé€å‡ºå»ã€‚ä½†æ˜¯é—¨å¤ªå°äº†ï¼Œä½ å¿…é¡»æŠŠåŒ…è£¹æ‹†æˆå‡ ä¸ªå°åŒ…è£¹æ‰èƒ½é€šè¿‡ã€‚åœ¨è¿™ä¸ªæ¯”å–»ä¸­ï¼Œå¤§åŒ…è£¹å°±åƒæ¨¡å‹çš„æƒé‡çŸ©é˜µï¼Œå°é—¨å°±åƒæˆ‘ä»¬æ–°å¢çš„ä½ç§©çŸ©é˜µï¼Œè€Œâ€œç§©â€å°±æ˜¯è¿™äº›å°åŒ…è£¹çš„æ•°é‡ã€‚åœ¨LoRAä¸­ï¼Œæˆ‘ä»¬é€šè¿‡åˆ›å»ºä¸€äº›å°çš„ï¼ˆä½ç§©ï¼‰çŸ©é˜µæ¥ä¼ é€’ä¿¡æ¯ï¼Œè€Œä¸æ˜¯ä½¿ç”¨åŸå§‹çš„å¤§çŸ©é˜µã€‚è¿™æ ·åšçš„å¥½å¤„æ˜¯æˆ‘ä»¬å¯ä»¥åªå…³æ³¨é‚£äº›æœ€é‡è¦çš„ä¿¡æ¯ï¼Œå¿½ç•¥æ‰ä¸é‡è¦çš„ä¿¡æ¯ï¼Œä»è€Œå‡å°‘è®¡ç®—é‡å’Œå†…å­˜éœ€æ±‚ã€‚</p> 
</blockquote> 
<h2><a id="AB_58"></a>äº”ã€å¦‚ä½•å¯¹Aå’ŒBè¿›è¡Œåˆå§‹åŒ–</h2> 
<p>Aå’ŒBå¦‚ä½•åˆå§‹åŒ–ï¼Ÿ<br> å¯¹Aé‡‡ç”¨é«˜æ–¯åˆå§‹åŒ–ï¼Œå¯¹Bé‡‡ç”¨é›¶åˆå§‹åŒ–çš„ç›®çš„æ˜¯ï¼Œè®©è®­ç»ƒåˆšå¼€å§‹æ—¶çš„å€¼ä¸º0ï¼Œè¿™æ ·ä¸ä¼šç»™æ¨¡å‹å¸¦æ¥é¢å¤–çš„å™ªå£°ã€‚</p> 
<p><img src="https://images2.imgbox.com/10/d3/43d4w64Y_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<h2><a id="_64"></a>å…­ã€å¢åŠ æ—è·¯ä¼šå¢åŠ æ¨ç†æ—¶é—´å—ï¼Ÿ</h2> 
<p>è™½ç„¶å¢åŠ äº†æ—è·¯çŸ©é˜µAå’ŒBï¼Œä½†æ˜¯ç”±äºå®ƒä»¬çš„ç»´åº¦è¿œå°äºåŸå§‹æ¨¡å‹çš„è¾“å…¥è¾“å‡ºç»´åº¦ï¼Œå› æ­¤åœ¨æ¨ç†è¿‡ç¨‹ä¸­ï¼Œè®¡ç®—é‡çš„å¢åŠ æ˜¯éå¸¸æœ‰é™çš„ã€‚<br> <img src="https://images2.imgbox.com/fa/bb/Fgo5KfS5_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<h2><a id="R_69"></a>ä¸ƒã€Rå€¼ä¸ºå¤šå°‘åˆé€‚</h2> 
<p>Rå€¼è¡¨ç¤ºçš„æ˜¯æ—è·¯çŸ©é˜µAå’ŒBçš„ç§©ã€‚ä¸€èˆ¬æ¥è¯´ï¼ŒRå€¼çš„é€‰æ‹©éœ€è¦æ ¹æ®å…·ä½“ä»»åŠ¡å’Œæ¨¡å‹ç»“æ„æ¥ç¡®å®šã€‚åœ¨å®é™…åº”ç”¨ä¸­ï¼Œå¯ä»¥å°è¯•ä¸åŒçš„Rå€¼ï¼Œä»¥æ‰¾åˆ°æœ€ä½³çš„è®¾ç½®ã€‚</p> 
<p><img src="https://images2.imgbox.com/12/70/piGzvdBW_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<h2><a id="LoRA_73"></a>å…«ã€å¦‚ä½•æ³¨å…¥LoRA</h2> 
<p>è¦å°†LoRAåº”ç”¨äºç°æœ‰çš„é¢„è®­ç»ƒæ¨¡å‹ä¸­ï¼Œé¦–å…ˆéœ€è¦åœ¨ç›¸é‚»å±‚ä¹‹é—´æ’å…¥æ—è·¯çŸ©é˜µAå’ŒBã€‚ç„¶åï¼Œåœ¨å¾®è°ƒè¿‡ç¨‹ä¸­ï¼Œåªéœ€è¦è°ƒæ•´è¿™ä¸¤ä¸ªæ—è·¯çŸ©é˜µçš„å‚æ•°å³å¯ã€‚è¿™æ ·ï¼Œå°±å¯ä»¥å®ç°æ¨¡å‹è¡Œä¸ºçš„é«˜æ•ˆè°ƒæ•´ã€‚<br> <img src="https://images2.imgbox.com/69/aa/PH5GP0yD_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<p>å¦‚ä¸Šå›¾ä¸­å®šä¹‰ä¸€ä¸ªç®€å•çš„3å±‚çš„ç¥ç»ç½‘ç»œï¼Œåœ¨ç¬¬1å±‚å¢åŠ æ—è·¯åæ•ˆæœå¦‚ä¸‹ï¼š<br> <img src="https://images2.imgbox.com/a5/0c/DoFz7WIB_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<h2><a id="LoRA_80"></a>ä¹ã€LoRAä»£ç å®è·µ</h2> 
<p>PEFTæ–‡æ¡£èµ„æ–™åœ°å€<br> 1ï¼‰æ–‡æ¡£åœ°å€ï¼šhttps://huggingface.co/docs/peft/index<br> 2ï¼‰Githubåœ°å€ï¼šhttps://github.com/huggingface/peft<br> <a href="https://huggingface.co/docs/peft/index" rel="nofollow">PEFT</a>ï¼ˆParameter-Efficient Fine-Tuningï¼‰åº“æ˜¯ä¸€ä¸ªç”¨äºå‚æ•°é«˜æ•ˆå¾®è°ƒé¢„è®­ç»ƒè¯­è¨€æ¨¡å‹çš„åº“ï¼Œæ—¨åœ¨é™ä½å¤§è§„æ¨¡æ¨¡å‹å¾®è°ƒçš„è®¡ç®—å’Œå­˜å‚¨æˆæœ¬ã€‚<br> PEFTåº“çš„æ ¸å¿ƒä¼˜åŠ¿åœ¨äºå®ƒèƒ½å¤Ÿä»…é€šè¿‡å¾®è°ƒå°‘é‡é¢å¤–æ¨¡å‹å‚æ•°æ¥é€‚åº”å„ç§ä¸‹æ¸¸ä»»åŠ¡ï¼Œé¿å…äº†å¯¹æ•´ä¸ªå¤§æ¨¡å‹å‚æ•°è¿›è¡Œå¾®è°ƒçš„éœ€æ±‚ã€‚è¿™ç§æ–¹æ³•ä¸ä»…é™ä½äº†èµ„æºæ¶ˆè€—ï¼Œè€Œä¸”åœ¨å¾ˆå¤šæƒ…å†µä¸‹èƒ½è¾¾åˆ°ä¸å®Œå…¨å¾®è°ƒç›¸å½“çš„æ€§èƒ½<br> <img src="https://images2.imgbox.com/64/d0/B03xau7r_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<p>PEFTæŠ€æœ¯çš„æ”¯æŒï¼š<br> <img src="https://images2.imgbox.com/91/d5/7ETPRfwU_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<h3><a id="_93"></a>å­¦æœ¯èµ„æºåŠ é€Ÿ</h3> 
<p>æ–¹ä¾¿ä»huggingfaceä¸‹è½½æ¨¡å‹ï¼Œè¿™äº‘å¹³å°<a href="https://www.autodl.com/" rel="nofollow">autodl</a>æä¾›çš„ï¼Œä»…é€‚ç”¨äºautodlã€‚</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> subprocess
<span class="token keyword">import</span> os

result <span class="token operator">=</span> subprocess<span class="token punctuation">.</span>run<span class="token punctuation">(</span><span class="token string">'bash -c "source /etc/network_turbo &amp;&amp; env | grep proxy"'</span><span class="token punctuation">,</span> shell<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> capture_output<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> text<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
output <span class="token operator">=</span> result<span class="token punctuation">.</span>stdout
<span class="token keyword">for</span> line <span class="token keyword">in</span> output<span class="token punctuation">.</span>splitlines<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">if</span> <span class="token string">'='</span> <span class="token keyword">in</span> line<span class="token punctuation">:</span>
        var<span class="token punctuation">,</span> value <span class="token operator">=</span> line<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'='</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
        os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span>var<span class="token punctuation">]</span> <span class="token operator">=</span> value
</code></pre> 
<h3><a id="1__108"></a>æ­¥éª¤1 å¯¼å…¥ç›¸å…³åŒ…</h3> 
<p>å¼€å§‹ä¹‹å‰ï¼Œæˆ‘ä»¬éœ€è¦å¯¼å…¥é€‚ç”¨äºæ¨¡å‹è®­ç»ƒå’Œæ¨ç†çš„å¿…è¦åº“ï¼Œå¦‚transformersã€‚</p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> datasets <span class="token keyword">import</span> Dataset
<span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoTokenizer<span class="token punctuation">,</span> AutoModelForCausalLM<span class="token punctuation">,</span> DataCollatorForSeq2Seq<span class="token punctuation">,</span> TrainingArguments<span class="token punctuation">,</span> Trainer
</code></pre> 
<h3><a id="2__117"></a>æ­¥éª¤2 åŠ è½½æ•°æ®é›†</h3> 
<p>ä½¿ç”¨é€‚å½“çš„æ•°æ®åŠ è½½å™¨ï¼Œä¾‹å¦‚datasetsåº“ï¼Œæ¥åŠ è½½é¢„å¤„ç†è¿‡çš„æŒ‡ä»¤éµå¾ªæ€§ä»»åŠ¡æ•°æ®é›†ã€‚</p> 
<pre><code class="prism language-python">ds <span class="token operator">=</span> Dataset<span class="token punctuation">.</span>load_from_disk<span class="token punctuation">(</span><span class="token string">"/root/tuning/lesson01/data/alpaca_data_zh/"</span><span class="token punctuation">)</span>
ds
</code></pre> 
<p>è¾“å‡º</p> 
<pre><code class="prism language-python">Dataset<span class="token punctuation">(</span><span class="token punctuation">{<!-- --></span>
    features<span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'output'</span><span class="token punctuation">,</span> <span class="token string">'input'</span><span class="token punctuation">,</span> <span class="token string">'instruction'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    num_rows<span class="token punctuation">:</span> <span class="token number">26858</span>
<span class="token punctuation">}</span><span class="token punctuation">)</span>
</code></pre> 
<p>æ•°æ®æŸ¥çœ‹</p> 
<pre><code class="prism language-python">ds<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">1</span><span class="token punctuation">]</span>
</code></pre> 
<p>è¾“å‡º</p> 
<pre><code class="prism language-python"><span class="token punctuation">{<!-- --></span><span class="token string">'output'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'ä»¥ä¸‹æ˜¯ä¿æŒå¥åº·çš„ä¸‰ä¸ªæç¤ºï¼š\n\n1. ä¿æŒèº«ä½“æ´»åŠ¨ã€‚æ¯å¤©åšé€‚å½“çš„èº«ä½“è¿åŠ¨ï¼Œå¦‚æ•£æ­¥ã€è·‘æ­¥æˆ–æ¸¸æ³³ï¼Œèƒ½ä¿ƒè¿›å¿ƒè¡€ç®¡å¥åº·ï¼Œå¢å¼ºè‚Œè‚‰åŠ›é‡ï¼Œå¹¶æœ‰åŠ©äºå‡å°‘ä½“é‡ã€‚\n\n2. å‡è¡¡é¥®é£Ÿã€‚æ¯å¤©é£Ÿç”¨æ–°é²œçš„è”¬èœã€æ°´æœã€å…¨è°·ç‰©å’Œè„‚è‚ªå«é‡ä½çš„è›‹ç™½è´¨é£Ÿç‰©ï¼Œé¿å…é«˜ç³–ã€é«˜è„‚è‚ªå’ŒåŠ å·¥é£Ÿå“ï¼Œä»¥ä¿æŒå¥åº·çš„é¥®é£Ÿä¹ æƒ¯ã€‚\n\n3. ç¡çœ å……è¶³ã€‚ç¡çœ å¯¹äººä½“å¥åº·è‡³å…³é‡è¦ï¼Œæˆå¹´äººæ¯å¤©åº”ä¿è¯ 7-8 å°æ—¶çš„ç¡çœ ã€‚è‰¯å¥½çš„ç¡çœ æœ‰åŠ©äºå‡è½»å‹åŠ›ï¼Œä¿ƒè¿›èº«ä½“æ¢å¤ï¼Œå¹¶æé«˜æ³¨æ„åŠ›å’Œè®°å¿†åŠ›ã€‚'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
 <span class="token string">'input'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">''</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
 <span class="token string">'instruction'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'ä¿æŒå¥åº·çš„ä¸‰ä¸ªæç¤ºã€‚'</span><span class="token punctuation">]</span><span class="token punctuation">}</span>
</code></pre> 
<h3><a id="3__147"></a>æ­¥éª¤3 æ•°æ®é›†é¢„å¤„ç†</h3> 
<p>åˆ©ç”¨é¢„è®­ç»ƒæ¨¡å‹çš„åˆ†è¯å™¨ï¼ˆTokenizerï¼‰å¯¹åŸå§‹æ–‡æœ¬è¿›è¡Œç¼–ç ï¼Œå¹¶ç”Ÿæˆç›¸åº”çš„è¾“å…¥IDã€æ³¨æ„åŠ›æ©ç å’Œæ ‡ç­¾ã€‚<br> 1ï¼‰è·å–åˆ†è¯å™¨</p> 
<pre><code class="prism language-python">tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"Langboat/bloom-1b4-zh"</span><span class="token punctuation">)</span>
tokenizer
</code></pre> 
<p><img src="https://images2.imgbox.com/44/50/3Nxbw6uo_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<p>è¾“å‡ºï¼š</p> 
<pre><code class="prism language-python">BloomTokenizerFast<span class="token punctuation">(</span>name_or_path<span class="token operator">=</span><span class="token string">'Langboat/bloom-1b4-zh'</span><span class="token punctuation">,</span> vocab_size<span class="token operator">=</span><span class="token number">46145</span><span class="token punctuation">,</span> model_max_length<span class="token operator">=</span><span class="token number">1000000000000000019884624838656</span><span class="token punctuation">,</span> is_fast<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> padding_side<span class="token operator">=</span><span class="token string">'left'</span><span class="token punctuation">,</span> truncation_side<span class="token operator">=</span><span class="token string">'right'</span><span class="token punctuation">,</span> special_tokens<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token string">'bos_token'</span><span class="token punctuation">:</span> <span class="token string">'&lt;s&gt;'</span><span class="token punctuation">,</span> <span class="token string">'eos_token'</span><span class="token punctuation">:</span> <span class="token string">'&lt;/s&gt;'</span><span class="token punctuation">,</span> <span class="token string">'unk_token'</span><span class="token punctuation">:</span> <span class="token string">'&lt;unk&gt;'</span><span class="token punctuation">,</span> <span class="token string">'pad_token'</span><span class="token punctuation">:</span> <span class="token string">'&lt;pad&gt;'</span><span class="token punctuation">}</span><span class="token punctuation">,</span> clean_up_tokenization_spaces<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  added_tokens_decoder<span class="token operator">=</span><span class="token punctuation">{<!-- --></span>
	<span class="token number">0</span><span class="token punctuation">:</span> AddedToken<span class="token punctuation">(</span><span class="token string">"&lt;unk&gt;"</span><span class="token punctuation">,</span> rstrip<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> lstrip<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> single_word<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> normalized<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> special<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
	<span class="token number">1</span><span class="token punctuation">:</span> AddedToken<span class="token punctuation">(</span><span class="token string">"&lt;s&gt;"</span><span class="token punctuation">,</span> rstrip<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> lstrip<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> single_word<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> normalized<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> special<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
	<span class="token number">2</span><span class="token punctuation">:</span> AddedToken<span class="token punctuation">(</span><span class="token string">"&lt;/s&gt;"</span><span class="token punctuation">,</span> rstrip<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> lstrip<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> single_word<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> normalized<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> special<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
	<span class="token number">3</span><span class="token punctuation">:</span> AddedToken<span class="token punctuation">(</span><span class="token string">"&lt;pad&gt;"</span><span class="token punctuation">,</span> rstrip<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> lstrip<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> single_word<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> normalized<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> special<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token punctuation">}</span>
</code></pre> 
<p>2ï¼‰å®šä¹‰æ•°æ®å¤„ç†å‡½æ•°</p> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">process_func</span><span class="token punctuation">(</span>example<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># è®¾ç½®æœ€å¤§é•¿åº¦ä¸º256</span>
    MAX_LENGTH <span class="token operator">=</span> <span class="token number">256</span>
    <span class="token comment"># åˆå§‹åŒ–è¾“å…¥IDã€æ³¨æ„åŠ›æ©ç å’Œæ ‡ç­¾åˆ—è¡¨</span>
    input_ids<span class="token punctuation">,</span> attention_mask<span class="token punctuation">,</span> labels <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token comment"># å¯¹æŒ‡ä»¤å’Œè¾“å…¥è¿›è¡Œç¼–ç </span>
    instruction <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span><span class="token string">"\n"</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">"Human: "</span> <span class="token operator">+</span> example<span class="token punctuation">[</span><span class="token string">"instruction"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> example<span class="token punctuation">[</span><span class="token string">"input"</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">"\n\nAssistant: "</span><span class="token punctuation">)</span>
    <span class="token comment"># å¯¹è¾“å‡ºè¿›è¡Œç¼–ç ï¼Œå¹¶æ·»åŠ ç»“æŸç¬¦</span>
    response <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>example<span class="token punctuation">[</span><span class="token string">"output"</span><span class="token punctuation">]</span> <span class="token operator">+</span> tokenizer<span class="token punctuation">.</span>eos_token<span class="token punctuation">)</span>
    <span class="token comment"># å°†æŒ‡ä»¤å’Œå“åº”çš„è¾“å…¥IDæ‹¼æ¥èµ·æ¥</span>
    input_ids <span class="token operator">=</span> instruction<span class="token punctuation">[</span><span class="token string">"input_ids"</span><span class="token punctuation">]</span> <span class="token operator">+</span> response<span class="token punctuation">[</span><span class="token string">"input_ids"</span><span class="token punctuation">]</span>
    <span class="token comment"># å°†æŒ‡ä»¤å’Œå“åº”çš„æ³¨æ„åŠ›æ©ç æ‹¼æ¥èµ·æ¥</span>
    attention_mask <span class="token operator">=</span> instruction<span class="token punctuation">[</span><span class="token string">"attention_mask"</span><span class="token punctuation">]</span> <span class="token operator">+</span> response<span class="token punctuation">[</span><span class="token string">"attention_mask"</span><span class="token punctuation">]</span>
    <span class="token comment"># å°†æŒ‡ä»¤çš„æ ‡ç­¾è®¾ç½®ä¸º-100ï¼Œè¡¨ç¤ºä¸è®¡ç®—æŸå¤±ï¼›å°†å“åº”çš„è¾“å…¥IDä½œä¸ºæ ‡ç­¾</span>
    labels <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">100</span><span class="token punctuation">]</span> <span class="token operator">*</span> <span class="token builtin">len</span><span class="token punctuation">(</span>instruction<span class="token punctuation">[</span><span class="token string">"input_ids"</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">+</span> response<span class="token punctuation">[</span><span class="token string">"input_ids"</span><span class="token punctuation">]</span>
    <span class="token comment"># å¦‚æœè¾“å…¥IDçš„é•¿åº¦è¶…è¿‡æœ€å¤§é•¿åº¦ï¼Œæˆªæ–­è¾“å…¥IDã€æ³¨æ„åŠ›æ©ç å’Œæ ‡ç­¾</span>
    <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>input_ids<span class="token punctuation">)</span> <span class="token operator">&gt;</span> MAX_LENGTH<span class="token punctuation">:</span>
        input_ids <span class="token operator">=</span> input_ids<span class="token punctuation">[</span><span class="token punctuation">:</span>MAX_LENGTH<span class="token punctuation">]</span>
        attention_mask <span class="token operator">=</span> attention_mask<span class="token punctuation">[</span><span class="token punctuation">:</span>MAX_LENGTH<span class="token punctuation">]</span>
        labels <span class="token operator">=</span> labels<span class="token punctuation">[</span><span class="token punctuation">:</span>MAX_LENGTH<span class="token punctuation">]</span>
    <span class="token comment"># è¿”å›å¤„ç†åçš„æ•°æ®</span>
    <span class="token keyword">return</span> <span class="token punctuation">{<!-- --></span>
        <span class="token string">"input_ids"</span><span class="token punctuation">:</span> input_ids<span class="token punctuation">,</span>
        <span class="token string">"attention_mask"</span><span class="token punctuation">:</span> attention_mask<span class="token punctuation">,</span>
        <span class="token string">"labels"</span><span class="token punctuation">:</span> labels
    <span class="token punctuation">}</span>
</code></pre> 
<p>3ï¼‰å¯¹æ•°æ®è¿›è¡Œé¢„å¤„ç†</p> 
<pre><code class="prism language-python">tokenized_ds <span class="token operator">=</span> ds<span class="token punctuation">.</span><span class="token builtin">map</span><span class="token punctuation">(</span>process_func<span class="token punctuation">,</span> remove_columns<span class="token operator">=</span>ds<span class="token punctuation">.</span>column_names<span class="token punctuation">)</span>
tokenized_ds
</code></pre> 
<p>è¾“å‡ºï¼š</p> 
<pre><code class="prism language-python">Dataset<span class="token punctuation">(</span><span class="token punctuation">{<!-- --></span>
    features<span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'input_ids'</span><span class="token punctuation">,</span> <span class="token string">'attention_mask'</span><span class="token punctuation">,</span> <span class="token string">'labels'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    num_rows<span class="token punctuation">:</span> <span class="token number">26858</span>
<span class="token punctuation">}</span><span class="token punctuation">)</span>
</code></pre> 
<h3><a id="4__215"></a>æ­¥éª¤4 åˆ›å»ºæ¨¡å‹</h3> 
<p>ç„¶åï¼Œæˆ‘ä»¬å®ä¾‹åŒ–ä¸€ä¸ªé¢„è®­ç»ƒæ¨¡å‹ï¼Œè¿™ä¸ªæ¨¡å‹å°†ä½œä¸ºå¾®è°ƒçš„åŸºç¡€ã€‚å¯¹äºå¤§å‹æ¨¡å‹ï¼Œæˆ‘ä»¬å¯èƒ½è¿˜éœ€è¦è¿›è¡Œä¸€äº›ç‰¹å®šçš„é…ç½®ï¼Œä»¥é€‚åº”å¯ç”¨çš„è®¡ç®—èµ„æºã€‚</p> 
<pre><code class="prism language-python"><span class="token comment">#è¿™è¡Œä»£ç ä»Hugging Face Model HubåŠ è½½äº†ä¸€ä¸ªé¢„è®­ç»ƒçš„Bloomæ¨¡å‹ï¼Œæ¨¡å‹åç§°ä¸º"Langboat/bloom-1b4-zh"ï¼Œå¹¶ä¸”è®¾ç½®äº†low_cpu_mem_usage=Trueä»¥å‡å°‘CPUå†…å­˜ä½¿ç”¨ã€‚</span>
model <span class="token operator">=</span> AutoModelForCausalLM<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"Langboat/bloom-1b4-zh"</span><span class="token punctuation">,</span> low_cpu_mem_usage<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
</code></pre> 
<p>æŸ¥çœ‹æ€»å…±æœ‰å“ªäº›å±‚ï¼Œå¯ä»¥åŸºäºè¿™äº›å±‚æ·»åŠ LoRA</p> 
<pre><code class="prism language-python"><span class="token keyword">for</span> name<span class="token punctuation">,</span> parameter <span class="token keyword">in</span> model<span class="token punctuation">.</span>named_parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>name<span class="token punctuation">)</span>
</code></pre> 
<p>è¾“å‡º</p> 
<pre><code class="prism language-python">base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>word_embeddings<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>word_embeddings_layernorm<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>word_embeddings_layernorm<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">0</span><span class="token punctuation">.</span>input_layernorm<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">0</span><span class="token punctuation">.</span>input_layernorm<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">0</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>base_layer<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">0</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>base_layer<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">0</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>lora_A<span class="token punctuation">.</span>default<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">0</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>lora_B<span class="token punctuation">.</span>default<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">0</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>dense<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">0</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>dense<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">0</span><span class="token punctuation">.</span>post_attention_layernorm<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">0</span><span class="token punctuation">.</span>post_attention_layernorm<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">0</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_h_to_4h<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">0</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_h_to_4h<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">0</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_4h_to_h<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">0</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_4h_to_h<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">1</span><span class="token punctuation">.</span>input_layernorm<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">1</span><span class="token punctuation">.</span>input_layernorm<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">1</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>base_layer<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">1</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>base_layer<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">1</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>lora_A<span class="token punctuation">.</span>default<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">1</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>lora_B<span class="token punctuation">.</span>default<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">1</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>dense<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">1</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>dense<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">1</span><span class="token punctuation">.</span>post_attention_layernorm<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">1</span><span class="token punctuation">.</span>post_attention_layernorm<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">1</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_h_to_4h<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">1</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_h_to_4h<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">1</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_4h_to_h<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">1</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_4h_to_h<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">2</span><span class="token punctuation">.</span>input_layernorm<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">2</span><span class="token punctuation">.</span>input_layernorm<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">2</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>base_layer<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">2</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>base_layer<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">2</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>lora_A<span class="token punctuation">.</span>default<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">2</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>lora_B<span class="token punctuation">.</span>default<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">2</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>dense<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">2</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>dense<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">2</span><span class="token punctuation">.</span>post_attention_layernorm<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">2</span><span class="token punctuation">.</span>post_attention_layernorm<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">2</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_h_to_4h<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">2</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_h_to_4h<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">2</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_4h_to_h<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">2</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_4h_to_h<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">3</span><span class="token punctuation">.</span>input_layernorm<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">3</span><span class="token punctuation">.</span>input_layernorm<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">3</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>base_layer<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">3</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>base_layer<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">3</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>lora_A<span class="token punctuation">.</span>default<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">3</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>lora_B<span class="token punctuation">.</span>default<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">3</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>dense<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">3</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>dense<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">3</span><span class="token punctuation">.</span>post_attention_layernorm<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">3</span><span class="token punctuation">.</span>post_attention_layernorm<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">3</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_h_to_4h<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">3</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_h_to_4h<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">3</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_4h_to_h<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">3</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_4h_to_h<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">4</span><span class="token punctuation">.</span>input_layernorm<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">4</span><span class="token punctuation">.</span>input_layernorm<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">4</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>base_layer<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">4</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>base_layer<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">4</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>lora_A<span class="token punctuation">.</span>default<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">4</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>lora_B<span class="token punctuation">.</span>default<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">4</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>dense<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">4</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>dense<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">4</span><span class="token punctuation">.</span>post_attention_layernorm<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">4</span><span class="token punctuation">.</span>post_attention_layernorm<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">4</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_h_to_4h<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">4</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_h_to_4h<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">4</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_4h_to_h<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">4</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_4h_to_h<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">5</span><span class="token punctuation">.</span>input_layernorm<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">5</span><span class="token punctuation">.</span>input_layernorm<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">5</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>base_layer<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">5</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>base_layer<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">5</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>lora_A<span class="token punctuation">.</span>default<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">5</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>lora_B<span class="token punctuation">.</span>default<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">5</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>dense<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">5</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>dense<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">5</span><span class="token punctuation">.</span>post_attention_layernorm<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">5</span><span class="token punctuation">.</span>post_attention_layernorm<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">5</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_h_to_4h<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">5</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_h_to_4h<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">5</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_4h_to_h<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">5</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_4h_to_h<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">6</span><span class="token punctuation">.</span>input_layernorm<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">6</span><span class="token punctuation">.</span>input_layernorm<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">6</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>base_layer<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">6</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>base_layer<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">6</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>lora_A<span class="token punctuation">.</span>default<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">6</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>lora_B<span class="token punctuation">.</span>default<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">6</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>dense<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">6</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>dense<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">6</span><span class="token punctuation">.</span>post_attention_layernorm<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">6</span><span class="token punctuation">.</span>post_attention_layernorm<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">6</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_h_to_4h<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">6</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_h_to_4h<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">6</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_4h_to_h<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">6</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_4h_to_h<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">7</span><span class="token punctuation">.</span>input_layernorm<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">7</span><span class="token punctuation">.</span>input_layernorm<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">7</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>base_layer<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">7</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>base_layer<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">7</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>lora_A<span class="token punctuation">.</span>default<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">7</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>lora_B<span class="token punctuation">.</span>default<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">7</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>dense<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">7</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>dense<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">7</span><span class="token punctuation">.</span>post_attention_layernorm<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">7</span><span class="token punctuation">.</span>post_attention_layernorm<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">7</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_h_to_4h<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">7</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_h_to_4h<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">7</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_4h_to_h<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">7</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_4h_to_h<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">8</span><span class="token punctuation">.</span>input_layernorm<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">8</span><span class="token punctuation">.</span>input_layernorm<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">8</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>base_layer<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">8</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>base_layer<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">8</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>lora_A<span class="token punctuation">.</span>default<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">8</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>lora_B<span class="token punctuation">.</span>default<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">8</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>dense<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">8</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>dense<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">8</span><span class="token punctuation">.</span>post_attention_layernorm<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">8</span><span class="token punctuation">.</span>post_attention_layernorm<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">8</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_h_to_4h<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">8</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_h_to_4h<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">8</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_4h_to_h<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">8</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_4h_to_h<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">9</span><span class="token punctuation">.</span>input_layernorm<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">9</span><span class="token punctuation">.</span>input_layernorm<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">9</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>base_layer<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">9</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>base_layer<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">9</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>lora_A<span class="token punctuation">.</span>default<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">9</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>lora_B<span class="token punctuation">.</span>default<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">9</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>dense<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">9</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>dense<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">9</span><span class="token punctuation">.</span>post_attention_layernorm<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">9</span><span class="token punctuation">.</span>post_attention_layernorm<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">9</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_h_to_4h<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">9</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_h_to_4h<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">9</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_4h_to_h<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">9</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_4h_to_h<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">10</span><span class="token punctuation">.</span>input_layernorm<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">10</span><span class="token punctuation">.</span>input_layernorm<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">10</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>base_layer<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">10</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>base_layer<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">10</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>lora_A<span class="token punctuation">.</span>default<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">10</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>lora_B<span class="token punctuation">.</span>default<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">10</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>dense<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">10</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>dense<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">10</span><span class="token punctuation">.</span>post_attention_layernorm<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">10</span><span class="token punctuation">.</span>post_attention_layernorm<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">10</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_h_to_4h<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">10</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_h_to_4h<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">10</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_4h_to_h<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">10</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_4h_to_h<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">11</span><span class="token punctuation">.</span>input_layernorm<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">11</span><span class="token punctuation">.</span>input_layernorm<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">11</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>base_layer<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">11</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>base_layer<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">11</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>lora_A<span class="token punctuation">.</span>default<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">11</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>lora_B<span class="token punctuation">.</span>default<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">11</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>dense<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">11</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>dense<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">11</span><span class="token punctuation">.</span>post_attention_layernorm<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">11</span><span class="token punctuation">.</span>post_attention_layernorm<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">11</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_h_to_4h<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">11</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_h_to_4h<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">11</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_4h_to_h<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">11</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_4h_to_h<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">12</span><span class="token punctuation">.</span>input_layernorm<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">12</span><span class="token punctuation">.</span>input_layernorm<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">12</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>base_layer<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">12</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>base_layer<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">12</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>lora_A<span class="token punctuation">.</span>default<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">12</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>lora_B<span class="token punctuation">.</span>default<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">12</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>dense<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">12</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>dense<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">12</span><span class="token punctuation">.</span>post_attention_layernorm<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">12</span><span class="token punctuation">.</span>post_attention_layernorm<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">12</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_h_to_4h<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">12</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_h_to_4h<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">12</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_4h_to_h<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">12</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_4h_to_h<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">13</span><span class="token punctuation">.</span>input_layernorm<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">13</span><span class="token punctuation">.</span>input_layernorm<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">13</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>base_layer<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">13</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>base_layer<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">13</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>lora_A<span class="token punctuation">.</span>default<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">13</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>lora_B<span class="token punctuation">.</span>default<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">13</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>dense<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">13</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>dense<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">13</span><span class="token punctuation">.</span>post_attention_layernorm<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">13</span><span class="token punctuation">.</span>post_attention_layernorm<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">13</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_h_to_4h<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">13</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_h_to_4h<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">13</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_4h_to_h<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">13</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_4h_to_h<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">14</span><span class="token punctuation">.</span>input_layernorm<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">14</span><span class="token punctuation">.</span>input_layernorm<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">14</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>base_layer<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">14</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>base_layer<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">14</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>lora_A<span class="token punctuation">.</span>default<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">14</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>lora_B<span class="token punctuation">.</span>default<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">14</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>dense<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">14</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>dense<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">14</span><span class="token punctuation">.</span>post_attention_layernorm<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">14</span><span class="token punctuation">.</span>post_attention_layernorm<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">14</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_h_to_4h<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">14</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_h_to_4h<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">14</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_4h_to_h<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">14</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_4h_to_h<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">15</span><span class="token punctuation">.</span>input_layernorm<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">15</span><span class="token punctuation">.</span>input_layernorm<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">15</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>base_layer<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">15</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>base_layer<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">15</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>lora_A<span class="token punctuation">.</span>default<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">15</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>lora_B<span class="token punctuation">.</span>default<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">15</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>dense<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">15</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>dense<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">15</span><span class="token punctuation">.</span>post_attention_layernorm<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">15</span><span class="token punctuation">.</span>post_attention_layernorm<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">15</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_h_to_4h<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">15</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_h_to_4h<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">15</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_4h_to_h<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">15</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_4h_to_h<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">16</span><span class="token punctuation">.</span>input_layernorm<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">16</span><span class="token punctuation">.</span>input_layernorm<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">16</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>base_layer<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">16</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>base_layer<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">16</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>lora_A<span class="token punctuation">.</span>default<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">16</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>lora_B<span class="token punctuation">.</span>default<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">16</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>dense<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">16</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>dense<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">16</span><span class="token punctuation">.</span>post_attention_layernorm<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">16</span><span class="token punctuation">.</span>post_attention_layernorm<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">16</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_h_to_4h<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">16</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_h_to_4h<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">16</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_4h_to_h<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">16</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_4h_to_h<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">17</span><span class="token punctuation">.</span>input_layernorm<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">17</span><span class="token punctuation">.</span>input_layernorm<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">17</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>base_layer<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">17</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>base_layer<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">17</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>lora_A<span class="token punctuation">.</span>default<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">17</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>lora_B<span class="token punctuation">.</span>default<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">17</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>dense<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">17</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>dense<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">17</span><span class="token punctuation">.</span>post_attention_layernorm<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">17</span><span class="token punctuation">.</span>post_attention_layernorm<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">17</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_h_to_4h<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">17</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_h_to_4h<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">17</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_4h_to_h<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">17</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_4h_to_h<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">18</span><span class="token punctuation">.</span>input_layernorm<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">18</span><span class="token punctuation">.</span>input_layernorm<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">18</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>base_layer<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">18</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>base_layer<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">18</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>lora_A<span class="token punctuation">.</span>default<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">18</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>lora_B<span class="token punctuation">.</span>default<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">18</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>dense<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">18</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>dense<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">18</span><span class="token punctuation">.</span>post_attention_layernorm<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">18</span><span class="token punctuation">.</span>post_attention_layernorm<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">18</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_h_to_4h<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">18</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_h_to_4h<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">18</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_4h_to_h<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">18</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_4h_to_h<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">19</span><span class="token punctuation">.</span>input_layernorm<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">19</span><span class="token punctuation">.</span>input_layernorm<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">19</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>base_layer<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">19</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>base_layer<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">19</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>lora_A<span class="token punctuation">.</span>default<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">19</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>lora_B<span class="token punctuation">.</span>default<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">19</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>dense<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">19</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>dense<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">19</span><span class="token punctuation">.</span>post_attention_layernorm<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">19</span><span class="token punctuation">.</span>post_attention_layernorm<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">19</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_h_to_4h<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">19</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_h_to_4h<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">19</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_4h_to_h<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">19</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_4h_to_h<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">20</span><span class="token punctuation">.</span>input_layernorm<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">20</span><span class="token punctuation">.</span>input_layernorm<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">20</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>base_layer<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">20</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>base_layer<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">20</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>lora_A<span class="token punctuation">.</span>default<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">20</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>lora_B<span class="token punctuation">.</span>default<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">20</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>dense<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">20</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>dense<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">20</span><span class="token punctuation">.</span>post_attention_layernorm<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">20</span><span class="token punctuation">.</span>post_attention_layernorm<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">20</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_h_to_4h<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">20</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_h_to_4h<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">20</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_4h_to_h<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">20</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_4h_to_h<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">21</span><span class="token punctuation">.</span>input_layernorm<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">21</span><span class="token punctuation">.</span>input_layernorm<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">21</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>base_layer<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">21</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>base_layer<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">21</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>lora_A<span class="token punctuation">.</span>default<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">21</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>lora_B<span class="token punctuation">.</span>default<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">21</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>dense<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">21</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>dense<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">21</span><span class="token punctuation">.</span>post_attention_layernorm<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">21</span><span class="token punctuation">.</span>post_attention_layernorm<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">21</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_h_to_4h<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">21</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_h_to_4h<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">21</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_4h_to_h<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">21</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_4h_to_h<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">22</span><span class="token punctuation">.</span>input_layernorm<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">22</span><span class="token punctuation">.</span>input_layernorm<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">22</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>base_layer<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">22</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>base_layer<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">22</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>lora_A<span class="token punctuation">.</span>default<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">22</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>lora_B<span class="token punctuation">.</span>default<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">22</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>dense<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">22</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>dense<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">22</span><span class="token punctuation">.</span>post_attention_layernorm<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">22</span><span class="token punctuation">.</span>post_attention_layernorm<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">22</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_h_to_4h<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">22</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_h_to_4h<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">22</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_4h_to_h<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">22</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_4h_to_h<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">23</span><span class="token punctuation">.</span>input_layernorm<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">23</span><span class="token punctuation">.</span>input_layernorm<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">23</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>base_layer<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">23</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>base_layer<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">23</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>lora_A<span class="token punctuation">.</span>default<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">23</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>query_key_value<span class="token punctuation">.</span>lora_B<span class="token punctuation">.</span>default<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">23</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>dense<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">23</span><span class="token punctuation">.</span>self_attention<span class="token punctuation">.</span>dense<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">23</span><span class="token punctuation">.</span>post_attention_layernorm<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">23</span><span class="token punctuation">.</span>post_attention_layernorm<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">23</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_h_to_4h<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">23</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_h_to_4h<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">23</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_4h_to_h<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>h<span class="token punctuation">.</span><span class="token number">23</span><span class="token punctuation">.</span>mlp<span class="token punctuation">.</span>dense_4h_to_h<span class="token punctuation">.</span>bias
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>ln_f<span class="token punctuation">.</span>weight
base_model<span class="token punctuation">.</span>model<span class="token punctuation">.</span>transformer<span class="token punctuation">.</span>ln_f<span class="token punctuation">.</span>bias
</code></pre> 
<p><strong>LoRAç›¸å…³çš„é…ç½®ï¼ˆä¸‹é¢2ä¸ªéƒ¨åˆ†æ˜¯LoRAç›¸å…³çš„é…ç½®ï¼Œå…¶ä»–çš„å’Œå…¨é‡å¾®è°ƒä»£ç ä¸€æ ·ï¼‰ã€‚</strong></p> 
<h4><a id="1PEFT_1__575"></a>1ã€PEFT æ­¥éª¤1 é…ç½®æ–‡ä»¶</h4> 
<p>åœ¨ä½¿ç”¨PEFTè¿›è¡Œå¾®è°ƒæ—¶ï¼Œæˆ‘ä»¬é¦–å…ˆéœ€è¦åˆ›å»ºä¸€ä¸ªé…ç½®æ–‡ä»¶ï¼Œè¯¥æ–‡ä»¶å®šä¹‰äº†å¾®è°ƒè¿‡ç¨‹ä¸­çš„å„ç§è®¾ç½®ï¼Œå¦‚å­¦ä¹ ç‡è°ƒåº¦ã€ä¼˜åŒ–å™¨é€‰æ‹©ç­‰ã€‚</p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> peft <span class="token keyword">import</span> LoraConfig<span class="token punctuation">,</span> TaskType<span class="token punctuation">,</span> get_peft_model
config <span class="token operator">=</span> LoraConfig<span class="token punctuation">(</span>task_type<span class="token operator">=</span>TaskType<span class="token punctuation">.</span>CAUSAL_LM<span class="token punctuation">)</span>
<span class="token comment">##ä¹Ÿå¯ä»¥ä¸ä½¿ç”¨é»˜è®¤çš„ï¼Œè‡ªå·±æŒ‡å®šï¼Œ ç›®æ ‡å±‚ target_modules=["query_key_value"],ç§© r=8</span>
<span class="token comment">#config = LoraConfig(task_type=TaskType.CAUSAL_LM,r=8, target_modules=['query_key_value','dense_4h_to_h'])</span>
config
</code></pre> 
<h4><a id="2PEFT_2__586"></a>2ã€PEFT æ­¥éª¤2 åˆ›å»ºæ¨¡å‹</h4> 
<p>æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬ä½¿ç”¨PEFTå’Œé¢„è®­ç»ƒæ¨¡å‹æ¥åˆ›å»ºä¸€ä¸ªå¾®è°ƒæ¨¡å‹ã€‚<font color="red">è¿™ä¸ªæ¨¡å‹å°†åŒ…å«åŸå§‹çš„é¢„è®­ç»ƒæ¨¡å‹ä»¥åŠç”±PEFTå¼•å…¥çš„ä½ç§©å‚æ•°ã€‚</font></p> 
<pre><code class="prism language-python">model <span class="token operator">=</span> get_peft_model<span class="token punctuation">(</span>model<span class="token punctuation">,</span> config<span class="token punctuation">)</span>
model
</code></pre> 
<p>è¾“å‡ºï¼š</p> 
<pre><code class="prism language-python">PeftModelForCausalLM<span class="token punctuation">(</span>
  <span class="token punctuation">(</span>base_model<span class="token punctuation">)</span><span class="token punctuation">:</span> LoraModel<span class="token punctuation">(</span>
    <span class="token punctuation">(</span>model<span class="token punctuation">)</span><span class="token punctuation">:</span> PeftModelForCausalLM<span class="token punctuation">(</span>
      <span class="token punctuation">(</span>base_model<span class="token punctuation">)</span><span class="token punctuation">:</span> LoraModel<span class="token punctuation">(</span>
        <span class="token punctuation">(</span>model<span class="token punctuation">)</span><span class="token punctuation">:</span> BloomForCausalLM<span class="token punctuation">(</span>
          <span class="token punctuation">(</span>transformer<span class="token punctuation">)</span><span class="token punctuation">:</span> BloomModel<span class="token punctuation">(</span>
            <span class="token punctuation">(</span>word_embeddings<span class="token punctuation">)</span><span class="token punctuation">:</span> Embedding<span class="token punctuation">(</span><span class="token number">46145</span><span class="token punctuation">,</span> <span class="token number">2048</span><span class="token punctuation">)</span>
            <span class="token punctuation">(</span>word_embeddings_layernorm<span class="token punctuation">)</span><span class="token punctuation">:</span> LayerNorm<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">2048</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span> eps<span class="token operator">=</span><span class="token number">1e-05</span><span class="token punctuation">,</span> elementwise_affine<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
            <span class="token punctuation">(</span>h<span class="token punctuation">)</span><span class="token punctuation">:</span> ModuleList<span class="token punctuation">(</span>
              <span class="token punctuation">(</span><span class="token number">0</span><span class="token operator">-</span><span class="token number">23</span><span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token number">24</span> x BloomBlock<span class="token punctuation">(</span>
                <span class="token punctuation">(</span>input_layernorm<span class="token punctuation">)</span><span class="token punctuation">:</span> LayerNorm<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">2048</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span> eps<span class="token operator">=</span><span class="token number">1e-05</span><span class="token punctuation">,</span> elementwise_affine<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
                <span class="token punctuation">(</span>self_attention<span class="token punctuation">)</span><span class="token punctuation">:</span> BloomAttention<span class="token punctuation">(</span>
                  <span class="token punctuation">(</span>query_key_value<span class="token punctuation">)</span><span class="token punctuation">:</span> lora<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>
                    <span class="token punctuation">(</span>base_layer<span class="token punctuation">)</span><span class="token punctuation">:</span> Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">2048</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token number">6144</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
                    <span class="token punctuation">(</span>lora_dropout<span class="token punctuation">)</span><span class="token punctuation">:</span> ModuleDict<span class="token punctuation">(</span>
                      <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token punctuation">:</span> Identity<span class="token punctuation">(</span><span class="token punctuation">)</span>
                    <span class="token punctuation">)</span>
                    <span class="token punctuation">(</span>lora_A<span class="token punctuation">)</span><span class="token punctuation">:</span> ModuleDict<span class="token punctuation">(</span>
                      <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token punctuation">:</span> Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">2048</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
                    <span class="token punctuation">)</span>
                    <span class="token punctuation">(</span>lora_B<span class="token punctuation">)</span><span class="token punctuation">:</span> ModuleDict<span class="token punctuation">(</span>
                      <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token punctuation">:</span> Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token number">6144</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
                    <span class="token punctuation">)</span>
                    <span class="token punctuation">(</span>lora_embedding_A<span class="token punctuation">)</span><span class="token punctuation">:</span> ParameterDict<span class="token punctuation">(</span><span class="token punctuation">)</span>
                    <span class="token punctuation">(</span>lora_embedding_B<span class="token punctuation">)</span><span class="token punctuation">:</span> ParameterDict<span class="token punctuation">(</span><span class="token punctuation">)</span>
                  <span class="token punctuation">)</span>
                  <span class="token punctuation">(</span>dense<span class="token punctuation">)</span><span class="token punctuation">:</span> Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">2048</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token number">2048</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
                  <span class="token punctuation">(</span>attention_dropout<span class="token punctuation">)</span><span class="token punctuation">:</span> Dropout<span class="token punctuation">(</span>p<span class="token operator">=</span><span class="token number">0.0</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
                <span class="token punctuation">)</span>
                <span class="token punctuation">(</span>post_attention_layernorm<span class="token punctuation">)</span><span class="token punctuation">:</span> LayerNorm<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">2048</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span> eps<span class="token operator">=</span><span class="token number">1e-05</span><span class="token punctuation">,</span> elementwise_affine<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
                <span class="token punctuation">(</span>mlp<span class="token punctuation">)</span><span class="token punctuation">:</span> BloomMLP<span class="token punctuation">(</span>
                  <span class="token punctuation">(</span>dense_h_to_4h<span class="token punctuation">)</span><span class="token punctuation">:</span> Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">2048</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token number">8192</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
                  <span class="token punctuation">(</span>gelu_impl<span class="token punctuation">)</span><span class="token punctuation">:</span> BloomGelu<span class="token punctuation">(</span><span class="token punctuation">)</span>
                  <span class="token punctuation">(</span>dense_4h_to_h<span class="token punctuation">)</span><span class="token punctuation">:</span> lora<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>
                    <span class="token punctuation">(</span>base_layer<span class="token punctuation">)</span><span class="token punctuation">:</span> Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">8192</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token number">2048</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
                    <span class="token punctuation">(</span>lora_dropout<span class="token punctuation">)</span><span class="token punctuation">:</span> ModuleDict<span class="token punctuation">(</span>
                      <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token punctuation">:</span> Identity<span class="token punctuation">(</span><span class="token punctuation">)</span>
                    <span class="token punctuation">)</span>
                    <span class="token punctuation">(</span>lora_A<span class="token punctuation">)</span><span class="token punctuation">:</span> ModuleDict<span class="token punctuation">(</span>
                      <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token punctuation">:</span> Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">8192</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
                    <span class="token punctuation">)</span>
                    <span class="token punctuation">(</span>lora_B<span class="token punctuation">)</span><span class="token punctuation">:</span> ModuleDict<span class="token punctuation">(</span>
                      <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token punctuation">:</span> Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token number">2048</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
                    <span class="token punctuation">)</span>
                    <span class="token punctuation">(</span>lora_embedding_A<span class="token punctuation">)</span><span class="token punctuation">:</span> ParameterDict<span class="token punctuation">(</span><span class="token punctuation">)</span>
                    <span class="token punctuation">(</span>lora_embedding_B<span class="token punctuation">)</span><span class="token punctuation">:</span> ParameterDict<span class="token punctuation">(</span><span class="token punctuation">)</span>
                  <span class="token punctuation">)</span>
                <span class="token punctuation">)</span>
              <span class="token punctuation">)</span>
            <span class="token punctuation">)</span>
            <span class="token punctuation">(</span>ln_f<span class="token punctuation">)</span><span class="token punctuation">:</span> LayerNorm<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">2048</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span> eps<span class="token operator">=</span><span class="token number">1e-05</span><span class="token punctuation">,</span> elementwise_affine<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
          <span class="token punctuation">)</span>
          <span class="token punctuation">(</span>lm_head<span class="token punctuation">)</span><span class="token punctuation">:</span> Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">2048</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token number">46145</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
        <span class="token punctuation">)</span>
      <span class="token punctuation">)</span>
    <span class="token punctuation">)</span>
  <span class="token punctuation">)</span>
<span class="token punctuation">)</span>
</code></pre> 
<p>æŸ¥çœ‹é…ç½®</p> 
<pre><code class="prism language-python">config
</code></pre> 
<p>è¾“å‡º</p> 
<pre><code class="prism language-python">LoraConfig<span class="token punctuation">(</span>peft_type<span class="token operator">=</span><span class="token operator">&lt;</span>PeftType<span class="token punctuation">.</span>LORA<span class="token punctuation">:</span> <span class="token string">'LORA'</span><span class="token operator">&gt;</span><span class="token punctuation">,</span> auto_mapping<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> base_model_name_or_path<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> revision<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> task_type<span class="token operator">=</span><span class="token operator">&lt;</span>TaskType<span class="token punctuation">.</span>CAUSAL_LM<span class="token punctuation">:</span> <span class="token string">'CAUSAL_LM'</span><span class="token operator">&gt;</span><span class="token punctuation">,</span> inference_mode<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> r<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">,</span> target_modules<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token string">'query_key_value'</span><span class="token punctuation">,</span> <span class="token string">'dense_4h_to_h'</span><span class="token punctuation">}</span><span class="token punctuation">,</span> lora_alpha<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">,</span> lora_dropout<span class="token operator">=</span><span class="token number">0.0</span><span class="token punctuation">,</span> fan_in_fan_out<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token string">'none'</span><span class="token punctuation">,</span> modules_to_save<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> init_lora_weights<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> layers_to_transform<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> layers_pattern<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> rank_pattern<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token punctuation">}</span><span class="token punctuation">,</span> alpha_pattern<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token punctuation">}</span><span class="token punctuation">,</span> megatron_config<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> megatron_core<span class="token operator">=</span><span class="token string">'megatron.core'</span><span class="token punctuation">,</span> loftq_config<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token punctuation">}</span><span class="token punctuation">)</span>
</code></pre> 
<h3><a id="5__665"></a>æ­¥éª¤5 é…ç½®è®­ç»ƒå‚æ•°</h3> 
<p>å®šä¹‰è®­ç»ƒå‚æ•°ï¼ŒåŒ…æ‹¬è¾“å‡ºç›®å½•ã€å­¦ä¹ ç‡ã€æ‰¹æ¬¡å¤§å°ã€æ¢¯åº¦ç´¯ç§¯æ­¥æ•°ã€ä¼˜åŒ–å™¨é€‰æ‹©ç­‰ã€‚</p> 
<pre><code class="prism language-python">args <span class="token operator">=</span> TrainingArguments<span class="token punctuation">(</span>
    output_dir<span class="token operator">=</span><span class="token string">"/root/autodl-tmp/tuningdata/lora"</span><span class="token punctuation">,</span><span class="token comment"># æŒ‡å®šæ¨¡å‹è®­ç»ƒç»“æœçš„è¾“å‡ºç›®å½•ã€‚</span>
    per_device_train_batch_size<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token comment"># æŒ‡å®šæ¯ä¸ªè®¾å¤‡ï¼ˆå¦‚GPUï¼‰ä¸Šçš„æ‰¹æ¬¡å¤§å°</span>
    gradient_accumulation_steps<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">,</span><span class="token comment"># æŒ‡å®šæ¢¯åº¦ç´¯ç§¯æ­¥æ•°ã€‚åœ¨æœ¬ä¾‹å­ä¸­ï¼Œæ¯8ä¸ªæ­¥éª¤è¿›è¡Œä¸€æ¬¡æ¢¯åº¦æ›´æ–°ã€‚</span>
    logging_steps<span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">,</span> <span class="token comment">#æŒ‡å®šæ—¥å¿—è®°å½•çš„é¢‘ç‡ã€‚åœ¨æœ¬ä¾‹å­ä¸­ï¼Œæ¯20ä¸ªæ­¥éª¤è®°å½•ä¸€æ¬¡æ—¥å¿—</span>
    num_train_epochs<span class="token operator">=</span><span class="token number">4</span> <span class="token comment">#æŒ‡å®šè®­ç»ƒçš„æ€»è½®æ•°</span>
<span class="token punctuation">)</span>

</code></pre> 
<h3><a id="6__679"></a>æ­¥éª¤6 åˆ›å»ºè®­ç»ƒå™¨</h3> 
<p>æœ€åï¼Œæˆ‘ä»¬åˆ›å»ºä¸€ä¸ªè®­ç»ƒå™¨å®ä¾‹ï¼Œå®ƒå°è£…äº†è®­ç»ƒå¾ªç¯ã€‚è®­ç»ƒå™¨å°†è´Ÿè´£è¿è¡Œè®­ç»ƒè¿‡ç¨‹ï¼Œå¹¶æ ¹æ®æˆ‘ä»¬ä¹‹å‰å®šä¹‰çš„å‚æ•°è¿›è¡Œä¼˜åŒ–ã€‚</p> 
<pre><code class="prism language-python">trainer <span class="token operator">=</span> Trainer<span class="token punctuation">(</span>
    model<span class="token operator">=</span>model<span class="token punctuation">,</span><span class="token comment">#æŒ‡å®šè®­ç»ƒæ¨¡å‹</span>
    args<span class="token operator">=</span>args<span class="token punctuation">,</span> <span class="token comment">#æŒ‡å®šè®­ç»ƒå‚æ•°</span>
    train_dataset<span class="token operator">=</span>tokenized_ds<span class="token punctuation">,</span> <span class="token comment">#æŒ‡å®šæ•°æ®é›†</span>
    data_collator<span class="token operator">=</span>DataCollatorForSeq2Seq<span class="token punctuation">(</span>tokenizer<span class="token operator">=</span>tokenizer<span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span> <span class="token comment">#æŒ‡å®šæ•°æ®æ”¶é›†å™¨ã€‚å…¶ä¸­tokenizeræ˜¯åˆ†è¯å™¨ï¼Œpadding=Trueè¡¨ç¤ºå¯¹è¾“å…¥è¿›è¡Œå¡«å……ä»¥ä¿æŒæ‰¹æ¬¡å¤§å°ä¸€è‡´ã€‚</span>
<span class="token punctuation">)</span>
</code></pre> 
<h3><a id="7__691"></a>æ­¥éª¤7 æ¨¡å‹è®­ç»ƒ</h3> 
<p>é€šè¿‡è°ƒç”¨è®­ç»ƒå™¨çš„<code>train()</code>æ–¹æ³•ï¼Œæˆ‘ä»¬å¯åŠ¨æ¨¡å‹çš„è®­ç»ƒè¿‡ç¨‹ã€‚</p> 
<pre><code class="prism language-python">trainer<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<h3><a id="8__699"></a>æ­¥éª¤8 æ¨¡å‹æ¨ç†</h3> 
<p>è®­ç»ƒå®Œæˆåï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹è¿›è¡Œæ¨ç†ã€‚è¿™é€šå¸¸æ¶‰åŠåˆ°ä½¿ç”¨æ¨¡å‹çš„<code>inference</code>æ–¹æ³•ï¼Œè¾“å…¥ç»è¿‡é€‚å½“å¤„ç†çš„é—®é¢˜ï¼Œå¹¶å¾—åˆ°æ¨¡å‹çš„è¾“å‡ºã€‚</p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> pipeline

pipe <span class="token operator">=</span> pipeline<span class="token punctuation">(</span><span class="token string">"text-generation"</span><span class="token punctuation">,</span> model<span class="token operator">=</span>model<span class="token punctuation">,</span> tokenizer<span class="token operator">=</span>tokenizer<span class="token punctuation">,</span> device<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>

ipt <span class="token operator">=</span> <span class="token string">"Human: {}\n{}"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span><span class="token string">"å¦‚ä½•å†™å¥½ä¸€ä¸ªç®€å†ï¼Ÿ"</span><span class="token punctuation">,</span> <span class="token string">""</span><span class="token punctuation">)</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">"\n\nAssistant: "</span>
pipe<span class="token punctuation">(</span>ipt<span class="token punctuation">,</span> max_length<span class="token operator">=</span><span class="token number">256</span><span class="token punctuation">,</span> do_sample<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> <span class="token punctuation">)</span>
</code></pre> 
<p>è¾“å‡º</p> 
<pre><code class="prism language-python"><span class="token punctuation">[</span><span class="token punctuation">{<!-- --></span><span class="token string">'generated_text'</span><span class="token punctuation">:</span> <span class="token string">'Human: å¦‚ä½•å†™å¥½ä¸€ä¸ªç®€å†ï¼Ÿ\n\nAssistant: ä¸€ç¯‡å¥½çš„ç®€å†åº”åŒ…å«ä»¥ä¸‹å†…å®¹ï¼šä¸ªäººä¿¡æ¯ï¼ˆå§“åï¼Œå‡ºç”Ÿæ—¥æœŸï¼Œå‡ºç”Ÿåœ°ï¼Œæ•™è‚²ç»å†ï¼Œå·¥ä½œç»å†ï¼‰ã€æ±‚èŒç†ç”±ã€ä¸ªäººèƒ½åŠ›ï¼ˆå¦‚è¯­è¨€èƒ½åŠ›ï¼Œè‹±è¯­æ°´å¹³ï¼Œæ“ä½œæŠ€èƒ½ï¼Œç¼–ç¨‹èƒ½åŠ›ï¼Œå¸‚åœºè¥é”€èƒ½åŠ›ï¼Œåˆ†æå½’çº³èƒ½åŠ›ç­‰ï¼‰ã€å­¦ä¹ ç»å†ã€å®è·µç»å†å’Œç»éªŒã€è£èª‰å¥–é¡¹ã€ç›¸å…³è¯ä¹¦å’Œè£èª‰ã€ä¸ªäººå…´è¶£çˆ±å¥½ä»¥åŠåœ¨å·¥ä½œä¸­é‡åˆ°çš„ç“¶é¢ˆå’Œéšœç¢ã€‚\n\nåœ¨ä¹¦å†™æ—¶ï¼Œåº”æ³¨æ„æ–‡å­—ç®€æ´ã€æ¡ç†æ¸…æ™°ï¼Œçªå‡ºé‡ç‚¹ï¼Œè¯­è¨€æµç•…ã€‚æ‚¨ä¹Ÿå¯ä»¥åœ¨ç®€å†ä¸­é™„ä¸Šä¸€äº›ç›¸å…³çš„ä¸ªäººç…§ç‰‡æˆ–ç…§ç‰‡èµ„æ–™ä»¥ä¾›ä»–äººå‚è€ƒã€‚å¦‚æœæ‚¨æœ‰ä»»ä½•ç–‘é—®ï¼Œè¯·éšæ—¶ä¸æˆ‘è”ç³»ã€‚'</span><span class="token punctuation">}</span><span class="token punctuation">]</span>
</code></pre> 
<h2><a id="_717"></a>åã€ä¸»è·¯åˆå¹¶æ—è·¯</h2> 
<h3><a id="1_718"></a>1ã€åŠ è½½åŸºç¡€æ¨¡å‹</h3> 
<pre><code class="prism language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoModelForCausalLM<span class="token punctuation">,</span> AutoTokenizer

<span class="token keyword">from</span> peft <span class="token keyword">import</span> PeftModel

model <span class="token operator">=</span> AutoModelForCausalLM<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"Langboat/bloom-1b4-zh"</span><span class="token punctuation">,</span> low_cpu_mem_usage<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"Langboat/bloom-1b4-zh"</span><span class="token punctuation">)</span>
</code></pre> 
<h3><a id="2LoRA_729"></a>2ã€åŠ è½½LoRAæ¨¡å‹</h3> 
<pre><code class="prism language-python">p_model <span class="token operator">=</span> PeftModel<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>model<span class="token punctuation">,</span> model_id<span class="token operator">=</span><span class="token string">"/root/autodl-tmp/tuningdata/lora/checkpoint-500"</span><span class="token punctuation">)</span>
p_model
</code></pre> 
<p>è¾“å‡º</p> 
<pre><code class="prism language-python">PeftModelForCausalLM<span class="token punctuation">(</span>
  <span class="token punctuation">(</span>base_model<span class="token punctuation">)</span><span class="token punctuation">:</span> LoraModel<span class="token punctuation">(</span>
    <span class="token punctuation">(</span>model<span class="token punctuation">)</span><span class="token punctuation">:</span> BloomForCausalLM<span class="token punctuation">(</span>
      <span class="token punctuation">(</span>transformer<span class="token punctuation">)</span><span class="token punctuation">:</span> BloomModel<span class="token punctuation">(</span>
        <span class="token punctuation">(</span>word_embeddings<span class="token punctuation">)</span><span class="token punctuation">:</span> Embedding<span class="token punctuation">(</span><span class="token number">46145</span><span class="token punctuation">,</span> <span class="token number">2048</span><span class="token punctuation">)</span>
        <span class="token punctuation">(</span>word_embeddings_layernorm<span class="token punctuation">)</span><span class="token punctuation">:</span> LayerNorm<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">2048</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span> eps<span class="token operator">=</span><span class="token number">1e-05</span><span class="token punctuation">,</span> elementwise_affine<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
        <span class="token punctuation">(</span>h<span class="token punctuation">)</span><span class="token punctuation">:</span> ModuleList<span class="token punctuation">(</span>
          <span class="token punctuation">(</span><span class="token number">0</span><span class="token operator">-</span><span class="token number">23</span><span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token number">24</span> x BloomBlock<span class="token punctuation">(</span>
            <span class="token punctuation">(</span>input_layernorm<span class="token punctuation">)</span><span class="token punctuation">:</span> LayerNorm<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">2048</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span> eps<span class="token operator">=</span><span class="token number">1e-05</span><span class="token punctuation">,</span> elementwise_affine<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
            <span class="token punctuation">(</span>self_attention<span class="token punctuation">)</span><span class="token punctuation">:</span> BloomAttention<span class="token punctuation">(</span>
              <span class="token punctuation">(</span>query_key_value<span class="token punctuation">)</span><span class="token punctuation">:</span> lora<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>
                <span class="token punctuation">(</span>base_layer<span class="token punctuation">)</span><span class="token punctuation">:</span> Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">2048</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token number">6144</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
                <span class="token punctuation">(</span>lora_dropout<span class="token punctuation">)</span><span class="token punctuation">:</span> ModuleDict<span class="token punctuation">(</span>
                  <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token punctuation">:</span> Identity<span class="token punctuation">(</span><span class="token punctuation">)</span>
                <span class="token punctuation">)</span>
                <span class="token punctuation">(</span>lora_A<span class="token punctuation">)</span><span class="token punctuation">:</span> ModuleDict<span class="token punctuation">(</span>
                  <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token punctuation">:</span> Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">2048</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
                <span class="token punctuation">)</span>
                <span class="token punctuation">(</span>lora_B<span class="token punctuation">)</span><span class="token punctuation">:</span> ModuleDict<span class="token punctuation">(</span>
                  <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token punctuation">:</span> Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token number">6144</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
                <span class="token punctuation">)</span>
                <span class="token punctuation">(</span>lora_embedding_A<span class="token punctuation">)</span><span class="token punctuation">:</span> ParameterDict<span class="token punctuation">(</span><span class="token punctuation">)</span>
                <span class="token punctuation">(</span>lora_embedding_B<span class="token punctuation">)</span><span class="token punctuation">:</span> ParameterDict<span class="token punctuation">(</span><span class="token punctuation">)</span>
              <span class="token punctuation">)</span>
              <span class="token punctuation">(</span>dense<span class="token punctuation">)</span><span class="token punctuation">:</span> Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">2048</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token number">2048</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
              <span class="token punctuation">(</span>attention_dropout<span class="token punctuation">)</span><span class="token punctuation">:</span> Dropout<span class="token punctuation">(</span>p<span class="token operator">=</span><span class="token number">0.0</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
            <span class="token punctuation">)</span>
            <span class="token punctuation">(</span>post_attention_layernorm<span class="token punctuation">)</span><span class="token punctuation">:</span> LayerNorm<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">2048</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span> eps<span class="token operator">=</span><span class="token number">1e-05</span><span class="token punctuation">,</span> elementwise_affine<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
            <span class="token punctuation">(</span>mlp<span class="token punctuation">)</span><span class="token punctuation">:</span> BloomMLP<span class="token punctuation">(</span>
              <span class="token punctuation">(</span>dense_h_to_4h<span class="token punctuation">)</span><span class="token punctuation">:</span> Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">2048</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token number">8192</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
              <span class="token punctuation">(</span>gelu_impl<span class="token punctuation">)</span><span class="token punctuation">:</span> BloomGelu<span class="token punctuation">(</span><span class="token punctuation">)</span>
              <span class="token punctuation">(</span>dense_4h_to_h<span class="token punctuation">)</span><span class="token punctuation">:</span> lora<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>
                <span class="token punctuation">(</span>base_layer<span class="token punctuation">)</span><span class="token punctuation">:</span> Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">8192</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token number">2048</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
                <span class="token punctuation">(</span>lora_dropout<span class="token punctuation">)</span><span class="token punctuation">:</span> ModuleDict<span class="token punctuation">(</span>
                  <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token punctuation">:</span> Identity<span class="token punctuation">(</span><span class="token punctuation">)</span>
                <span class="token punctuation">)</span>
                <span class="token punctuation">(</span>lora_A<span class="token punctuation">)</span><span class="token punctuation">:</span> ModuleDict<span class="token punctuation">(</span>
                  <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token punctuation">:</span> Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">8192</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
                <span class="token punctuation">)</span>
                <span class="token punctuation">(</span>lora_B<span class="token punctuation">)</span><span class="token punctuation">:</span> ModuleDict<span class="token punctuation">(</span>
                  <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token punctuation">:</span> Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token number">2048</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
                <span class="token punctuation">)</span>
                <span class="token punctuation">(</span>lora_embedding_A<span class="token punctuation">)</span><span class="token punctuation">:</span> ParameterDict<span class="token punctuation">(</span><span class="token punctuation">)</span>
                <span class="token punctuation">(</span>lora_embedding_B<span class="token punctuation">)</span><span class="token punctuation">:</span> ParameterDict<span class="token punctuation">(</span><span class="token punctuation">)</span>
              <span class="token punctuation">)</span>
            <span class="token punctuation">)</span>
          <span class="token punctuation">)</span>
        <span class="token punctuation">)</span>
        <span class="token punctuation">(</span>ln_f<span class="token punctuation">)</span><span class="token punctuation">:</span> LayerNorm<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">2048</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span> eps<span class="token operator">=</span><span class="token number">1e-05</span><span class="token punctuation">,</span> elementwise_affine<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
      <span class="token punctuation">)</span>
      <span class="token punctuation">(</span>lm_head<span class="token punctuation">)</span><span class="token punctuation">:</span> Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">2048</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token number">46145</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
    <span class="token punctuation">)</span>
  <span class="token punctuation">)</span>
<span class="token punctuation">)</span>
</code></pre> 
<h3><a id="3_794"></a>3ã€æ¨¡å‹æ¨ç†</h3> 
<pre><code class="prism language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> pipeline

pipe <span class="token operator">=</span> pipeline<span class="token punctuation">(</span><span class="token string">"text-generation"</span><span class="token punctuation">,</span> model<span class="token operator">=</span>p_model<span class="token punctuation">,</span> tokenizer<span class="token operator">=</span>tokenizer<span class="token punctuation">,</span> device<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
ipt <span class="token operator">=</span> <span class="token string">"Human: {}\n{}"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span><span class="token string">"å¦‚ä½•å†™å¥½ä¸€ä¸ªç®€å†ï¼Ÿ"</span><span class="token punctuation">,</span> <span class="token string">""</span><span class="token punctuation">)</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">"\n\nAssistant: "</span>
pipe<span class="token punctuation">(</span>ipt<span class="token punctuation">,</span> max_length<span class="token operator">=</span><span class="token number">256</span><span class="token punctuation">,</span> do_sample<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> <span class="token punctuation">)</span>
</code></pre> 
<h3><a id="4_806"></a>4ã€æ¨¡å‹åˆå¹¶</h3> 
<pre><code class="prism language-python">merge_model <span class="token operator">=</span> p_model<span class="token punctuation">.</span>merge_and_unload<span class="token punctuation">(</span><span class="token punctuation">)</span>
merge_model
</code></pre> 
<p>è¾“å‡º</p> 
<pre><code class="prism language-python">BloomForCausalLM<span class="token punctuation">(</span>
  <span class="token punctuation">(</span>transformer<span class="token punctuation">)</span><span class="token punctuation">:</span> BloomModel<span class="token punctuation">(</span>
    <span class="token punctuation">(</span>word_embeddings<span class="token punctuation">)</span><span class="token punctuation">:</span> Embedding<span class="token punctuation">(</span><span class="token number">46145</span><span class="token punctuation">,</span> <span class="token number">2048</span><span class="token punctuation">)</span>
    <span class="token punctuation">(</span>word_embeddings_layernorm<span class="token punctuation">)</span><span class="token punctuation">:</span> LayerNorm<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">2048</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span> eps<span class="token operator">=</span><span class="token number">1e-05</span><span class="token punctuation">,</span> elementwise_affine<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    <span class="token punctuation">(</span>h<span class="token punctuation">)</span><span class="token punctuation">:</span> ModuleList<span class="token punctuation">(</span>
      <span class="token punctuation">(</span><span class="token number">0</span><span class="token operator">-</span><span class="token number">23</span><span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token number">24</span> x BloomBlock<span class="token punctuation">(</span>
        <span class="token punctuation">(</span>input_layernorm<span class="token punctuation">)</span><span class="token punctuation">:</span> LayerNorm<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">2048</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span> eps<span class="token operator">=</span><span class="token number">1e-05</span><span class="token punctuation">,</span> elementwise_affine<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
        <span class="token punctuation">(</span>self_attention<span class="token punctuation">)</span><span class="token punctuation">:</span> BloomAttention<span class="token punctuation">(</span>
          <span class="token punctuation">(</span>query_key_value<span class="token punctuation">)</span><span class="token punctuation">:</span> Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">2048</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token number">6144</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
          <span class="token punctuation">(</span>dense<span class="token punctuation">)</span><span class="token punctuation">:</span> Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">2048</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token number">2048</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
          <span class="token punctuation">(</span>attention_dropout<span class="token punctuation">)</span><span class="token punctuation">:</span> Dropout<span class="token punctuation">(</span>p<span class="token operator">=</span><span class="token number">0.0</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
        <span class="token punctuation">)</span>
        <span class="token punctuation">(</span>post_attention_layernorm<span class="token punctuation">)</span><span class="token punctuation">:</span> LayerNorm<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">2048</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span> eps<span class="token operator">=</span><span class="token number">1e-05</span><span class="token punctuation">,</span> elementwise_affine<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
        <span class="token punctuation">(</span>mlp<span class="token punctuation">)</span><span class="token punctuation">:</span> BloomMLP<span class="token punctuation">(</span>
          <span class="token punctuation">(</span>dense_h_to_4h<span class="token punctuation">)</span><span class="token punctuation">:</span> Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">2048</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token number">8192</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
          <span class="token punctuation">(</span>gelu_impl<span class="token punctuation">)</span><span class="token punctuation">:</span> BloomGelu<span class="token punctuation">(</span><span class="token punctuation">)</span>
          <span class="token punctuation">(</span>dense_4h_to_h<span class="token punctuation">)</span><span class="token punctuation">:</span> Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">8192</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token number">2048</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
        <span class="token punctuation">)</span>
      <span class="token punctuation">)</span>
    <span class="token punctuation">)</span>
    <span class="token punctuation">(</span>ln_f<span class="token punctuation">)</span><span class="token punctuation">:</span> LayerNorm<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">2048</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span> eps<span class="token operator">=</span><span class="token number">1e-05</span><span class="token punctuation">,</span> elementwise_affine<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
  <span class="token punctuation">)</span>
  <span class="token punctuation">(</span>lm_head<span class="token punctuation">)</span><span class="token punctuation">:</span> Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">2048</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token number">46145</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
<span class="token punctuation">)</span>
</code></pre> 
<h3><a id="5_841"></a>5ã€æ¨¡å‹æ¨ç†</h3> 
<pre><code class="prism language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> pipeline

pipe <span class="token operator">=</span> pipeline<span class="token punctuation">(</span><span class="token string">"text-generation"</span><span class="token punctuation">,</span> model<span class="token operator">=</span>merge_model<span class="token punctuation">,</span> tokenizer<span class="token operator">=</span>tokenizer<span class="token punctuation">,</span> device<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
ipt <span class="token operator">=</span> <span class="token string">"Human:å¦‚ä½•å†™å¥½ä¸€ä¸ªç®€å†ï¼Ÿ\n\nAssistant: "</span>
pipe<span class="token punctuation">(</span>ipt<span class="token punctuation">,</span> max_length<span class="token operator">=</span><span class="token number">256</span><span class="token punctuation">,</span><span class="token punctuation">)</span>
</code></pre> 
<h3><a id="6_851"></a>6ã€å®Œæ•´æ¨¡å‹ä¿å­˜</h3> 
<p>æ¨¡å‹è®­ç»ƒå®Œåï¼Œå¯ä»¥å°†åˆå¹¶çš„æ¨¡å‹è¿›è¡Œä¿å­˜åˆ°æœ¬åœ°ï¼Œè¿›è¡Œå¤‡ç”¨</p> 
<pre><code class="prism language-python">merge_model<span class="token punctuation">.</span>save_pretrained<span class="token punctuation">(</span><span class="token string">"/root/autodl-tmp/tuningdata/merge_model"</span><span class="token punctuation">)</span>
</code></pre> 
<hr> 
<h2><a id="_858"></a>æ€»ç»“</h2> 
<p>LoRAæ˜¯ä¸€ç§æ–°é¢–çš„å¾®è°ƒæŠ€æœ¯ï¼Œé€šè¿‡å¼•å…¥ä½ç§©çŸ©é˜µæ¥è°ƒæ•´æ¨¡å‹çš„è¡Œä¸ºï¼Œä»¥æé«˜æ¨¡å‹åœ¨æ–°ä»»åŠ¡ä¸Šçš„è¡¨ç°ã€‚å®ƒå…·æœ‰å‚æ•°é«˜æ•ˆã€è®¡ç®—å¤æ‚åº¦ä½ç­‰ä¼˜ç‚¹ï¼Œå› æ­¤åœ¨è‡ªç„¶è¯­è¨€å¤„ç†é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚</p> 
<p><img src="https://images2.imgbox.com/bb/e7/UeuHars5_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<p>ğŸ¯ğŸ”–æ›´å¤šä¸“æ ç³»åˆ—æ–‡ç« ï¼š<a href="https://blog.csdn.net/xiaobing259/category_12628007.html?spm=1001.2014.3001.5482"><strong>AIGC-AIå¤§æ¨¡å‹æ¢ç´¢ä¹‹è·¯</strong></a></p> 
<blockquote> 
 <p>å¦‚æœæ–‡ç« å†…å®¹å¯¹æ‚¨æœ‰æ‰€è§¦åŠ¨ï¼Œåˆ«å¿˜äº†<font color="red"><strong>ç‚¹èµã€â­å…³æ³¨ï¼Œæ”¶è—</strong></font>ï¼åŠ å…¥æˆ‘ï¼Œè®©æˆ‘ä»¬æºæ‰‹åŒè¡ŒAIçš„æ¢ç´¢ä¹‹æ—…ï¼Œä¸€èµ·å¼€å¯æ™ºèƒ½æ—¶ä»£çš„å¤§é—¨ï¼</p> 
</blockquote>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/e3f0e947814c486c131605818f9370ac/" rel="prev">
			<span class="pager__subtitle">Â«&thinsp;Previous</span>
			<p class="pager__title">2024å¹´ç½‘ç»œå®‰å…¨æœ€å…¨å‡¯å“¥å¸¦ä½ ä»é›¶å­¦å¤§æ•°æ®ç³»åˆ—ä¹‹Javaç¯‡---ç¬¬åä¸ƒç«  é›†åˆ(List)(1)ï¼Œ2024å¹´æœ€æ–°å¸¦ä½ è½»æ¾ç†è§£ç½‘ç»œå®‰å…¨-Hookæœºåˆ¶</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/b4c594d4a2ce56f5eb1dd1e647b2b8ca/" rel="next">
			<span class="pager__subtitle">Next&thinsp;Â»</span>
			<p class="pager__title">ã€Javaã€‘ç¬¬äºŒè®²ï¼šå­—ç¬¦ä¸²ç›¸å…³ç±»</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 ç¼–ç¨‹å­¦ä¹ è€….
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>